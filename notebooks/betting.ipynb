{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 264,
   "id": "ac0dcea3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import polars as pl\n",
    "import os\n",
    "import copy\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import random as rnd\n",
    "from collections import defaultdict\n",
    "os.chdir('..')\n",
    "os.chdir('src')\n",
    "from env import BlackjackEnv\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "623d6b94",
   "metadata": {},
   "source": [
    "#### Heuristics about betting and true count\n",
    "The most common strategy for betting based on the true count is to use a multiplier for your base bet (say 1) according to the counter.\n",
    "A reasonable choice for a simple betting strategy is the following:\n",
    "- Non-positive true count (0 or below): 1x base bet\n",
    "- Positive mid true count (1 to 5): 4x base bet (could be split in 2x and 4x)\n",
    "- Positive high true count (6 or above): 8x base bet \\\n",
    "Our goal: make the agent learn this betting strategy, which should yield a higher expected reward than simply betting 1 \\\n",
    "Assumption: all games are played according to the basic strategy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8f20e44",
   "metadata": {},
   "source": [
    "### Load playing strategies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "id": "e7209e63",
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_strategy_csv(file_path):\n",
    "    try:\n",
    "        # Read the CSV file\n",
    "        df = pl.read_csv(file_path)\n",
    "        \n",
    "        # Initialize the basic strategy dictionary\n",
    "        strategy = {}\n",
    "        \n",
    "        # Process the dataframe into a dictionary\n",
    "        for row in df.iter_rows(named=True):\n",
    "            # Parse the state from string format like '(12, 10, 0)'\n",
    "            # Extract the state values\n",
    "            state_str = row['State'].strip('()').split(', ')\n",
    "\n",
    "            # state_str = row['State'].strip('[]').split()\n",
    "            player_sum = int(state_str[0])\n",
    "            dealer_card = int(state_str[1])\n",
    "            usable_ace = int(state_str[2])\n",
    "            \n",
    "            # Create the state key\n",
    "            state_key = (player_sum, dealer_card, usable_ace)\n",
    "            \n",
    "            # Get the action values\n",
    "            stand_value = row['Action 0 (Stand)']\n",
    "            hit_value = row['Action 1 (Hit)']\n",
    "            # Check if the column for double action exists\n",
    "            if 'Action 2 (Double)' in row:\n",
    "                double_value = row['Action 2 (Double)']\n",
    "            else:\n",
    "                # If not present, set double value to None or some default\n",
    "                double_value = None\n",
    "            \n",
    "            # Store the action values in a dictionary\n",
    "            strategy[state_key] = {\n",
    "                0: stand_value,  # Stand\n",
    "                1: hit_value,    # Hit\n",
    "                2: double_value   # Double\n",
    "            }\n",
    "            \n",
    "        return strategy\n",
    "    except Exception as e:\n",
    "        print(f\"Error reading {file_path}: {e}\")\n",
    "        return {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "id": "6fe91653",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir('..')\n",
    "os.chdir('strategies')\n",
    "# Load the strategy CSV file\n",
    "q_table_strat = parse_strategy_csv('dq_h_s_dd_strat.csv')\n",
    "basic_strat = parse_strategy_csv('basic_strat_doub.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9710af61",
   "metadata": {},
   "source": [
    "### Q table initialization for betting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "id": "43e6e771",
   "metadata": {},
   "outputs": [],
   "source": [
    "config = {\n",
    "    \"num_decks\": 6,\n",
    "    \"red_card_position\": 0.2,\n",
    "    \"bet_size\": [1, 4, 8],\n",
    "    \"actions\": [\"stand\", \"hit\", \"double\"],\n",
    "    \"num_players\": 1\n",
    "}\n",
    "\n",
    "env = BlackjackEnv(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "id": "587ddc26",
   "metadata": {},
   "outputs": [],
   "source": [
    "q_table_bet_1 = {}\n",
    "q_table_bet_2 = {}\n",
    "# Initialize the Q-table for betting based on the true count using a dictionary\n",
    "for i in range(0, 3):\n",
    "    q_table_bet_1[i] = {bet: 0.0 for bet in config[\"bet_size\"]}\n",
    "    q_table_bet_2[i] = {bet: 0.0 for bet in config[\"bet_size\"]}\n",
    "    # Initialize with some bias based on betting theory:\n",
    "    # - Higher bets are better for high counts (card counting advantage)\n",
    "    # - Lower bets are better for low or negative counts\n",
    "    for bet in config[\"bet_size\"]:\n",
    "        if i >= 1 and bet > 1:  # High count, higher bet might be better\n",
    "            q_table_bet_1[i][bet] = 0.1 * bet * i / 3 #5\n",
    "            q_table_bet_2[i][bet] = 0.1 * bet * i / 3 #5\n",
    "        elif i == 0 and bet == 1:  # Negative count, minimum bet is better\n",
    "            q_table_bet_1[i][bet] = 0.5\n",
    "            q_table_bet_2[i][bet] = 0.5\n",
    "        elif i == 0 and bet > 1:  # Negative count, higher bet is worse\n",
    "            q_table_bet_1[i][bet] = -0.1\n",
    "            q_table_bet_2[i][bet] = -0.1\n",
    "\n",
    "# True count visit tracking for exploration bias\n",
    "true_count_visits = {i: 0 for i in range(0, 3)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "id": "e64eaa9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameters\n",
    "initial_alpha = 0.1  # Starting learning rate\n",
    "min_alpha = 0.001  # Minimum learning rate\n",
    "decay_rate = 0.999995  # Decay rate for learning rate\n",
    "gamma = 0.95  # Discount factor\n",
    "starting_epsilon = 1.0  # Exploration rate\n",
    "epsilon_decay = 0.99999  # Decay rate for exploration\n",
    "min_epsilon = 0.01  # Minimum exploration rate"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81957317",
   "metadata": {},
   "source": [
    "### Training functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "id": "5f9767d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_true_count(full_state):\n",
    "    true_count = full_state[-1]\n",
    "    return true_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "id": "d31f54cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Modified state representation - focusing on meaningful game states\n",
    "def get_state_features(full_state):\n",
    "    # Extract just player sum, dealer card, and usable ace\n",
    "    player_sum = full_state[0]\n",
    "    dealer_card = full_state[1]\n",
    "    usable_ace = full_state[2]\n",
    "    return (player_sum, dealer_card, usable_ace)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "id": "5d56f4d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_q_values(state_features, q_table=q_table_strat):\n",
    "    \"\"\"Get Q-values for a given state\"\"\"\n",
    "    if state_features in q_table:\n",
    "        return np.array([q_table[state_features][0], q_table[state_features][1], q_table[state_features][2]])\n",
    "    else:\n",
    "        # Return default values based on player sum\n",
    "        player_sum = state_features[0]\n",
    "        if player_sum < 12:\n",
    "            return np.array([-0.1, 0.5, 0.0])  # Default to hit for low sums\n",
    "        elif player_sum >= 20:\n",
    "            return np.array([0.5, -0.1, 0.0])  # Default to stand for high sums\n",
    "        else:\n",
    "            return np.array([0.0, 0.0, 0.0])  # Neutral for middle sums"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "id": "bccc5739",
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_q_value(true_count, bet_amount, reward, next_true_count, lr, terminal=False, q_table=None, target_q_table=None):\n",
    "    \"\"\"Update Q-value for true_count-bet pair using Double Q-learning.\"\"\"\n",
    "    \n",
    "    # Current Q-value\n",
    "    current_q = q_table[true_count][bet_amount]\n",
    "    \n",
    "    if terminal or next_true_count is None:\n",
    "        # Terminal state - no future rewards\n",
    "        new_q = current_q + lr * (reward - current_q)\n",
    "    else:\n",
    "        # Get the next state's best action from current Q-table\n",
    "        best_next_bet = max(q_table[next_true_count], key=q_table[next_true_count].get)\n",
    "        \n",
    "        # Get Q-value for best action from target Q-table\n",
    "        max_next_q = target_q_table[next_true_count][best_next_bet]\n",
    "        \n",
    "        # Q-learning update formula with future rewards\n",
    "        new_q = current_q + lr * (reward + gamma * max_next_q - current_q)\n",
    "    \n",
    "    # Update the Q-table entry\n",
    "    q_table[true_count][bet_amount] = new_q\n",
    "    \n",
    "    return q_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "id": "a3d66dd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def smart_exploration(true_count, epsilon, q_table_1, q_table_2):\n",
    "    \"\"\"Smart exploration strategy based on true count visit frequency.\"\"\"\n",
    "    \n",
    "    # Count-based exploration: make rarely seen true counts more likely to be explored\n",
    "    visit_count = true_count_visits[true_count]\n",
    "    exploration_bonus = 1.0 / (1.0 + visit_count / 1000)  # Normalize visit count\n",
    "    adjusted_epsilon = min(0.9, epsilon + exploration_bonus)\n",
    "    \n",
    "    # Decide to explore or exploit\n",
    "    if np.random.rand() < adjusted_epsilon:\n",
    "        # Explore - but with a bias towards higher bets for high counts\n",
    "        num_bets = len(config[\"bet_size\"])\n",
    "        if true_count >= 2:\n",
    "            # With high count, bias towards higher bets during exploration\n",
    "            bet_probs = np.linspace(0.1, 0.9, num_bets)\n",
    "        elif true_count == 0:\n",
    "            # With low/negative count, bias towards lower bets\n",
    "            bet_probs = np.linspace(0.9, 0.1, num_bets)\n",
    "        else:\n",
    "            # Neutral count, uniform exploration\n",
    "            bet_probs = np.full(num_bets, 1.0 / num_bets)\n",
    "        \n",
    "        # Normalize probabilities to ensure they sum to 1\n",
    "        bet_probs /= bet_probs.sum()\n",
    "        bet_amount = np.random.choice(config[\"bet_size\"], p=bet_probs)\n",
    "    else:\n",
    "        # Exploit: use average of both Q-tables to determine best bet\n",
    "        avg_q_values = {}\n",
    "        for bet in config[\"bet_size\"]:\n",
    "            avg_q_values[bet] = (q_table_1[true_count][bet] + q_table_2[true_count][bet]) / 2\n",
    "        \n",
    "        bet_amount = max(avg_q_values, key=avg_q_values.get)\n",
    "    \n",
    "    # Update visit count for this true count\n",
    "    true_count_visits[true_count] += 1\n",
    "    \n",
    "    return bet_amount"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "id": "49de5069",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_adaptive_lr(initial_lr, min_lr, decay_rate, episode, visits=None):\n",
    "    \"\"\"Calculate an adaptive learning rate based on episode and visit count.\"\"\"\n",
    "    if visits and visits > 100:\n",
    "        # Slower decay for frequently visited states\n",
    "        return max(min_lr, initial_lr * (0.999 ** (visits // 100)))\n",
    "    else:\n",
    "        # Regular decay based on episode number\n",
    "        return max(min_lr, initial_lr * (decay_rate ** episode))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c919bb90",
   "metadata": {},
   "source": [
    "### Training process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "id": "82c0c0fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "def discretize_true_count(tc):\n",
    "    if tc <= 1: return 0\n",
    "    # elif 1 < tc <= 3: return 1\n",
    "    # elif 3 < tc < 5: return 2\n",
    "    elif 1 < tc < 5: return 1\n",
    "    else: return 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a94e5cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Starting betting learning process...\n",
      "Current Q-values for True Count 0: {1: -0.5038074622227043, 4: -0.0063246401640314615, 8: -0.18135532037450477}\n",
      "Episode 10000/3000000 - Epsilon: 0.9048, Alpha: 0.0932,\n",
      "Current Q-values for True Count 0: {1: 0.07554855259574053, 4: -0.17320667093251368, 8: -0.3286770360333686}\n",
      "Episode 20000/3000000 - Epsilon: 0.8187, Alpha: 0.0869,\n",
      "Current Q-values for True Count 0: {1: -0.1368905339189322, 4: 0.28112764879789454, 8: 0.13241496961554106}\n",
      "Episode 30000/3000000 - Epsilon: 0.7408, Alpha: 0.0810,\n",
      "Current Q-values for True Count 0: {1: 0.15940619835901676, 4: -0.1342633014789847, 8: -0.3912096344293493}\n",
      "Episode 40000/3000000 - Epsilon: 0.6703, Alpha: 0.0751,\n",
      "Current Q-values for True Count 1: {1: 0.20464646526193986, 4: 0.07961263666094781, 8: -0.020020708093759165}\n",
      "Episode 50000/3000000 - Epsilon: 0.6065, Alpha: 0.0885,\n",
      "Current Q-values for True Count 0: {1: 0.27360655135382084, 4: -0.025300668836394105, 8: -0.0672289075440515}\n",
      "Episode 60000/3000000 - Epsilon: 0.5488, Alpha: 0.0650,\n",
      "Current Q-values for True Count 0: {1: -0.2993774866187398, 4: -0.1707163888076976, 8: -0.10199889186926614}\n",
      "Episode 70000/3000000 - Epsilon: 0.4966, Alpha: 0.0604,\n",
      "Current Q-values for True Count 0: {1: -0.10326812473938304, 4: -0.23522612010673982, 8: -0.14254630685207473}\n",
      "Episode 80000/3000000 - Epsilon: 0.4493, Alpha: 0.0562,\n",
      "Current Q-values for True Count 0: {1: -0.2015136278533755, 4: -0.11238612873308154, 8: 0.06029056856416572}\n",
      "Episode 90000/3000000 - Epsilon: 0.4066, Alpha: 0.0521,\n",
      "Current Q-values for True Count 0: {1: -0.15293249269253967, 4: -0.15783387149816638, 8: -0.45002893627040436}\n",
      "Episode 100000/3000000 - Epsilon: 0.3679, Alpha: 0.0484,\n",
      "Current Q-values for True Count 0: {1: -0.23031267752749912, 4: -0.058517384527390706, 8: -0.26304247235165823}\n",
      "Episode 110000/3000000 - Epsilon: 0.3329, Alpha: 0.0450,\n",
      "Current Q-values for True Count 1: {1: 0.25972251203116326, 4: 0.10315185450815902, 8: -0.118192556954199}\n",
      "Episode 120000/3000000 - Epsilon: 0.3012, Alpha: 0.0746,\n",
      "Current Q-values for True Count 0: {1: -0.0498938379765064, 4: -0.13065083927593313, 8: -0.0013192190776709634}\n",
      "Episode 130000/3000000 - Epsilon: 0.2725, Alpha: 0.0393,\n",
      "Current Q-values for True Count 0: {1: -0.16187483777584372, 4: -0.11012889361202477, 8: 0.07424160103773675}\n",
      "Episode 140000/3000000 - Epsilon: 0.2466, Alpha: 0.0364,\n",
      "Current Q-values for True Count 0: {1: -0.302098671931726, 4: -0.17249730833375704, 8: -0.016453659458199828}\n",
      "Episode 150000/3000000 - Epsilon: 0.2231, Alpha: 0.0338,\n",
      "Current Q-values for True Count 0: {1: -0.06629746964300454, 4: -0.06363340540448476, 8: -0.048327262088973214}\n",
      "Episode 160000/3000000 - Epsilon: 0.2019, Alpha: 0.0315,\n",
      "Current Q-values for True Count 0: {1: -0.10010991057859495, 4: -0.07265842835511596, 8: -0.00776021833846785}\n",
      "Episode 170000/3000000 - Epsilon: 0.1827, Alpha: 0.0293,\n",
      "Current Q-values for True Count 0: {1: -0.0254405610856764, 4: -0.278780472029573, 8: -0.2282802360878856}\n",
      "Episode 180000/3000000 - Epsilon: 0.1653, Alpha: 0.0272,\n",
      "Current Q-values for True Count 1: {1: -0.09374814372146355, 4: -0.3549682284280976, 8: -0.32039686694250097}\n",
      "Episode 190000/3000000 - Epsilon: 0.1496, Alpha: 0.0629,\n",
      "Current Q-values for True Count 0: {1: -0.22493901668776245, 4: -0.1271832096126933, 8: -0.27781354089682647}\n",
      "Episode 200000/3000000 - Epsilon: 0.1353, Alpha: 0.0236,\n",
      "Current Q-values for True Count 1: {1: -0.0785686242170219, 4: -0.3342020142240956, 8: 0.09603085207521397}\n",
      "Episode 210000/3000000 - Epsilon: 0.1225, Alpha: 0.0601,\n",
      "Current Q-values for True Count 0: {1: -0.2104711488681325, 4: 0.04968629709459972, 8: -0.10373421457417695}\n",
      "Episode 220000/3000000 - Epsilon: 0.1108, Alpha: 0.0205,\n",
      "Current Q-values for True Count 0: {1: -0.1438778925091683, 4: -0.19164350418288467, 8: -0.07603619438374462}\n",
      "Episode 230000/3000000 - Epsilon: 0.1003, Alpha: 0.0191,\n",
      "Current Q-values for True Count 0: {1: -0.07268166027992225, 4: -0.1522254173167569, 8: -0.22462245080048807}\n",
      "Episode 240000/3000000 - Epsilon: 0.0907, Alpha: 0.0177,\n",
      "Current Q-values for True Count 0: {1: 0.002591913668638701, 4: -0.16454894884418192, 8: -0.08937389396609217}\n",
      "Episode 250000/3000000 - Epsilon: 0.0821, Alpha: 0.0165,\n",
      "Current Q-values for True Count 0: {1: 0.00976300330569578, 4: -0.1747884109284428, 8: 0.03364048854927143}\n",
      "Episode 260000/3000000 - Epsilon: 0.0743, Alpha: 0.0154,\n",
      "Current Q-values for True Count 0: {1: -0.1267528584091961, 4: -0.24197466322064032, 8: -0.0816140625906259}\n",
      "Episode 270000/3000000 - Epsilon: 0.0672, Alpha: 0.0142,\n",
      "Current Q-values for True Count 1: {1: -0.046015588885223724, 4: -0.17445582953531094, 8: -0.2176274040091007}\n",
      "Episode 280000/3000000 - Epsilon: 0.0608, Alpha: 0.0505,\n",
      "Current Q-values for True Count 0: {1: -0.09960939410173096, 4: -0.24389201748742823, 8: -0.18214347997267105}\n",
      "Episode 290000/3000000 - Epsilon: 0.0550, Alpha: 0.0124,\n",
      "Current Q-values for True Count 0: {1: -0.20109302910100288, 4: -0.21283256898568076, 8: -0.07443007532080856}\n",
      "Episode 300000/3000000 - Epsilon: 0.0498, Alpha: 0.0115,\n",
      "Current Q-values for True Count 0: {1: -0.08029888813532414, 4: -0.11108118434384978, 8: -0.18391433556678322}\n",
      "Episode 310000/3000000 - Epsilon: 0.0450, Alpha: 0.0108,\n",
      "Current Q-values for True Count 1: {1: 0.17596311146173543, 4: -0.08063029207550987, 8: -0.23487489180365498}\n",
      "Episode 320000/3000000 - Epsilon: 0.0408, Alpha: 0.0456,\n",
      "Current Q-values for True Count 0: {1: -0.11672858005821377, 4: -0.19853883639297726, 8: -0.12989406399440312}\n",
      "Episode 330000/3000000 - Epsilon: 0.0369, Alpha: 0.0093,\n",
      "Current Q-values for True Count 0: {1: 0.14042887869773923, 4: -0.22425468661065345, 8: -0.09488119518315152}\n",
      "Episode 340000/3000000 - Epsilon: 0.0334, Alpha: 0.0086,\n",
      "Current Q-values for True Count 0: {1: -0.2702549466090725, 4: -0.011053001366653478, 8: -0.1178202878238125}\n",
      "Episode 350000/3000000 - Epsilon: 0.0302, Alpha: 0.0080,\n",
      "Current Q-values for True Count 0: {1: -0.047305287826362445, 4: -0.1535590056596673, 8: -0.17632729861863514}\n",
      "Episode 360000/3000000 - Epsilon: 0.0273, Alpha: 0.0075,\n",
      "Current Q-values for True Count 0: {1: -0.19616738644761691, 4: -0.23229837275999177, 8: -0.0764339113951158}\n",
      "Episode 370000/3000000 - Epsilon: 0.0247, Alpha: 0.0070,\n",
      "Current Q-values for True Count 2: {1: -0.15630489177978898, 4: -0.20495999712636254, 8: -0.03335109273601733}\n",
      "Episode 380000/3000000 - Epsilon: 0.0224, Alpha: 0.0875,\n",
      "Current Q-values for True Count 1: {1: 0.1172303393480828, 4: -0.38608524409602585, 8: -0.245358686835128}\n",
      "Episode 390000/3000000 - Epsilon: 0.0202, Alpha: 0.0385,\n",
      "Current Q-values for True Count 0: {1: -0.15271585424102035, 4: -0.18138659973937973, 8: 0.027923019957574336}\n",
      "Episode 400000/3000000 - Epsilon: 0.0183, Alpha: 0.0056,\n",
      "Current Q-values for True Count 0: {1: 0.10020649516217962, 4: -0.08085132997448471, 8: -0.20379519642424584}\n",
      "Episode 410000/3000000 - Epsilon: 0.0166, Alpha: 0.0052,\n",
      "Current Q-values for True Count 0: {1: -0.3063174277342656, 4: 0.004330308911955811, 8: -0.24188355556505728}\n",
      "Episode 420000/3000000 - Epsilon: 0.0150, Alpha: 0.0048,\n",
      "Current Q-values for True Count 0: {1: -0.28581998531801517, 4: -0.054361841278518945, 8: -0.23985365862229535}\n",
      "Episode 430000/3000000 - Epsilon: 0.0136, Alpha: 0.0045,\n",
      "Current Q-values for True Count 0: {1: -0.09141829522562737, 4: -0.3320243065668734, 8: -0.2070856436559037}\n",
      "Episode 440000/3000000 - Epsilon: 0.0123, Alpha: 0.0042,\n",
      "Current Q-values for True Count 0: {1: -0.18411326313457538, 4: -0.4270911343211979, 8: -0.20560474982972682}\n",
      "Episode 450000/3000000 - Epsilon: 0.0111, Alpha: 0.0039,\n",
      "Current Q-values for True Count 0: {1: -0.0673525939170037, 4: -0.35668941136401777, 8: -0.2191067529035618}\n",
      "Episode 460000/3000000 - Epsilon: 0.0101, Alpha: 0.0036,\n",
      "Current Q-values for True Count 0: {1: -0.048441144453978416, 4: -0.3680335793705498, 8: -0.22015641816461648}\n",
      "Episode 470000/3000000 - Epsilon: 0.0100, Alpha: 0.0034,\n",
      "Current Q-values for True Count 0: {1: -0.23344366442306588, 4: -0.2868755098119056, 8: -0.2270514580291234}\n",
      "Episode 480000/3000000 - Epsilon: 0.0100, Alpha: 0.0031,\n",
      "Current Q-values for True Count 0: {1: 0.09766806605102411, 4: -0.3028780737825011, 8: -0.22335256674657752}\n",
      "Episode 490000/3000000 - Epsilon: 0.0100, Alpha: 0.0029,\n",
      "Current Q-values for True Count 0: {1: -0.09500445595694537, 4: -0.3082664734190589, 8: -0.2873625965184023}\n",
      "Episode 500000/3000000 - Epsilon: 0.0100, Alpha: 0.0027,\n",
      "Current Q-values for True Count 0: {1: -0.31406722868650766, 4: -0.08353864612771161, 8: -0.28143443860885003}\n",
      "Episode 510000/3000000 - Epsilon: 0.0100, Alpha: 0.0025,\n",
      "Current Q-values for True Count 0: {1: -0.3184219426373398, 4: 0.02453685964879314, 8: -0.2818348337811197}\n",
      "Episode 520000/3000000 - Epsilon: 0.0100, Alpha: 0.0024,\n",
      "Current Q-values for True Count 0: {1: -0.13268657567490208, 4: -0.004687729232985613, 8: -0.280470757948782}\n",
      "Episode 530000/3000000 - Epsilon: 0.0100, Alpha: 0.0022,\n",
      "Current Q-values for True Count 0: {1: 0.0033585548234770254, 4: -0.06099354625568222, 8: -0.2828607470690289}\n",
      "Episode 540000/3000000 - Epsilon: 0.0100, Alpha: 0.0020,\n",
      "Current Q-values for True Count 0: {1: -0.20222476800996697, 4: -0.10752782458209927, 8: -0.28171119992538285}\n",
      "Episode 550000/3000000 - Epsilon: 0.0100, Alpha: 0.0019,\n",
      "Current Q-values for True Count 0: {1: 0.007096908797182353, 4: -0.11005739362508359, 8: -0.27617679791690225}\n",
      "Episode 560000/3000000 - Epsilon: 0.0100, Alpha: 0.0018,\n",
      "Current Q-values for True Count 0: {1: -0.09964765056291622, 4: -0.12017214368640923, 8: -0.27617679791690225}\n",
      "Episode 570000/3000000 - Epsilon: 0.0100, Alpha: 0.0016,\n",
      "Current Q-values for True Count 1: {1: -0.25517915001183683, 4: 0.13376153562211468, 8: -0.25097494510894497}\n",
      "Episode 580000/3000000 - Epsilon: 0.0100, Alpha: 0.0243,\n",
      "Current Q-values for True Count 1: {1: -0.26013844800066305, 4: 0.08913258456449145, 8: -0.3038318691603409}\n",
      "Episode 590000/3000000 - Epsilon: 0.0100, Alpha: 0.0237,\n",
      "Current Q-values for True Count 0: {1: -0.006580656499920406, 4: -0.2653261660936907, 8: -0.27760475176591365}\n",
      "Episode 600000/3000000 - Epsilon: 0.0100, Alpha: 0.0013,\n",
      "Current Q-values for True Count 0: {1: -0.08746264228759912, 4: -0.24780346047060364, 8: -0.29493047364653063}\n",
      "Episode 610000/3000000 - Epsilon: 0.0100, Alpha: 0.0012,\n",
      "Current Q-values for True Count 0: {1: -0.19324479467291264, 4: -0.2085822019787163, 8: -0.31159329836328487}\n",
      "Episode 620000/3000000 - Epsilon: 0.0100, Alpha: 0.0011,\n",
      "Current Q-values for True Count 0: {1: -0.1821071011589656, 4: -0.11021577428893091, 8: -0.3123632309699806}\n",
      "Episode 630000/3000000 - Epsilon: 0.0100, Alpha: 0.0011,\n",
      "Current Q-values for True Count 0: {1: -0.17929947720106448, 4: -0.07696616239055021, 8: -0.31055867172111734}\n",
      "Episode 640000/3000000 - Epsilon: 0.0100, Alpha: 0.0010,\n",
      "Current Q-values for True Count 1: {1: -0.21279393279203673, 4: 0.04632759755169227, 8: -0.15151894828209936}\n",
      "Episode 650000/3000000 - Epsilon: 0.0100, Alpha: 0.0204,\n",
      "Current Q-values for True Count 1: {1: 0.08283186509543126, 4: -0.24901561343318296, 8: -0.08038849257952158}\n",
      "Episode 660000/3000000 - Epsilon: 0.0100, Alpha: 0.0199,\n",
      "Current Q-values for True Count 0: {1: -0.032623550477289445, 4: 0.022688899102925725, 8: -0.27584484559112005}\n",
      "Episode 670000/3000000 - Epsilon: 0.0100, Alpha: 0.0010,\n",
      "Current Q-values for True Count 1: {1: -0.059758463343666565, 4: -0.2674124835524711, 8: -0.042750002300505505}\n",
      "Episode 680000/3000000 - Epsilon: 0.0100, Alpha: 0.0189,\n",
      "Current Q-values for True Count 0: {1: -0.12386560088968618, 4: -0.26644802812128243, 8: -0.2914534737819033}\n",
      "Episode 690000/3000000 - Epsilon: 0.0100, Alpha: 0.0010,\n",
      "Current Q-values for True Count 1: {1: 0.13892027965776094, 4: -0.2024019874871149, 8: -0.1673429833586669}\n",
      "Episode 700000/3000000 - Epsilon: 0.0100, Alpha: 0.0180,\n",
      "Current Q-values for True Count 0: {1: -0.2812384718106771, 4: -0.19775493019971566, 8: -0.26836477793083524}\n",
      "Episode 710000/3000000 - Epsilon: 0.0100, Alpha: 0.0010,\n",
      "Current Q-values for True Count 0: {1: -0.3003225430773943, 4: -0.05619596144922391, 8: -0.26782731673975146}\n",
      "Episode 720000/3000000 - Epsilon: 0.0100, Alpha: 0.0010,\n",
      "Current Q-values for True Count 0: {1: -0.2529974915332326, 4: -0.08033323108841914, 8: -0.2672929299335887}\n",
      "Episode 730000/3000000 - Epsilon: 0.0100, Alpha: 0.0010,\n",
      "Current Q-values for True Count 0: {1: -0.20920921768418485, 4: 0.1085731300809231, 8: -0.2660256370036551}\n",
      "Episode 740000/3000000 - Epsilon: 0.0100, Alpha: 0.0010,\n",
      "Current Q-values for True Count 0: {1: -0.18428054734810545, 4: 0.007937007301314577, 8: -0.2674928517552848}\n",
      "Episode 750000/3000000 - Epsilon: 0.0100, Alpha: 0.0010,\n",
      "Current Q-values for True Count 0: {1: -0.1985331827045258, 4: -0.10056810093051918, 8: -0.26968817641108134}\n",
      "Episode 760000/3000000 - Epsilon: 0.0100, Alpha: 0.0010,\n",
      "Current Q-values for True Count 1: {1: -0.05609394669222932, 4: -0.1151485482587717, 8: -0.35848186790214015}\n",
      "Episode 770000/3000000 - Epsilon: 0.0100, Alpha: 0.0152,\n",
      "Current Q-values for True Count 0: {1: -0.22683477394970059, 4: -0.12665031491327627, 8: -0.27114806974643557}\n",
      "Episode 780000/3000000 - Epsilon: 0.0100, Alpha: 0.0010,\n",
      "Current Q-values for True Count 1: {1: 0.06711199640711618, 4: -0.14356054024657136, 8: -0.3138157238681592}\n",
      "Episode 790000/3000000 - Epsilon: 0.0100, Alpha: 0.0144,\n",
      "Current Q-values for True Count 0: {1: -0.15718597419425584, 4: -0.10973101768679272, 8: -0.2710302281451009}\n",
      "Episode 800000/3000000 - Epsilon: 0.0100, Alpha: 0.0010,\n",
      "Current Q-values for True Count 1: {1: -0.036706014645397814, 4: -0.25323449902423417, 8: -0.154361902977998}\n",
      "Episode 810000/3000000 - Epsilon: 0.0100, Alpha: 0.0137,\n",
      "Current Q-values for True Count 0: {1: 0.10243920289592473, 4: -0.09161150929348857, 8: -0.26886356800957834}\n",
      "Episode 820000/3000000 - Epsilon: 0.0100, Alpha: 0.0010,\n",
      "Current Q-values for True Count 0: {1: -0.2104223370604973, 4: 0.08004829326184824, 8: -0.2672897238447627}\n",
      "Episode 830000/3000000 - Epsilon: 0.0100, Alpha: 0.0010,\n",
      "Current Q-values for True Count 1: {1: -0.21167493432946133, 4: -0.2501486249220338, 8: -0.15900887320171023}\n",
      "Episode 840000/3000000 - Epsilon: 0.0100, Alpha: 0.0127,\n",
      "Current Q-values for True Count 0: {1: 0.003370507253084462, 4: -0.13610172378458224, 8: -0.26615387722672407}\n",
      "Episode 850000/3000000 - Epsilon: 0.0100, Alpha: 0.0010,\n",
      "Current Q-values for True Count 0: {1: 0.08428879660813407, 4: -0.12258469666954025, 8: -0.26562283562614786}\n",
      "Episode 860000/3000000 - Epsilon: 0.0100, Alpha: 0.0010,\n",
      "Current Q-values for True Count 1: {1: -0.13687054697064355, 4: -0.24941397970212742, 8: -0.1348412880547885}\n",
      "Episode 870000/3000000 - Epsilon: 0.0100, Alpha: 0.0118,\n",
      "Current Q-values for True Count 0: {1: -0.19367293127868385, 4: -0.19092925782347162, 8: -0.2625614379584313}\n",
      "Episode 880000/3000000 - Epsilon: 0.0100, Alpha: 0.0010,\n",
      "Current Q-values for True Count 0: {1: 0.10101369495548448, 4: -0.14351476817161424, 8: -0.26027554006630843}\n",
      "Episode 890000/3000000 - Epsilon: 0.0100, Alpha: 0.0010,\n",
      "Current Q-values for True Count 0: {1: -0.2021051607415949, 4: -0.1305083357788297, 8: -0.25699849251245416}\n",
      "Episode 900000/3000000 - Epsilon: 0.0100, Alpha: 0.0010,\n",
      "Current Q-values for True Count 0: {1: -0.24780305998476002, 4: 0.09802741346605838, 8: -0.2564837525259218}\n",
      "Episode 910000/3000000 - Epsilon: 0.0100, Alpha: 0.0010,\n",
      "Current Q-values for True Count 1: {1: -0.21719989258121278, 4: 0.06438089780558748, 8: -0.16328324879456896}\n",
      "Episode 920000/3000000 - Epsilon: 0.0100, Alpha: 0.0104,\n",
      "Current Q-values for True Count 0: {1: -0.23883167302364933, 4: -0.09988741409849554, 8: -0.25791746794742487}\n",
      "Episode 930000/3000000 - Epsilon: 0.0100, Alpha: 0.0010,\n",
      "Current Q-values for True Count 1: {1: -0.27824466758088945, 4: 0.18815561283635687, 8: -0.12401759649698227}\n",
      "Episode 940000/3000000 - Epsilon: 0.0100, Alpha: 0.0098,\n",
      "Current Q-values for True Count 0: {1: -0.20037566843442114, 4: 0.03466027919294192, 8: -0.25563444920948086}\n",
      "Episode 950000/3000000 - Epsilon: 0.0100, Alpha: 0.0010,\n",
      "Current Q-values for True Count 0: {1: -0.2594987078828252, 4: 0.23287936648845148, 8: -0.2628431376616788}\n",
      "Episode 960000/3000000 - Epsilon: 0.0100, Alpha: 0.0010,\n",
      "Current Q-values for True Count 0: {1: -0.08178756812905166, 4: -0.2040924322416415, 8: -0.26227201023684804}\n",
      "Episode 970000/3000000 - Epsilon: 0.0100, Alpha: 0.0010,\n",
      "Current Q-values for True Count 0: {1: -0.15623797538862208, 4: -0.1924797361121715, 8: -0.26248697975989616}\n",
      "Episode 980000/3000000 - Epsilon: 0.0100, Alpha: 0.0010,\n",
      "Current Q-values for True Count 0: {1: -0.18945406351114494, 4: 0.1454779917080447, 8: -0.2619632682873561}\n",
      "Episode 990000/3000000 - Epsilon: 0.0100, Alpha: 0.0010,\n",
      "Current Q-values for True Count 0: {1: -0.11455895394652534, 4: -0.07301018009117832, 8: -0.269482372328175}\n",
      "Episode 1000000/3000000 - Epsilon: 0.0100, Alpha: 0.0010,\n",
      "Current Q-values for True Count 0: {1: 0.031142070878757363, 4: -0.2783897503858883, 8: -0.26894467706589104}\n",
      "Episode 1010000/3000000 - Epsilon: 0.0100, Alpha: 0.0010,\n",
      "Current Q-values for True Count 0: {1: 0.03264966359550225, 4: -0.27915313622421783, 8: -0.2678705129491801}\n",
      "Episode 1020000/3000000 - Epsilon: 0.0100, Alpha: 0.0010,\n",
      "Current Q-values for True Count 0: {1: -0.00018768597215424636, 4: -0.329176070444039, 8: -0.2573136814564521}\n",
      "Episode 1030000/3000000 - Epsilon: 0.0100, Alpha: 0.0010,\n",
      "Current Q-values for True Count 0: {1: 0.06305291652109254, 4: -0.3265685925409011, 8: -0.25554151309581347}\n",
      "Episode 1040000/3000000 - Epsilon: 0.0100, Alpha: 0.0010,\n",
      "Current Q-values for True Count 0: {1: -0.04893500671075129, 4: -0.32230342994805955, 8: -0.23730413050300164}\n",
      "Episode 1050000/3000000 - Epsilon: 0.0100, Alpha: 0.0010,\n",
      "Current Q-values for True Count 0: {1: -0.07221984261230072, 4: -0.3252019357450253, 8: -0.2420154547195582}\n",
      "Episode 1060000/3000000 - Epsilon: 0.0100, Alpha: 0.0010,\n",
      "Current Q-values for True Count 0: {1: -0.04822474905423449, 4: -0.3246911292085485, 8: -0.2410488420265885}\n",
      "Episode 1070000/3000000 - Epsilon: 0.0100, Alpha: 0.0010,\n",
      "Current Q-values for True Count 0: {1: -0.06678243051200589, 4: -0.3234438250864443, 8: -0.24034400389859142}\n",
      "Episode 1080000/3000000 - Epsilon: 0.0100, Alpha: 0.0010,\n",
      "Current Q-values for True Count 1: {1: -0.33377721065762833, 4: -0.18153217989934925, 8: -0.018215731108951302}\n",
      "Episode 1090000/3000000 - Epsilon: 0.0100, Alpha: 0.0068,\n",
      "Current Q-values for True Count 0: {1: 0.03121348435984547, 4: -0.32004285359265966, 8: -0.22771844432236887}\n",
      "Episode 1100000/3000000 - Epsilon: 0.0100, Alpha: 0.0010,\n",
      "Current Q-values for True Count 0: {1: 0.03616976142082418, 4: -0.32257950591834045, 8: -0.22926223515216845}\n",
      "Episode 1110000/3000000 - Epsilon: 0.0100, Alpha: 0.0010,\n",
      "Current Q-values for True Count 1: {1: -0.3112226491705632, 4: -0.20158271787455004, 8: 0.12747086933920537}\n",
      "Episode 1120000/3000000 - Epsilon: 0.0100, Alpha: 0.0063,\n",
      "Current Q-values for True Count 0: {1: -0.10678107838069102, 4: -0.3045548272573281, 8: -0.21916769508361392}\n",
      "Episode 1130000/3000000 - Epsilon: 0.0100, Alpha: 0.0010,\n",
      "Current Q-values for True Count 0: {1: -0.21690123944199707, 4: -0.31430203327080497, 8: -0.015292913514207989}\n",
      "Episode 1140000/3000000 - Epsilon: 0.0100, Alpha: 0.0010,\n",
      "Current Q-values for True Count 1: {1: -0.3338479241901509, 4: -0.20485404344130487, 8: 0.034577390048081}\n",
      "Episode 1150000/3000000 - Epsilon: 0.0100, Alpha: 0.0058,\n",
      "Current Q-values for True Count 0: {1: -0.21250984902028924, 4: -0.30575856157779097, 8: -0.11938478913096781}\n",
      "Episode 1160000/3000000 - Epsilon: 0.0100, Alpha: 0.0010,\n",
      "Current Q-values for True Count 0: {1: -0.21195527523917948, 4: -0.046876898300508375, 8: -0.27798528774099784}\n",
      "Episode 1170000/3000000 - Epsilon: 0.0100, Alpha: 0.0010,\n",
      "Current Q-values for True Count 0: {1: -0.18846733710630548, 4: -0.013131754524177246, 8: -0.27670730245325686}\n",
      "Episode 1180000/3000000 - Epsilon: 0.0100, Alpha: 0.0010,\n",
      "Current Q-values for True Count 0: {1: -0.23859041241868123, 4: 0.06824439418131453, 8: -0.2736856065527848}\n",
      "Episode 1190000/3000000 - Epsilon: 0.0100, Alpha: 0.0010,\n",
      "Current Q-values for True Count 0: {1: -0.22478638927579545, 4: -0.21822164811748626, 8: -0.2726375090252858}\n",
      "Episode 1200000/3000000 - Epsilon: 0.0100, Alpha: 0.0010,\n",
      "Current Q-values for True Count 0: {1: 0.05256381485625344, 4: -0.20729279651943489, 8: -0.2713648715162605}\n",
      "Episode 1210000/3000000 - Epsilon: 0.0100, Alpha: 0.0010,\n",
      "Current Q-values for True Count 0: {1: -0.039404686594597366, 4: -0.2050531429945143, 8: -0.2708214131380995}\n",
      "Episode 1220000/3000000 - Epsilon: 0.0100, Alpha: 0.0010,\n",
      "Current Q-values for True Count 0: {1: 0.02811542896502135, 4: -0.2076949247511302, 8: -0.27173974933201106}\n",
      "Episode 1230000/3000000 - Epsilon: 0.0100, Alpha: 0.0010,\n",
      "Current Q-values for True Count 0: {1: -0.033962524489059946, 4: -0.26134406327603393, 8: -0.27219554157309633}\n",
      "Episode 1240000/3000000 - Epsilon: 0.0100, Alpha: 0.0010,\n",
      "Current Q-values for True Count 0: {1: 0.09551986200577212, 4: -0.30205014820988363, 8: -0.2736504226854917}\n",
      "Episode 1250000/3000000 - Epsilon: 0.0100, Alpha: 0.0010,\n",
      "Current Q-values for True Count 1: {1: -0.16227402601826899, 4: -0.22941530094961493, 8: -0.23889387311583618}\n",
      "Episode 1260000/3000000 - Epsilon: 0.0100, Alpha: 0.0045,\n",
      "Current Q-values for True Count 1: {1: -0.15808366836657184, 4: -0.012581149534944566, 8: -0.24461718753149692}\n",
      "Episode 1270000/3000000 - Epsilon: 0.0100, Alpha: 0.0044,\n",
      "Current Q-values for True Count 1: {1: -0.15670106818399698, 4: 0.11651301514413477, 8: -0.23396330049675143}\n",
      "Episode 1280000/3000000 - Epsilon: 0.0100, Alpha: 0.0043,\n",
      "Current Q-values for True Count 1: {1: -0.15362499203899305, 4: -0.004443984427259581, 8: -0.2500794333028316}\n",
      "Episode 1290000/3000000 - Epsilon: 0.0100, Alpha: 0.0042,\n",
      "Current Q-values for True Count 1: {1: -0.14313402951055978, 4: -0.08097606096508612, 8: -0.2467647194175872}\n",
      "Episode 1300000/3000000 - Epsilon: 0.0100, Alpha: 0.0041,\n",
      "Current Q-values for True Count 2: {1: -0.4035456815768466, 4: -0.11362408912407912, 8: -0.05657020672057868}\n",
      "Episode 1310000/3000000 - Epsilon: 0.0100, Alpha: 0.0630,\n",
      "Current Q-values for True Count 1: {1: -0.1965610502272694, 4: 0.0646012092069638, 8: -0.2533108402644743}\n",
      "Episode 1320000/3000000 - Epsilon: 0.0100, Alpha: 0.0039,\n",
      "Current Q-values for True Count 0: {1: -0.21634477946574424, 4: -0.2695576124853869, 8: -0.2626073582550264}\n",
      "Episode 1330000/3000000 - Epsilon: 0.0100, Alpha: 0.0010,\n",
      "Current Q-values for True Count 1: {1: -0.20280048179782512, 4: 0.014150233647278186, 8: -0.2542587742563188}\n",
      "Episode 1340000/3000000 - Epsilon: 0.0100, Alpha: 0.0037,\n",
      "Current Q-values for True Count 0: {1: -0.04190415435200136, 4: -0.26187567587027627, 8: -0.2547832460035149}\n",
      "Episode 1350000/3000000 - Epsilon: 0.0100, Alpha: 0.0010,\n",
      "Current Q-values for True Count 0: {1: -0.06685875802130684, 4: -0.2530981344511062, 8: -0.25352846275751134}\n",
      "Episode 1360000/3000000 - Epsilon: 0.0100, Alpha: 0.0010,\n",
      "Current Q-values for True Count 0: {1: -0.14172493393895524, 4: -0.2583612498527202, 8: -0.25376963670109864}\n",
      "Episode 1370000/3000000 - Epsilon: 0.0100, Alpha: 0.0010,\n",
      "Current Q-values for True Count 1: {1: -0.2042893791151765, 4: -0.10790582394460173, 8: -0.19347366488179807}\n",
      "Episode 1380000/3000000 - Epsilon: 0.0100, Alpha: 0.0033,\n",
      "Current Q-values for True Count 0: {1: -0.007242668993925119, 4: -0.25816927486181135, 8: -0.25519786013171336}\n",
      "Episode 1390000/3000000 - Epsilon: 0.0100, Alpha: 0.0010,\n",
      "Current Q-values for True Count 0: {1: -0.1610451884497551, 4: -0.25758421470455134, 8: -0.25368771960931}\n",
      "Episode 1400000/3000000 - Epsilon: 0.0100, Alpha: 0.0010,\n",
      "Current Q-values for True Count 0: {1: -0.12299092143445602, 4: -0.2572446739299453, 8: -0.2549168228478516}\n",
      "Episode 1410000/3000000 - Epsilon: 0.0100, Alpha: 0.0010,\n",
      "Current Q-values for True Count 0: {1: 0.07144003172673856, 4: -0.2596015297964728, 8: -0.2544082441189788}\n",
      "Episode 1420000/3000000 - Epsilon: 0.0100, Alpha: 0.0010,\n",
      "Current Q-values for True Count 2: {1: -0.4122113657270064, 4: -0.08514228046103772, 8: -0.6258746078660019}\n",
      "Episode 1430000/3000000 - Epsilon: 0.0100, Alpha: 0.0604,\n",
      "Current Q-values for True Count 0: {1: 0.12978422795248334, 4: -0.25161868015740324, 8: -0.25262970130437623}\n",
      "Episode 1440000/3000000 - Epsilon: 0.0100, Alpha: 0.0010,\n",
      "Current Q-values for True Count 0: {1: -0.18662128197708414, 4: -0.24812823582519, 8: -0.25262970130437623}\n",
      "Episode 1450000/3000000 - Epsilon: 0.0100, Alpha: 0.0010,\n",
      "Current Q-values for True Count 1: {1: -0.2491932393157756, 4: 0.18066574462000357, 8: -0.2015506779791065}\n",
      "Episode 1460000/3000000 - Epsilon: 0.0100, Alpha: 0.0028,\n",
      "Current Q-values for True Count 0: {1: 0.01990628815879423, 4: -0.23664731519421078, 8: -0.2521256945314688}\n",
      "Episode 1470000/3000000 - Epsilon: 0.0100, Alpha: 0.0010,\n",
      "Current Q-values for True Count 0: {1: -0.07708470782653914, 4: -0.23427951670158575, 8: -0.25026426753351333}\n",
      "Episode 1480000/3000000 - Epsilon: 0.0100, Alpha: 0.0010,\n",
      "Current Q-values for True Count 0: {1: 0.007836784951778345, 4: -0.2395994727608385, 8: -0.2490140032659798}\n",
      "Episode 1490000/3000000 - Epsilon: 0.0100, Alpha: 0.0010,\n",
      "Current Q-values for True Count 1: {1: -0.16065497722189306, 4: 0.04668907822825957, 8: -0.13104200768122376}\n",
      "Episode 1500000/3000000 - Epsilon: 0.0100, Alpha: 0.0025,\n",
      "Current Q-values for True Count 0: {1: -0.04147745188694298, 4: -0.2351753441747357, 8: -0.2485152242734511}\n",
      "Episode 1510000/3000000 - Epsilon: 0.0100, Alpha: 0.0010,\n",
      "Current Q-values for True Count 0: {1: 0.21027598383996834, 4: -0.22938022314348844, 8: -0.24801744234012846}\n",
      "Episode 1520000/3000000 - Epsilon: 0.0100, Alpha: 0.0010,\n",
      "Current Q-values for True Count 0: {1: -0.17391647371888244, 4: -0.22529234807086723, 8: -0.2505180729760987}\n",
      "Episode 1530000/3000000 - Epsilon: 0.0100, Alpha: 0.0010,\n",
      "Current Q-values for True Count 1: {1: -0.19897143635279982, 4: 0.07632139400448461, 8: -0.12140009683728549}\n",
      "Episode 1540000/3000000 - Epsilon: 0.0100, Alpha: 0.0023,\n",
      "Current Q-values for True Count 0: {1: 0.1024482493131414, 4: -0.22387725319979973, 8: -0.25276427106087124}\n",
      "Episode 1550000/3000000 - Epsilon: 0.0100, Alpha: 0.0010,\n",
      "Current Q-values for True Count 0: {1: -0.16983515411623934, 4: -0.2115540914056822, 8: -0.2532589952830206}\n",
      "Episode 1560000/3000000 - Epsilon: 0.0100, Alpha: 0.0010,\n",
      "Current Q-values for True Count 0: {1: -0.2063037911220161, 4: 0.029996863035363096, 8: -0.25175373055144984}\n",
      "Episode 1570000/3000000 - Epsilon: 0.0100, Alpha: 0.0010,\n",
      "Current Q-values for True Count 0: {1: -0.1961182884664597, 4: -0.022380533957754755, 8: -0.25125147484407745}\n",
      "Episode 1580000/3000000 - Epsilon: 0.0100, Alpha: 0.0010,\n",
      "Current Q-values for True Count 0: {1: -0.12360743880671678, 4: 0.1594225590714728, 8: -0.25125147484407745}\n",
      "Episode 1590000/3000000 - Epsilon: 0.0100, Alpha: 0.0010,\n",
      "Current Q-values for True Count 0: {1: -0.11602609330631776, 4: 0.011804060581772382, 8: -0.2509954749227183}\n",
      "Episode 1600000/3000000 - Epsilon: 0.0100, Alpha: 0.0010,\n",
      "Current Q-values for True Count 1: {1: -0.1874422993466443, 4: -0.01851291523786197, 8: -0.3089144668216238}\n",
      "Episode 1610000/3000000 - Epsilon: 0.0100, Alpha: 0.0019,\n",
      "Current Q-values for True Count 0: {1: -0.12025436670171355, 4: 0.009477862933760494, 8: -0.2543029372043377}\n",
      "Episode 1620000/3000000 - Epsilon: 0.0100, Alpha: 0.0010,\n",
      "Current Q-values for True Count 2: {1: -0.5875290914937396, 4: -0.1930722959234253, 8: -0.0017622952629466546}\n",
      "Episode 1630000/3000000 - Epsilon: 0.0100, Alpha: 0.0563,\n",
      "Current Q-values for True Count 0: {1: -0.17061807716692876, 4: 0.08303703828124455, 8: -0.25179319914877424}\n",
      "Episode 1640000/3000000 - Epsilon: 0.0100, Alpha: 0.0010,\n",
      "Current Q-values for True Count 0: {1: -0.16600582064250988, 4: 0.08113805414151389, 8: -0.2525414059496255}\n",
      "Episode 1650000/3000000 - Epsilon: 0.0100, Alpha: 0.0010,\n",
      "Current Q-values for True Count 0: {1: -0.030613795366220903, 4: 0.009138943208806646, 8: -0.2520375756791322}\n",
      "Episode 1660000/3000000 - Epsilon: 0.0100, Alpha: 0.0010,\n",
      "Current Q-values for True Count 0: {1: -0.004108977220635238, 4: 0.005301013402100968, 8: -0.2520195085678724}\n",
      "Episode 1670000/3000000 - Epsilon: 0.0100, Alpha: 0.0010,\n",
      "Current Q-values for True Count 0: {1: -0.18081431524209926, 4: -0.034711505001613505, 8: -0.24926791770818202}\n",
      "Episode 1680000/3000000 - Epsilon: 0.0100, Alpha: 0.0010,\n",
      "Current Q-values for True Count 0: {1: -0.17553723355410802, 4: -0.11063071812065804, 8: -0.24926791770818202}\n",
      "Episode 1690000/3000000 - Epsilon: 0.0100, Alpha: 0.0010,\n",
      "Current Q-values for True Count 0: {1: -0.003123839891170104, 4: -0.16431795435736762, 8: -0.24801864979047383}\n",
      "Episode 1700000/3000000 - Epsilon: 0.0100, Alpha: 0.0010,\n",
      "Current Q-values for True Count 1: {1: -0.1448573864155378, 4: 0.09892575883708993, 8: -0.2964349339166967}\n",
      "Episode 1710000/3000000 - Epsilon: 0.0100, Alpha: 0.0015,\n",
      "Current Q-values for True Count 0: {1: -0.0946963669317512, 4: -0.15642924842818218, 8: -0.2515242632098247}\n",
      "Episode 1720000/3000000 - Epsilon: 0.0100, Alpha: 0.0010,\n",
      "Current Q-values for True Count 0: {1: -0.05871838209357092, 4: -0.08935359121822935, 8: -0.2485224662076682}\n",
      "Episode 1730000/3000000 - Epsilon: 0.0100, Alpha: 0.0010,\n",
      "Current Q-values for True Count 0: {1: -0.03691344409744201, 4: -0.08791370790996014, 8: -0.24706161993147044}\n",
      "Episode 1740000/3000000 - Epsilon: 0.0100, Alpha: 0.0010,\n",
      "Current Q-values for True Count 0: {1: -0.17649130269795044, 4: -0.13825243905415904, 8: -0.24781455831153898}\n",
      "Episode 1750000/3000000 - Epsilon: 0.0100, Alpha: 0.0010,\n",
      "Current Q-values for True Count 0: {1: 0.13545807499111334, 4: -0.12788929465577686, 8: -0.24656674375322743}\n",
      "Episode 1760000/3000000 - Epsilon: 0.0100, Alpha: 0.0010,\n",
      "Current Q-values for True Count 0: {1: -0.10885003160115436, 4: -0.12322878024888632, 8: -0.24208795069365663}\n",
      "Episode 1770000/3000000 - Epsilon: 0.0100, Alpha: 0.0010,\n",
      "Current Q-values for True Count 0: {1: 0.062274378640414005, 4: -0.11977839520399855, 8: -0.24359377236074425}\n",
      "Episode 1780000/3000000 - Epsilon: 0.0100, Alpha: 0.0010,\n",
      "Current Q-values for True Count 0: {1: -0.1504291775001249, 4: -0.09980905541670469, 8: -0.24310582840979514}\n",
      "Episode 1790000/3000000 - Epsilon: 0.0100, Alpha: 0.0010,\n",
      "Current Q-values for True Count 0: {1: -0.14666666667427242, 4: -0.11006364886384172, 8: -0.24337823899894515}\n",
      "Episode 1800000/3000000 - Epsilon: 0.0100, Alpha: 0.0010,\n",
      "Current Q-values for True Count 0: {1: -0.016716458307351065, 4: -0.1964019442546569, 8: -0.24166627965127568}\n",
      "Episode 1810000/3000000 - Epsilon: 0.0100, Alpha: 0.0010,\n",
      "Current Q-values for True Count 1: {1: 0.1737508203196602, 4: -0.16180251488506348, 8: -0.27359471650640454}\n",
      "Episode 1820000/3000000 - Epsilon: 0.0100, Alpha: 0.0011,\n",
      "Current Q-values for True Count 0: {1: 0.060843638927553206, 4: -0.1296570926692687, 8: -0.24296035750535958}\n",
      "Episode 1830000/3000000 - Epsilon: 0.0100, Alpha: 0.0010,\n",
      "Current Q-values for True Count 0: {1: -0.0993705873300526, 4: -0.12551747630000434, 8: -0.2409879758648847}\n",
      "Episode 1840000/3000000 - Epsilon: 0.0100, Alpha: 0.0010,\n",
      "Current Q-values for True Count 0: {1: 0.021569002286982025, 4: -0.1316205204092064, 8: -0.23850724090113082}\n",
      "Episode 1850000/3000000 - Epsilon: 0.0100, Alpha: 0.0010,\n",
      "Current Q-values for True Count 0: {1: -0.019449158136555133, 4: -0.13322672227147137, 8: -0.23850724090113082}\n",
      "Episode 1860000/3000000 - Epsilon: 0.0100, Alpha: 0.0010,\n",
      "Current Q-values for True Count 0: {1: -0.1701310994141732, 4: -0.12490294579755112, 8: -0.23850724090113082}\n",
      "Episode 1870000/3000000 - Epsilon: 0.0100, Alpha: 0.0010,\n",
      "Current Q-values for True Count 0: {1: -0.016373456010942637, 4: -0.12166452797405308, 8: -0.24031156269849763}\n",
      "Episode 1880000/3000000 - Epsilon: 0.0100, Alpha: 0.0010,\n",
      "Current Q-values for True Count 0: {1: 0.034220478660865604, 4: -0.15901562484561801, 8: -0.2433457613550739}\n",
      "Episode 1890000/3000000 - Epsilon: 0.0100, Alpha: 0.0010,\n",
      "Current Q-values for True Count 0: {1: -0.048791250471540946, 4: -0.15744754937158636, 8: -0.24013745557866997}\n",
      "Episode 1900000/3000000 - Epsilon: 0.0100, Alpha: 0.0010,\n",
      "Current Q-values for True Count 0: {1: -0.013339209852885692, 4: -0.19138561156205103, 8: -0.23965842080496821}\n",
      "Episode 1910000/3000000 - Epsilon: 0.0100, Alpha: 0.0010,\n",
      "Current Q-values for True Count 0: {1: -0.019916700079497668, 4: -0.23167654499643173, 8: -0.24041876238416324}\n",
      "Episode 1920000/3000000 - Epsilon: 0.0100, Alpha: 0.0010,\n",
      "Current Q-values for True Count 0: {1: -0.0032633318018567984, 4: -0.23237264980829023, 8: -0.23969922711287914}\n",
      "Episode 1930000/3000000 - Epsilon: 0.0100, Alpha: 0.0010,\n",
      "Current Q-values for True Count 0: {1: -0.041542716986175794, 4: -0.22607530632537556, 8: -0.24021906835788048}\n",
      "Episode 1940000/3000000 - Epsilon: 0.0100, Alpha: 0.0010,\n",
      "Current Q-values for True Count 0: {1: -0.174735933781544, 4: -0.08802936078679789, 8: -0.2389788492895226}\n",
      "Episode 1950000/3000000 - Epsilon: 0.0100, Alpha: 0.0010,\n",
      "Current Q-values for True Count 0: {1: -0.1755598738015546, 4: -0.05148442065487662, 8: -0.24025963043922305}\n",
      "Episode 1960000/3000000 - Epsilon: 0.0100, Alpha: 0.0010,\n",
      "Current Q-values for True Count 0: {1: -0.17620258932155136, 4: 0.0699703692343439, 8: -0.23978035143797505}\n",
      "Episode 1970000/3000000 - Epsilon: 0.0100, Alpha: 0.0010,\n",
      "Current Q-values for True Count 1: {1: -0.11772774849251035, 4: -0.05078496122351477, 8: -0.3160484317375701}\n",
      "Episode 1980000/3000000 - Epsilon: 0.0100, Alpha: 0.0010,\n",
      "Current Q-values for True Count 1: {1: -0.11457071273153684, 4: 0.021863259729029232, 8: -0.31478413503633257}\n",
      "Episode 1990000/3000000 - Epsilon: 0.0100, Alpha: 0.0010,\n",
      "Current Q-values for True Count 2: {1: -0.35683257943786356, 4: -0.210718817809847, 8: -0.15399456622133864}\n",
      "Episode 2000000/3000000 - Epsilon: 0.0100, Alpha: 0.0495,\n",
      "Current Q-values for True Count 0: {1: -0.16881843780842407, 4: -0.15257597752144642, 8: -0.23765940205563493}\n",
      "Episode 2010000/3000000 - Epsilon: 0.0100, Alpha: 0.0010,\n",
      "Current Q-values for True Count 0: {1: -0.16413498534543897, 4: 0.0018372626346483563, 8: -0.2384217426535793}\n",
      "Episode 2020000/3000000 - Epsilon: 0.0100, Alpha: 0.0010,\n",
      "Current Q-values for True Count 0: {1: -0.15715255466335998, 4: 0.03232575435378726, 8: -0.23694513759001481}\n",
      "Episode 2030000/3000000 - Epsilon: 0.0100, Alpha: 0.0010,\n",
      "Current Q-values for True Count 1: {1: -0.29672483380453274, 4: -0.04554131770411048, 8: -0.21749874184985005}\n",
      "Episode 2040000/3000000 - Epsilon: 0.0100, Alpha: 0.0010,\n",
      "Current Q-values for True Count 0: {1: -0.15164600238789377, 4: 0.0691426054614204, 8: -0.2322994702159634}\n",
      "Episode 2050000/3000000 - Epsilon: 0.0100, Alpha: 0.0010,\n",
      "Current Q-values for True Count 1: {1: -0.25813040563354805, 4: -0.09786676189613279, 8: -0.2146300530041243}\n",
      "Episode 2060000/3000000 - Epsilon: 0.0100, Alpha: 0.0010,\n",
      "Current Q-values for True Count 0: {1: -0.19149784169128972, 4: 0.08791995731379439, 8: -0.22741414525320952}\n",
      "Episode 2070000/3000000 - Epsilon: 0.0100, Alpha: 0.0010,\n",
      "Current Q-values for True Count 0: {1: -0.19606761772362516, 4: -0.06887106444447094, 8: -0.22646104437684836}\n",
      "Episode 2080000/3000000 - Epsilon: 0.0100, Alpha: 0.0010,\n",
      "Current Q-values for True Count 0: {1: -0.10012572609621319, 4: -0.12717610922030903, 8: -0.22455855606098948}\n",
      "Episode 2090000/3000000 - Epsilon: 0.0100, Alpha: 0.0010,\n",
      "Current Q-values for True Count 0: {1: -0.1823797276583714, 4: -0.12353078290321608, 8: -0.22116416629107222}\n",
      "Episode 2100000/3000000 - Epsilon: 0.0100, Alpha: 0.0010,\n",
      "Current Q-values for True Count 0: {1: -0.11200128576471342, 4: -0.12689660261238886, 8: -0.22106255089374272}\n",
      "Episode 2110000/3000000 - Epsilon: 0.0100, Alpha: 0.0010,\n",
      "Current Q-values for True Count 0: {1: -0.11310344374023479, 4: -0.12476029751760954, 8: -0.22106255089374272}\n",
      "Episode 2120000/3000000 - Epsilon: 0.0100, Alpha: 0.0010,\n",
      "Current Q-values for True Count 1: {1: 0.05418886322626598, 4: -0.16225750840267086, 8: -0.20282834710804945}\n",
      "Episode 2130000/3000000 - Epsilon: 0.0100, Alpha: 0.0010,\n",
      "Current Q-values for True Count 0: {1: -0.08789372330747926, 4: -0.12421657535434523, 8: -0.21751875461060854}\n",
      "Episode 2140000/3000000 - Epsilon: 0.0100, Alpha: 0.0010,\n",
      "Current Q-values for True Count 0: {1: -0.11010684289783425, 4: -0.1236034591677174, 8: -0.21830123585599795}\n",
      "Episode 2150000/3000000 - Epsilon: 0.0100, Alpha: 0.0010,\n",
      "Current Q-values for True Count 0: {1: 0.03537084640293406, 4: -0.11938544348113136, 8: -0.2198638516855218}\n",
      "Episode 2160000/3000000 - Epsilon: 0.0100, Alpha: 0.0010,\n",
      "Current Q-values for True Count 0: {1: 0.04956039094248894, 4: -0.11707977304319402, 8: -0.2189857125836543}\n",
      "Episode 2170000/3000000 - Epsilon: 0.0100, Alpha: 0.0010,\n",
      "Current Q-values for True Count 0: {1: -0.16952942399460194, 4: -0.11510526007275362, 8: -0.21633141118405536}\n",
      "Episode 2180000/3000000 - Epsilon: 0.0100, Alpha: 0.0010,\n",
      "Current Q-values for True Count 0: {1: -0.1638743097277059, 4: -0.03576821672974728, 8: -0.22158484602470913}\n",
      "Episode 2190000/3000000 - Epsilon: 0.0100, Alpha: 0.0010,\n",
      "Current Q-values for True Count 1: {1: 0.08142056486895831, 4: -0.09451553137982646, 8: -0.197570811221011}\n",
      "Episode 2200000/3000000 - Epsilon: 0.0100, Alpha: 0.0010,\n",
      "Current Q-values for True Count 1: {1: -0.07696142573400609, 4: -0.09432559483259818, 8: -0.199186966608443}\n",
      "Episode 2210000/3000000 - Epsilon: 0.0100, Alpha: 0.0010,\n",
      "Current Q-values for True Count 0: {1: -0.15040593109603967, 4: 0.10831152708436713, 8: -0.21698113742530606}\n",
      "Episode 2220000/3000000 - Epsilon: 0.0100, Alpha: 0.0010,\n",
      "Current Q-values for True Count 1: {1: 0.03390979778268275, 4: -0.09627424254469598, 8: -0.20117911932941987}\n",
      "Episode 2230000/3000000 - Epsilon: 0.0100, Alpha: 0.0010,\n",
      "Current Q-values for True Count 0: {1: -0.002357960755411016, 4: -0.11079313754212222, 8: -0.21119099148894227}\n",
      "Episode 2240000/3000000 - Epsilon: 0.0100, Alpha: 0.0010,\n",
      "Current Q-values for True Count 0: {1: -0.012177727239181969, 4: -0.11267324262765308, 8: -0.207724069690032}\n",
      "Episode 2250000/3000000 - Epsilon: 0.0100, Alpha: 0.0010,\n",
      "Current Q-values for True Count 0: {1: -0.003085754005427747, 4: -0.11633864091716876, 8: -0.20651634562034196}\n",
      "Episode 2260000/3000000 - Epsilon: 0.0100, Alpha: 0.0010,\n",
      "Current Q-values for True Count 1: {1: 0.0898763495879745, 4: -0.13127211253420104, 8: -0.18795568160707868}\n",
      "Episode 2270000/3000000 - Epsilon: 0.0100, Alpha: 0.0010,\n",
      "Current Q-values for True Count 0: {1: 0.049563511780593136, 4: -0.18732796251825878, 8: -0.20786100573461183}\n",
      "Episode 2280000/3000000 - Epsilon: 0.0100, Alpha: 0.0010,\n",
      "Current Q-values for True Count 0: {1: 0.05047326680350229, 4: -0.22761206454253466, 8: -0.20544649158414835}\n",
      "Episode 2290000/3000000 - Epsilon: 0.0100, Alpha: 0.0010,\n",
      "Current Q-values for True Count 0: {1: -0.012921895580598093, 4: -0.22188281424105225, 8: -0.2042410450925642}\n",
      "Episode 2300000/3000000 - Epsilon: 0.0100, Alpha: 0.0010,\n",
      "Current Q-values for True Count 0: {1: -0.13208528683520845, 4: -0.21845526930959858, 8: -0.20662593547618074}\n",
      "Episode 2310000/3000000 - Epsilon: 0.0100, Alpha: 0.0010,\n",
      "Current Q-values for True Count 0: {1: -0.029806365827429467, 4: -0.215303434114575, 8: -0.20421389023116385}\n",
      "Episode 2320000/3000000 - Epsilon: 0.0100, Alpha: 0.0010,\n",
      "Current Q-values for True Count 0: {1: 0.014573504084403424, 4: -0.21722307582138622, 8: -0.20659886199792715}\n",
      "Episode 2330000/3000000 - Epsilon: 0.0100, Alpha: 0.0010,\n",
      "Current Q-values for True Count 0: {1: 0.06832499017505236, 4: -0.21350731337958334, 8: -0.2079766860019205}\n",
      "Episode 2340000/3000000 - Epsilon: 0.0100, Alpha: 0.0010,\n",
      "Current Q-values for True Count 1: {1: -0.14007539501162566, 4: -0.10548936891178379, 8: -0.11704025951606838}\n",
      "Episode 2350000/3000000 - Epsilon: 0.0100, Alpha: 0.0010,\n",
      "Current Q-values for True Count 0: {1: 0.014796778925419796, 4: -0.21018839508917425, 8: -0.21072295536678973}\n",
      "Episode 2360000/3000000 - Epsilon: 0.0100, Alpha: 0.0010,\n",
      "Current Q-values for True Count 0: {1: -0.00254080846816135, 4: -0.2104463545790106, 8: -0.21030272017901153}\n",
      "Episode 2370000/3000000 - Epsilon: 0.0100, Alpha: 0.0010,\n",
      "Current Q-values for True Count 0: {1: -0.06170455297961136, 4: -0.21086137741355823, 8: -0.2066754417163323}\n",
      "Episode 2380000/3000000 - Epsilon: 0.0100, Alpha: 0.0010,\n",
      "Current Q-values for True Count 1: {1: -0.06641891534258568, 4: -0.03510529033637558, 8: -0.21535524822252985}\n",
      "Episode 2390000/3000000 - Epsilon: 0.0100, Alpha: 0.0010,\n",
      "Current Q-values for True Count 0: {1: -0.07257369150934612, 4: -0.21315416883743446, 8: -0.20805403621083302}\n",
      "Episode 2400000/3000000 - Epsilon: 0.0100, Alpha: 0.0010,\n",
      "Current Q-values for True Count 0: {1: 0.03527150413422325, 4: -0.20853173841807357, 8: -0.20763913619244756}\n",
      "Episode 2410000/3000000 - Epsilon: 0.0100, Alpha: 0.0010,\n",
      "Current Q-values for True Count 1: {1: 0.14636000951091674, 4: -0.07242113902790291, 8: -0.2034020311871497}\n",
      "Episode 2420000/3000000 - Epsilon: 0.0100, Alpha: 0.0010,\n",
      "Current Q-values for True Count 0: {1: 0.002831348737791871, 4: -0.1987147752923576, 8: -0.206811822653146}\n",
      "Episode 2430000/3000000 - Epsilon: 0.0100, Alpha: 0.0010,\n",
      "Current Q-values for True Count 0: {1: -0.039132833987593874, 4: -0.18868831298070277, 8: -0.2031950064138427}\n",
      "Episode 2440000/3000000 - Epsilon: 0.0100, Alpha: 0.0010,\n",
      "Current Q-values for True Count 0: {1: -0.07317145930798613, 4: -0.18800953152792252, 8: -0.20299181140742886}\n",
      "Episode 2450000/3000000 - Epsilon: 0.0100, Alpha: 0.0010,\n",
      "Current Q-values for True Count 0: {1: -0.10635177460495682, 4: -0.19077715610748594, 8: -0.20258503077642542}\n",
      "Episode 2460000/3000000 - Epsilon: 0.0100, Alpha: 0.0010,\n",
      "Current Q-values for True Count 1: {1: -0.022544229668757205, 4: -0.0681807293872619, 8: -0.22797489533868437}\n",
      "Episode 2470000/3000000 - Epsilon: 0.0100, Alpha: 0.0010,\n",
      "Current Q-values for True Count 0: {1: -0.13915327917480713, 4: -0.16997622262638054, 8: -0.201382445745649}\n",
      "Episode 2480000/3000000 - Epsilon: 0.0100, Alpha: 0.0010,\n",
      "Current Q-values for True Count 0: {1: -0.07449141306921687, 4: -0.16279431621230145, 8: -0.20098088223660346}\n",
      "Episode 2490000/3000000 - Epsilon: 0.0100, Alpha: 0.0010,\n",
      "Current Q-values for True Count 0: {1: 0.04414662137776501, 4: -0.15952544675372984, 8: -0.15408011069887104}\n",
      "Episode 2500000/3000000 - Epsilon: 0.0100, Alpha: 0.0010,\n",
      "Current Q-values for True Count 0: {1: -0.04619313497488619, 4: -0.15662463902450527, 8: -0.155771104557584}\n",
      "Episode 2510000/3000000 - Epsilon: 0.0100, Alpha: 0.0010,\n",
      "Current Q-values for True Count 0: {1: -0.08036259566256088, 4: -0.1519406901599063, 8: -0.15461533345302642}\n",
      "Episode 2520000/3000000 - Epsilon: 0.0100, Alpha: 0.0010,\n",
      "Current Q-values for True Count 0: {1: -0.09466695913980702, 4: -0.06552911651157167, 8: -0.1568417993967144}\n",
      "Episode 2530000/3000000 - Epsilon: 0.0100, Alpha: 0.0010,\n",
      "Current Q-values for True Count 0: {1: -0.0982318809712423, 4: -0.05339800167312905, 8: -0.15752827263972036}\n",
      "Episode 2540000/3000000 - Epsilon: 0.0100, Alpha: 0.0010,\n",
      "Current Q-values for True Count 0: {1: -0.09492300232790213, 4: 0.03499424473097464, 8: -0.15637074436708065}\n",
      "Episode 2550000/3000000 - Epsilon: 0.0100, Alpha: 0.0010,\n",
      "Current Q-values for True Count 0: {1: -0.09242267293873324, 4: 0.019634977886269108, 8: -0.15637074436708065}\n",
      "Episode 2560000/3000000 - Epsilon: 0.0100, Alpha: 0.0010,\n",
      "Current Q-values for True Count 1: {1: -0.03584007907488045, 4: -0.02885308490639312, 8: -0.17493443305005268}\n",
      "Episode 2570000/3000000 - Epsilon: 0.0100, Alpha: 0.0010,\n",
      "Current Q-values for True Count 1: {1: -0.0346245814763581, 4: -0.06454775029434921, 8: -0.17458573911838562}\n",
      "Episode 2580000/3000000 - Epsilon: 0.0100, Alpha: 0.0010,\n",
      "Current Q-values for True Count 0: {1: -0.03739452445521537, 4: 0.047619660861966916, 8: -0.15815027074446766}\n",
      "Episode 2590000/3000000 - Epsilon: 0.0100, Alpha: 0.0010,\n",
      "Current Q-values for True Count 0: {1: -0.04162850549515236, 4: 0.014288395187141256, 8: -0.15752261393167133}\n",
      "Episode 2600000/3000000 - Epsilon: 0.0100, Alpha: 0.0010,\n",
      "Current Q-values for True Count 0: {1: -0.03163415568984058, 4: 0.0433762035360757, 8: -0.15836509131773965}\n",
      "Episode 2610000/3000000 - Epsilon: 0.0100, Alpha: 0.0010,\n",
      "Current Q-values for True Count 1: {1: -0.045748562330247475, 4: -0.11919756086008446, 8: -0.11029753535798131}\n",
      "Episode 2620000/3000000 - Epsilon: 0.0100, Alpha: 0.0010,\n",
      "Current Q-values for True Count 1: {1: -0.043528267551961604, 4: -0.11983932665098923, 8: 0.10726086995581584}\n",
      "Episode 2630000/3000000 - Epsilon: 0.0100, Alpha: 0.0010,\n",
      "Current Q-values for True Count 0: {1: -0.09253288924328626, 4: 0.09590778444464548, 8: -0.16125385781418541}\n",
      "Episode 2640000/3000000 - Epsilon: 0.0100, Alpha: 0.0010,\n",
      "Current Q-values for True Count 0: {1: -0.08125199589156251, 4: -0.09536265220566664, 8: -0.16177157884106244}\n",
      "Episode 2650000/3000000 - Epsilon: 0.0100, Alpha: 0.0010,\n",
      "Current Q-values for True Count 0: {1: -0.07985824892892499, 4: 0.012110038199788653, 8: -0.16060980726222138}\n",
      "Episode 2660000/3000000 - Epsilon: 0.0100, Alpha: 0.0010,\n",
      "Current Q-values for True Count 1: {1: -0.054663844398851316, 4: 0.08626999485508934, 8: -0.039681532768804366}\n",
      "Episode 2670000/3000000 - Epsilon: 0.0100, Alpha: 0.0010,\n",
      "Current Q-values for True Count 1: {1: -0.05350101580252411, 4: 0.03878656258026776, 8: -0.04048151952667007}\n",
      "Episode 2680000/3000000 - Epsilon: 0.0100, Alpha: 0.0010,\n",
      "Current Q-values for True Count 0: {1: -0.06941401873075866, 4: -0.024560167806547566, 8: -0.15981235871968774}\n",
      "Episode 2690000/3000000 - Epsilon: 0.0100, Alpha: 0.0010,\n",
      "Current Q-values for True Count 0: {1: -0.06633079970537671, 4: -0.04888798770809788, 8: -0.1594938938146071}\n",
      "Episode 2700000/3000000 - Epsilon: 0.0100, Alpha: 0.0010,\n",
      "Current Q-values for True Count 0: {1: -0.10803456354977334, 4: -0.1345104201482172, 8: -0.15536336906639547}\n",
      "Episode 2710000/3000000 - Epsilon: 0.0100, Alpha: 0.0010,\n",
      "Current Q-values for True Count 0: {1: -0.13974249624673374, 4: -0.10849124195638199, 8: -0.15789474589394012}\n",
      "Episode 2720000/3000000 - Epsilon: 0.0100, Alpha: 0.0010,\n",
      "Current Q-values for True Count 0: {1: -0.08355491399932267, 4: -0.10883393369208093, 8: -0.15873685114804617}\n",
      "Episode 2730000/3000000 - Epsilon: 0.0100, Alpha: 0.0010,\n",
      "Current Q-values for True Count 1: {1: -0.055590732529908746, 4: -0.018114370244869202, 8: -0.1744076842746809}\n",
      "Episode 2740000/3000000 - Epsilon: 0.0100, Alpha: 0.0010,\n",
      "Current Q-values for True Count 0: {1: -0.08624958521055817, 4: -0.10005631816462163, 8: -0.15726411564641865}\n",
      "Episode 2750000/3000000 - Epsilon: 0.0100, Alpha: 0.0010,\n",
      "Current Q-values for True Count 0: {1: 0.011563929024850882, 4: -0.09607830903987438, 8: -0.15694974467924144}\n",
      "Episode 2760000/3000000 - Epsilon: 0.0100, Alpha: 0.0010,\n",
      "Current Q-values for True Count 0: {1: -0.17293787918733822, 4: -0.09631834343049832, 8: -0.1557927949345622}\n",
      "Episode 2770000/3000000 - Epsilon: 0.0100, Alpha: 0.0010,\n",
      "Current Q-values for True Count 1: {1: -0.008771837835985587, 4: -0.008218366343619018, 8: -0.19405361112699257}\n",
      "Episode 2780000/3000000 - Epsilon: 0.0100, Alpha: 0.0010,\n",
      "Current Q-values for True Count 0: {1: 0.02492711930166188, 4: -0.09065952449085163, 8: -0.1555123948256906}\n",
      "Episode 2790000/3000000 - Epsilon: 0.0100, Alpha: 0.0010,\n",
      "Current Q-values for True Count 0: {1: -0.08979179063480588, 4: -0.09049921322163677, 8: -0.1575766500397387}\n",
      "Episode 2800000/3000000 - Epsilon: 0.0100, Alpha: 0.0010,\n",
      "Current Q-values for True Count 1: {1: -0.04480664182309059, 4: -0.10537584872783567, 8: -0.22733975902498801}\n",
      "Episode 2810000/3000000 - Epsilon: 0.0100, Alpha: 0.0010,\n",
      "Current Q-values for True Count 0: {1: -0.050411005893324465, 4: -0.08582104287594386, 8: -0.15610739166199294}\n",
      "Episode 2820000/3000000 - Epsilon: 0.0100, Alpha: 0.0010,\n",
      "Current Q-values for True Count 1: {1: -0.044207733348231554, 4: -0.005467005497017255, 8: -0.21602014496778912}\n",
      "Episode 2830000/3000000 - Epsilon: 0.0100, Alpha: 0.0010,\n",
      "Current Q-values for True Count 1: {1: -0.044118362089268434, 4: -0.06819363330277338, 8: -0.21472027406999902}\n",
      "Episode 2840000/3000000 - Epsilon: 0.0100, Alpha: 0.0010,\n",
      "Current Q-values for True Count 0: {1: -0.030841443497741566, 4: -0.08673951098427528, 8: -0.1490837220875693}\n",
      "Episode 2850000/3000000 - Epsilon: 0.0100, Alpha: 0.0010,\n",
      "Current Q-values for True Count 0: {1: -0.13996604646583138, 4: -0.08643855925599483, 8: -0.1490837220875693}\n",
      "Episode 2860000/3000000 - Epsilon: 0.0100, Alpha: 0.0010,\n",
      "Current Q-values for True Count 1: {1: -0.04288843210428254, 4: 0.043604342429551794, 8: -0.23808983783345908}\n",
      "Episode 2870000/3000000 - Epsilon: 0.0100, Alpha: 0.0010,\n",
      "Current Q-values for True Count 0: {1: 0.014458924657137134, 4: -0.08643653210119756, 8: -0.1479011903647803}\n",
      "Episode 2880000/3000000 - Epsilon: 0.0100, Alpha: 0.0010,\n",
      "Current Q-values for True Count 1: {1: -0.04163374697501683, 4: -0.009157146572094278, 8: -0.23588028085138235}\n",
      "Episode 2890000/3000000 - Epsilon: 0.0100, Alpha: 0.0010,\n",
      "Current Q-values for True Count 1: {1: -0.04291700415648315, 4: -0.042725700408076085, 8: -0.23664440057053096}\n",
      "Episode 2900000/3000000 - Epsilon: 0.0100, Alpha: 0.0010,\n",
      "Current Q-values for True Count 0: {1: -0.04033799006330923, 4: -0.08322012424779997, 8: -0.1483114714190065}\n",
      "Episode 2910000/3000000 - Epsilon: 0.0100, Alpha: 0.0010,\n",
      "Current Q-values for True Count 0: {1: -0.11326978804890012, 4: -0.07734813357357999, 8: -0.1480159967876399}\n",
      "Episode 2920000/3000000 - Epsilon: 0.0100, Alpha: 0.0010,\n",
      "Current Q-values for True Count 2: {1: -0.3628122572773895, 4: -0.3091298554814961, 8: 0.14659142589777552}\n",
      "Episode 2930000/3000000 - Epsilon: 0.0100, Alpha: 0.0356,\n",
      "Current Q-values for True Count 0: {1: 0.0633174025575874, 4: -0.07700136171627264, 8: -0.14941882430355408}\n",
      "Episode 2940000/3000000 - Epsilon: 0.0100, Alpha: 0.0010,\n",
      "Current Q-values for True Count 1: {1: -0.047826311553102865, 4: -0.13252156838046275, 8: -0.23261730103681333}\n",
      "Episode 2950000/3000000 - Epsilon: 0.0100, Alpha: 0.0010,\n",
      "Current Q-values for True Count 1: {1: -0.0486839750495519, 4: -0.0883669061317609, 8: -0.2313846837357765}\n",
      "Episode 2960000/3000000 - Epsilon: 0.0100, Alpha: 0.0010,\n",
      "Current Q-values for True Count 1: {1: -0.0486839750495519, 4: -0.08092231402069947, 8: -0.22919522210723572}\n",
      "Episode 2970000/3000000 - Epsilon: 0.0100, Alpha: 0.0010,\n",
      "Current Q-values for True Count 0: {1: -0.17250340701574512, 4: -0.009756749862649704, 8: -0.15172265556721942}\n",
      "Episode 2980000/3000000 - Epsilon: 0.0100, Alpha: 0.0010,\n",
      "Current Q-values for True Count 0: {1: -0.16837884008751827, 4: -0.060035751853236945, 8: -0.15511067867314504}\n",
      "Episode 2990000/3000000 - Epsilon: 0.0100, Alpha: 0.0010,\n",
      "Current Q-values for True Count 0: {1: -0.1377270852735814, 4: -0.13862262892734917, 8: -0.1547996124264774}\n",
      "Episode 3000000/3000000 - Epsilon: 0.0100, Alpha: 0.0010,\n",
      "Betting learning process complete.\n",
      "Total Wins: 1298729\n",
      "Total Draws: 257154\n",
      "Total Losses: 1444117\n",
      "Total Money Won: 4211299.0\n",
      "Total Money Lost: 4254722\n",
      "Average reward: (-0.0145)\n"
     ]
    }
   ],
   "source": [
    "config = {\n",
    "    \"num_decks\": 6,\n",
    "    \"red_card_position\": 0.2,\n",
    "    \"bet_size\": [1, 4, 8],\n",
    "    \"actions\": [\"stand\", \"hit\", \"double\"],\n",
    "    \"num_players\": 1\n",
    "}\n",
    "env = BlackjackEnv(config)\n",
    "\n",
    "# Implement the learning process for betting\n",
    "print(\"\\nStarting betting learning process...\")\n",
    "\n",
    "episodes = 3000000\n",
    "epsilon = starting_epsilon\n",
    "alpha = initial_alpha\n",
    "episode = 0\n",
    "\n",
    "stats = {\n",
    "    'wins': 0,\n",
    "    'draws': 0,\n",
    "    'losses': 0,\n",
    "    'money won': 0,\n",
    "    'money lost': 0,\n",
    "}\n",
    "\n",
    "while episode < episodes:\n",
    "    # Reset the environment and get the true count\n",
    "    _, _, _, true_count = env.reset()\n",
    "    # true_count = int(true_count)  # Convert true count to integer for indexing\n",
    "    true_count = discretize_true_count(true_count)\n",
    "\n",
    "    bet_amount = smart_exploration(true_count, epsilon, q_table_bet_1, q_table_bet_2)\n",
    "\n",
    "    # Perform the betting action\n",
    "    bet_index = config[\"bet_size\"].index(bet_amount)\n",
    "    state, reward, done = env.step(bet_index, action_type=\"bet\")\n",
    "\n",
    "    if done:\n",
    "        # Update Q-value using the reward\n",
    "        next_true_count = discretize_true_count(state[-1])\n",
    "        if np.random.rand() < 0.5: #epsilon\n",
    "            q_table_bet_1 = update_q_value(true_count, bet_amount, reward, next_true_count, alpha, terminal=True, q_table=q_table_bet_1, target_q_table=q_table_bet_2)\n",
    "        else:\n",
    "            q_table_bet_2 = update_q_value(true_count, bet_amount, reward, next_true_count, alpha, terminal=True, q_table=q_table_bet_2, target_q_table=q_table_bet_1)\n",
    "        if reward > 0:\n",
    "            stats['wins'] += 1\n",
    "            stats['money won'] += reward * bet_amount\n",
    "        elif reward == 0:\n",
    "            stats['draws'] += 1\n",
    "        else:\n",
    "            stats['losses'] += 1\n",
    "            stats['money lost'] += abs(reward) * bet_amount\n",
    "    else:\n",
    "        # Continue playing the game according to the strategy in q_table_strat\n",
    "        state_features = get_state_features(state)\n",
    "        double_down = False\n",
    "        while not done:\n",
    "\n",
    "            if state_features[0] < 9:\n",
    "            # Always hit this state as it's not relevant for our training\n",
    "                next_state, _, _ = env.step(1, action_type=\"move\")\n",
    "                next_state_features = get_state_features(next_state) if not done else None\n",
    "                state = next_state\n",
    "                state_features = next_state_features if next_state is not None else None\n",
    "                continue\n",
    "\n",
    "            # Choose the best action based on q_table_strat\n",
    "            q_values = get_q_values(state_features, basic_strat)\n",
    "            action = np.argmax(q_values)\n",
    "\n",
    "            if action == 2:\n",
    "                # Double down action\n",
    "                bet_amount *= 2\n",
    "                double_down = True\n",
    "\n",
    "            # Perform the action\n",
    "            next_state, reward, done = env.step(action, action_type=\"move\")\n",
    "            state = next_state\n",
    "            state_features = get_state_features(state)\n",
    "        \n",
    "        next_true_count = discretize_true_count(state[-1])\n",
    "\n",
    "        if np.random.rand() < 0.5:\n",
    "            q_table_bet_1 = update_q_value(true_count, bet_amount/(double_down + 1), reward, next_true_count, alpha, terminal=done, q_table=q_table_bet_1, target_q_table=q_table_bet_2)\n",
    "        else:\n",
    "            q_table_bet_2 = update_q_value(true_count, bet_amount/(double_down + 1), reward, next_true_count, alpha, terminal=done, q_table=q_table_bet_2, target_q_table=q_table_bet_1)\n",
    "\n",
    "        # Update metrics\n",
    "        if reward > 0:\n",
    "            stats['wins'] += 1\n",
    "            stats['money won'] += reward * bet_amount\n",
    "        elif reward == 0:\n",
    "            stats['draws'] += 1\n",
    "        else:\n",
    "            stats['losses'] += 1\n",
    "            stats['money lost'] += abs(reward) * bet_amount\n",
    "\n",
    "    # Decay epsilon\n",
    "    epsilon = max(min_epsilon, epsilon * epsilon_decay)\n",
    "    alpha = get_adaptive_lr(\n",
    "        initial_alpha, \n",
    "        min_alpha, \n",
    "        decay_rate, \n",
    "        episode,\n",
    "        true_count_visits[true_count]\n",
    "    )\n",
    "    episode += 1\n",
    "    # Print progress every 10000 episodes\n",
    "    if episode % 10000 == 0:\n",
    "        print(f\"Current Q-values for True Count {true_count}: {q_table_bet_1[true_count]}\")\n",
    "        print(f\"Episode {episode}/{episodes} - Epsilon: {epsilon:.4f}, Alpha: {alpha:.4f},\")\n",
    "\n",
    "print(\"Betting learning process complete.\")\n",
    "# Print statistics\n",
    "print(f\"Total Wins: {stats['wins']}\")\n",
    "print(f\"Total Draws: {stats['draws']}\")\n",
    "print(f\"Total Losses: {stats['losses']}\")\n",
    "print(f\"Total Money Won: {stats['money won']}\")\n",
    "print(f\"Total Money Lost: {stats['money lost']}\")\n",
    "print(f\"Average reward: ({(stats['money won'] - stats['money lost']) / episodes:.4f})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "id": "114d9673",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0: 2156809, 1: 737491, 2: 105700}\n"
     ]
    }
   ],
   "source": [
    "print(true_count_visits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "id": "fc170f95",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0: {1: -0.12104271755211019, 4: -0.1656750127837061, 8: -0.18375823361604204}, 1: {1: -0.11718334021568524, 4: -0.053584130222492025, 8: -0.1237619839732702}, 2: {1: -0.2948345016861084, 4: -0.27409454726287363, 8: -0.0864740390207789}}\n"
     ]
    }
   ],
   "source": [
    "#take the average of the two Q-tables\n",
    "q_table_bet_avg = {}\n",
    "for i in range(0, 3):\n",
    "    q_table_bet_avg[i] = {}\n",
    "    for bet in config[\"bet_size\"]:\n",
    "        q_table_bet_avg[i][bet] = (q_table_bet_1[i][bet] + q_table_bet_2[i][bet]) / 2\n",
    "print(q_table_bet_avg)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34e0692e",
   "metadata": {},
   "source": [
    "### Evaluation of betting strategy + basic strategy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c45e095",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Starting betting testing process...\n",
      "Total Wins: 432809\n",
      "Total Draws: 85781\n",
      "Total Losses: 481410\n",
      "Total Money Won: 836893.0\n",
      "Total Money Lost: 833735\n",
      "Net profit: 3158.0\n",
      "Average reward: 0.003158\n"
     ]
    }
   ],
   "source": [
    "# Implement the learning process for betting\n",
    "print(\"\\nStarting betting testing process...\")\n",
    "\n",
    "eval_episodes = 1000000\n",
    "episode = 0\n",
    "\n",
    "config = {\n",
    "    \"num_decks\": 6,\n",
    "    \"red_card_position\": 0.2,\n",
    "    \"bet_size\": [1, 4, 8],\n",
    "    \"actions\": [\"stand\", \"hit\", \"double\"],\n",
    "    \"num_players\": 1\n",
    "}\n",
    "# Create environment with 6 decks (standard casino configuration)\n",
    "env = BlackjackEnv(config=config)\n",
    "\n",
    "eval_stats = {\n",
    "    'wins': 0,\n",
    "    'draws': 0,\n",
    "    'losses': 0,\n",
    "    'money won': 0,\n",
    "    'money lost': 0,\n",
    "}\n",
    "\n",
    "\n",
    "while episode < eval_episodes:\n",
    "    # Reset the environment and get the true count\n",
    "    _, _, _, true_count = env.reset()\n",
    "    true_count = int(true_count)  # Convert true count to integer for indexing\n",
    "    true_count = discretize_true_count(true_count)\n",
    "\n",
    "    bet_amount = max(q_table_bet_avg[true_count], key=q_table_bet_avg[true_count].get)  # Exploit: best bet\n",
    "\n",
    "    # Perform the betting action\n",
    "    bet_index = config[\"bet_size\"].index(bet_amount)\n",
    "    state, reward, done= env.step(bet_index, action_type=\"bet\")\n",
    "\n",
    "    # Update Q-values for betting\n",
    "    if done:\n",
    "        if reward > 0:\n",
    "            eval_stats['wins'] += 1\n",
    "            eval_stats['money won'] += reward * bet_amount\n",
    "        elif reward == 0:\n",
    "            eval_stats['draws'] += 1\n",
    "        else:\n",
    "            eval_stats['losses'] += 1\n",
    "            eval_stats['money lost'] += abs(reward) * bet_amount\n",
    "    else:\n",
    "        # Continue playing the game according to the strategy in q_table_strat\n",
    "        state_features = get_state_features(state)\n",
    "        while not done:\n",
    "\n",
    "            if state_features[0] < 9:\n",
    "            # Always hit this state as it's not relevant for our training\n",
    "                next_state, _, _ = env.step(1, action_type=\"move\")\n",
    "                next_state_features = get_state_features(next_state) if not done else None\n",
    "                state = next_state\n",
    "                state_features = next_state_features if next_state is not None else None\n",
    "                continue\n",
    "\n",
    "            # Choose the best action based on q_table_strat\n",
    "            q_values = get_q_values(state_features, basic_strat)\n",
    "            action = np.argmax(q_values)\n",
    "\n",
    "            if action == 2:\n",
    "                # Double down action\n",
    "                bet_amount *= 2\n",
    "\n",
    "            # Perform the action\n",
    "            next_state, reward, done = env.step(action, action_type=\"move\")\n",
    "            state = next_state\n",
    "            state_features = get_state_features(state)\n",
    "\n",
    "        # Update metrics\n",
    "        if reward > 0:\n",
    "            eval_stats['wins'] += 1\n",
    "            eval_stats['money won'] += reward * bet_amount\n",
    "        elif reward == 0:\n",
    "            eval_stats['draws'] += 1\n",
    "        else:\n",
    "            eval_stats['losses'] += 1\n",
    "            eval_stats['money lost'] += abs(reward) * bet_amount\n",
    "\n",
    "    episode += 1\n",
    "\n",
    "# Print statistics\n",
    "print(f\"Total Wins: {eval_stats['wins']}\")\n",
    "print(f\"Total Draws: {eval_stats['draws']}\")\n",
    "print(f\"Total Losses: {eval_stats['losses']}\")\n",
    "print(f\"Total Money Won: {eval_stats['money won']}\")\n",
    "print(f\"Total Money Lost: {eval_stats['money lost']}\")\n",
    "print(f\"Net profit: {eval_stats['money won'] - eval_stats['money lost']}\")\n",
    "print(f\"Average reward: {(eval_stats['money won'] - eval_stats['money lost']) / eval_episodes}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb9bcdb2",
   "metadata": {},
   "source": [
    "- Total Wins: 4326200\n",
    "- Total Draws: 857745\n",
    "- Total Losses: 4816055\n",
    "- Total Money Won: 8419082.0\n",
    "- Total Money Lost: 8431736\n",
    "- Net profit: -12654.0\n",
    "- Average reward: -0.0012654"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a153b35",
   "metadata": {},
   "source": [
    "Average reward: -0.035773"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b00943b6",
   "metadata": {},
   "source": [
    "### Benchmark with bet size 1 and basic strategy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97eae321",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Wins: 432960\n",
      "Total Draws: 85933\n",
      "Total Losses: 481107\n",
      "Total Money Won: 515064.0\n",
      "Total Money Lost: 521970\n",
      "Net profit: -6906.0\n",
      "Average reward: -0.006906\n"
     ]
    }
   ],
   "source": [
    "config = {\n",
    "    \"num_decks\": 6,\n",
    "    \"red_card_position\": 0.2,\n",
    "    \"bet_size\": [1],\n",
    "    \"actions\": [\"stand\", \"hit\", \"double\"],\n",
    "    \"num_players\": 1\n",
    "}\n",
    "# Create environment with 6 decks (standard casino configuration)\n",
    "env = BlackjackEnv(config=config)\n",
    "\n",
    "eval_episodes = 1000000\n",
    "episode = 0\n",
    "\n",
    "eval_stats = {\n",
    "    'wins': 0,\n",
    "    'draws': 0,\n",
    "    'losses': 0,\n",
    "    'money won': 0,\n",
    "    'money lost': 0,\n",
    "}\n",
    "\n",
    "while episode < eval_episodes:\n",
    "    # Reset the environment and get the true count\n",
    "    _, _, _, true_count = env.reset()\n",
    "    true_count = int(true_count)  # Convert true count to integer for indexing\n",
    "\n",
    "    bet_amount = 1\n",
    "\n",
    "    # Perform the betting action\n",
    "    bet_index = config[\"bet_size\"].index(bet_amount)\n",
    "    state, reward, done = env.step(bet_index, action_type=\"bet\")\n",
    "\n",
    "    if done:\n",
    "        if reward > 0:\n",
    "            eval_stats['wins'] += 1\n",
    "            eval_stats['money won'] += reward * bet_amount\n",
    "        elif reward == 0:\n",
    "            eval_stats['draws'] += 1\n",
    "        else:\n",
    "            eval_stats['losses'] += 1\n",
    "            eval_stats['money lost'] += abs(reward) * bet_amount\n",
    "    else:\n",
    "        # Continue playing the game according to the strategy in q_table_strat\n",
    "        state_features = get_state_features(state)\n",
    "        while not done:\n",
    "\n",
    "            if state_features[0] < 9:\n",
    "            # Always hit this state as it's not relevant for our training\n",
    "                next_state, _, _ = env.step(1, action_type=\"move\")\n",
    "                next_state_features = get_state_features(next_state) if not done else None\n",
    "                state = next_state\n",
    "                state_features = next_state_features if next_state is not None else None\n",
    "                continue\n",
    "\n",
    "            # Choose the best action based on q_table_strat\n",
    "            q_values = get_q_values(state_features, basic_strat)\n",
    "            action = np.argmax(q_values)\n",
    "\n",
    "            if action == 2:\n",
    "                # Double down action\n",
    "                bet_amount *= 2\n",
    "\n",
    "            # Perform the action\n",
    "            next_state, reward, done = env.step(action, action_type=\"move\")\n",
    "            state = next_state\n",
    "            state_features = get_state_features(state)\n",
    "\n",
    "        # Update metrics\n",
    "        if reward > 0:\n",
    "            eval_stats['wins'] += 1\n",
    "            eval_stats['money won'] += reward * bet_amount\n",
    "        elif reward == 0:\n",
    "            eval_stats['draws'] += 1\n",
    "        else:\n",
    "            eval_stats['losses'] += 1\n",
    "            eval_stats['money lost'] += abs(reward) * bet_amount\n",
    "\n",
    "    episode += 1\n",
    "\n",
    "# Print statistics\n",
    "print(f\"Total Wins: {eval_stats['wins']}\")\n",
    "print(f\"Total Draws: {eval_stats['draws']}\")\n",
    "print(f\"Total Losses: {eval_stats['losses']}\")\n",
    "print(f\"Total Money Won: {eval_stats['money won']}\")\n",
    "print(f\"Total Money Lost: {eval_stats['money lost']}\")\n",
    "print(f\"Net profit: {eval_stats['money won'] - eval_stats['money lost']}\")\n",
    "print(f\"Average reward: {(eval_stats['money won'] - eval_stats['money lost']) / eval_episodes}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db9921d7",
   "metadata": {},
   "source": [
    "Average reward: -0.008368"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8144d128",
   "metadata": {},
   "source": [
    "### Alternative betting strategy (no learning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "id": "0b9b632b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def discretize_true_count(tc):\n",
    "    if tc <= 1: return 0\n",
    "    elif 1 < tc < 5: return 1\n",
    "    else: return 2\n",
    "\n",
    "bet_dict = {\n",
    "    0: 1,\n",
    "    1: 4,\n",
    "    2: 8\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "id": "2da0390b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Wins: 433283\n",
      "Total Draws: 85628\n",
      "Total Losses: 481089\n",
      "Total Money Won: 1022933.0\n",
      "Total Money Lost: 1018769\n",
      "Net profit: 4164.0\n",
      "Average reward: 0.004164\n"
     ]
    }
   ],
   "source": [
    "config = {\n",
    "    \"num_decks\": 6,\n",
    "    \"red_card_position\": 0.2,\n",
    "    \"bet_size\": [1, 4, 8],\n",
    "    \"actions\": [\"stand\", \"hit\", \"double\"],\n",
    "    \"num_players\": 1\n",
    "}\n",
    "# Create environment with 6 decks (standard casino configuration)\n",
    "env = BlackjackEnv(config=config)\n",
    "\n",
    "eval_episodes = 1000000\n",
    "episode = 0\n",
    "\n",
    "eval_stats = {\n",
    "    'wins': 0,\n",
    "    'draws': 0,\n",
    "    'losses': 0,\n",
    "    'money won': 0,\n",
    "    'money lost': 0,\n",
    "}\n",
    "true_count_visits = defaultdict(int)\n",
    "bet_visits = defaultdict(int)\n",
    "\n",
    "while episode < eval_episodes:\n",
    "    # Reset the environment and get the true count\n",
    "    _, _, _, true_count = env.reset()\n",
    "    # keep track of the true count visits\n",
    "    true_count_visits[int(true_count)] += 1\n",
    "    # true_count = int(true_count)  # Convert true count to integer for indexing\n",
    "    true_count = discretize_true_count(true_count)\n",
    "\n",
    "    bet_amount = bet_dict[true_count]\n",
    "    # keep track of the bet visits\n",
    "    bet_visits[bet_amount] += 1\n",
    "\n",
    "    # Perform the betting action\n",
    "    bet_index = config[\"bet_size\"].index(bet_amount)\n",
    "    state, reward, done = env.step(bet_index, action_type=\"bet\")\n",
    "\n",
    "    # Update Q-values for betting\n",
    "    if done:\n",
    "        if reward > 0:\n",
    "            eval_stats['wins'] += 1\n",
    "            eval_stats['money won'] += reward * bet_amount\n",
    "        elif reward == 0:\n",
    "            eval_stats['draws'] += 1\n",
    "        else:\n",
    "            eval_stats['losses'] += 1\n",
    "            eval_stats['money lost'] += abs(reward) * bet_amount\n",
    "    else:\n",
    "        # Continue playing the game according to the strategy in q_table_strat\n",
    "        state_features = get_state_features(state)\n",
    "        while not done:\n",
    "\n",
    "            if state_features[0] < 9:\n",
    "            # Always hit this state as it's not relevant for our training\n",
    "                next_state, _, _ = env.step(1, action_type=\"move\")\n",
    "                next_state_features = get_state_features(next_state) if not done else None\n",
    "                state = next_state\n",
    "                state_features = next_state_features if next_state is not None else None\n",
    "                continue\n",
    "\n",
    "            # Choose the best action based on q_table_strat\n",
    "            q_values = get_q_values(state_features, basic_strat)\n",
    "            action = np.argmax(q_values)\n",
    "\n",
    "            if action == 2:\n",
    "                # Double down action\n",
    "                bet_amount *= 2\n",
    "\n",
    "            # Perform the action\n",
    "            next_state, reward, done = env.step(action, action_type=\"move\")\n",
    "            state = next_state\n",
    "            state_features = get_state_features(state)\n",
    "\n",
    "        # Update metrics\n",
    "        if reward > 0:\n",
    "            eval_stats['wins'] += 1\n",
    "            eval_stats['money won'] += reward * bet_amount\n",
    "        elif reward == 0:\n",
    "            eval_stats['draws'] += 1\n",
    "        else:\n",
    "            eval_stats['losses'] += 1\n",
    "            eval_stats['money lost'] += abs(reward) * bet_amount\n",
    "\n",
    "    episode += 1\n",
    "\n",
    "# Print statistics\n",
    "print(f\"Total Wins: {eval_stats['wins']}\")\n",
    "print(f\"Total Draws: {eval_stats['draws']}\")\n",
    "print(f\"Total Losses: {eval_stats['losses']}\")\n",
    "print(f\"Total Money Won: {eval_stats['money won']}\")\n",
    "print(f\"Total Money Lost: {eval_stats['money lost']}\")\n",
    "print(f\"Net profit: {eval_stats['money won'] - eval_stats['money lost']}\")\n",
    "print(f\"Average reward: {(eval_stats['money won'] - eval_stats['money lost']) / eval_episodes}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "id": "fc55a70c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "defaultdict(<class 'int'>, {0: 432195, -1: 118318, -2: 68230, -3: 39764, -4: 24502, -5: 14405, 1: 116317, 2: 66781, 3: 38973, 4: 23930, 5: 14204, 6: 8682, -6: 8790, -7: 5062, 7: 5021, 8: 3219, -8: 3253, -10: 1103, -9: 1798, 9: 1788, 10: 1098, -11: 559, -12: 297, -13: 231, -15: 52, -16: 31, 11: 574, 12: 328, 13: 183, -14: 101, 14: 88, 15: 55, -19: 2, 16: 16, 17: 15, 18: 12, -17: 11, -18: 5, 19: 4, -20: 1, 21: 2})\n",
      "defaultdict(<class 'int'>, {1: 719461, 4: 245250, 8: 35289})\n"
     ]
    }
   ],
   "source": [
    "print(true_count_visits)\n",
    "print(bet_visits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 285,
   "id": "86f707be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0: 1, 1: 4, 2: 8}\n"
     ]
    }
   ],
   "source": [
    "# take the best bet for each true count\n",
    "best_bet = {}\n",
    "for i in range(0, 3):\n",
    "    best_bet[i] = max(q_table_bet_avg[i], key=q_table_bet_avg[i].get)\n",
    "print(best_bet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "id": "9b7b93c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# os.chdir('..')\n",
    "# os.chdir('strategies')\n",
    "# # save the Q-table to a CSV file\n",
    "# q_table_bet_avg_df = pd.DataFrame.from_dict(q_table_bet_avg, orient='index')\n",
    "# q_table_bet_avg_df.to_csv('q_table_bet_avg.csv', index=True, header=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
