{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import polars as pl\n",
    "import os\n",
    "import random as rnd\n",
    "os.chdir('..')\n",
    "os.chdir('src')\n",
    "from env import BlackjackEnv\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = {\n",
    "    \"num_decks\": 6,\n",
    "    \"red_card_position\": 0.2,\n",
    "    \"bet_size\": [1],\n",
    "    \"actions\": [\"stand\", \"hit\"],\n",
    "    \"num_players\": 1\n",
    "}\n",
    "# Create environment with 6 decks (standard casino configuration)\n",
    "env = BlackjackEnv(config=config)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initialization of Q table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate relevant states - focusing on decision points that matter\n",
    "states = []\n",
    "# For hard totals (no usable ace), only track 12-21\n",
    "# Below 12, the optimal play is always hit\n",
    "for player_sum in range(12, 22):\n",
    "    for dealer_card in range(2, 12):\n",
    "        states.append((player_sum, dealer_card, 0))  # Hard total\n",
    "\n",
    "# For soft totals (with usable ace), track 12-21\n",
    "# Soft totals below 12 are impossible (A+1 = 12)\n",
    "for player_sum in range(12, 22):\n",
    "    for dealer_card in range(2, 12):\n",
    "        states.append((player_sum, dealer_card, 1))  # Soft total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Initialize Q-table with strategic initial values\n",
    "q_data = {\n",
    "    'State': states,\n",
    "    'Action 0 (Stand)': np.zeros(len(states)),\n",
    "    'Action 1 (Hit)': np.zeros(len(states))\n",
    "}\n",
    "\n",
    "# Strategic initialization: Set high values for \"stand\" in 20-21, high values for \"hit\" in 4-11\n",
    "for i, state in enumerate(states):\n",
    "    player_sum, _, _ = state\n",
    "    if player_sum >= 20:\n",
    "        # For high player sums, initialize stand value higher\n",
    "        q_data['Action 0 (Stand)'][i] = 0.5\n",
    "        q_data['Action 1 (Hit)'][i] = -0.1\n",
    "    elif player_sum < 12:\n",
    "        # For low player sums, initialize hit value higher\n",
    "        q_data['Action 0 (Stand)'][i] = -0.1\n",
    "        q_data['Action 1 (Hit)'][i] = 0.5\n",
    "\n",
    "Q = pl.DataFrame(q_data)\n",
    "\n",
    "# Double Q-learning: Second Q-table for reducing bias\n",
    "Q2 = Q.clone()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Track state-action visit counts for adaptive learning rates\n",
    "visit_counts = {}\n",
    "for state in states:\n",
    "    visit_counts[(state, 0)] = 0  # Stand\n",
    "    visit_counts[(state, 1)] = 0  # Hit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Improved hyperparameters\n",
    "initial_lr = 0.1             # Learning rate\n",
    "lr_decay_rate = 0.00005      # Gentler decay rate\n",
    "gamma = 0.95                 # Higher discount factor - long-term rewards matter more\n",
    "n_episodes = 200000         # More training episodes\n",
    "initial_epsilon = 1.0        # Start with 100% exploration\n",
    "epsilon_min = 0.01           # Minimum exploration rate\n",
    "epsilon_decay = 0.99995      # Much slower decay rate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Helper functions Strategy Q-table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Modified state representation - focusing on meaningful game states\n",
    "def get_state_features(full_state):\n",
    "    # Extract just player sum, dealer card, and usable ace\n",
    "    player_sum = full_state[0]\n",
    "    dealer_card = full_state[1]\n",
    "    usable_ace = full_state[2]\n",
    "    return (player_sum, dealer_card, usable_ace)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_adaptive_lr(state, action, base_lr):\n",
    "    \"\"\"Get state-action specific learning rate based on visit count\"\"\"\n",
    "    key = (state, action)\n",
    "    count = visit_counts.get(key, 0) + 1\n",
    "    # Decay learning rate based on visit count, but maintain a minimum rate\n",
    "    return max(base_lr / (1 + 0.005 * count), base_lr * 0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_q_values(state_features, q_table=Q):\n",
    "    \"\"\"Get Q-values for a given state\"\"\"\n",
    "    # Filter the DataFrame for the specific state\n",
    "    state_row = q_table.filter(pl.col('State') == state_features)\n",
    "    \n",
    "    if len(state_row) == 0:\n",
    "        # Return default values based on player sum\n",
    "        player_sum = state_features[0]\n",
    "        if player_sum < 12:\n",
    "            return np.array([-0.1, 0.5])  # Default to hit for low sums\n",
    "        elif player_sum >= 20:\n",
    "            return np.array([0.5, -0.1])  # Default to stand for high sums\n",
    "        else:\n",
    "            return np.array([0.0, 0.0])  # Neutral for middle sums\n",
    "            \n",
    "    # Extract Q-values from the DataFrame\n",
    "    stand_val = state_row.select('Action 0 (Stand)').item()\n",
    "    hit_val = state_row.select('Action 1 (Hit)').item()\n",
    "    return np.array([stand_val, hit_val])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_q_value(state_features, action, reward, next_state_features, lr, q_table=Q, q_table_target=Q2):\n",
    "    \"\"\"Update Q-value for state-action pair using Double Q-learning\"\"\"\n",
    "    # Check if state exists in our table\n",
    "    state_row = q_table.filter(pl.col('State') == state_features)\n",
    "    if len(state_row) == 0:\n",
    "        return # State not in our table\n",
    "    \n",
    "    # Determine which action column to update\n",
    "    action_col = 'Action 1 (Hit)' if action == 1 else 'Action 0 (Stand)'\n",
    "    \n",
    "    # Current Q-value in the DataFrame\n",
    "    current_q = state_row.select(action_col).item()\n",
    "    \n",
    "    # If next_state_features is None, this is a terminal state\n",
    "    if next_state_features is None:\n",
    "        # Terminal state - no future rewards\n",
    "        new_q = current_q + lr * (reward - current_q)\n",
    "    else:\n",
    "        # Get the next state's best action from current Q-table\n",
    "        next_q_values = get_q_values(next_state_features, q_table)\n",
    "        best_next_action = np.argmax(next_q_values)\n",
    "        \n",
    "        # Get Q-value for best action from target Q-table\n",
    "        next_q_values_target = get_q_values(next_state_features, q_table_target)\n",
    "        max_next_q = next_q_values_target[best_next_action]\n",
    "        \n",
    "        # Q-learning update formula with future rewards\n",
    "        new_q = current_q + lr * (reward + gamma * max_next_q - current_q)\n",
    "    \n",
    "    # Update the Q-table entry in the DataFrame\n",
    "    # Create a temporary mask for the state we want to update\n",
    "    mask = pl.col('State') == state_features\n",
    "    \n",
    "    # Use the when/then/otherwise pattern to update values\n",
    "    q_table = q_table.with_columns(\n",
    "        pl.when(mask)\n",
    "        .then(pl.lit(new_q))\n",
    "        .otherwise(pl.col(action_col))\n",
    "        .alias(action_col)\n",
    "    )\n",
    "    \n",
    "    # Track visit counts\n",
    "    visit_counts[(state_features, action)] = visit_counts.get((state_features, action), 0) + 1\n",
    "    \n",
    "    return q_table"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training Q-table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting improved training...\n",
      "Episode 10000, max Q-value change: 0.821892\n",
      "Episode 20000, max Q-value change: 0.517179\n",
      "Episode 30000, max Q-value change: 0.273300\n",
      "Episode 40000, max Q-value change: 0.207642\n",
      "Episode 50000, max Q-value change: 0.219709\n",
      "Episode 60000, max Q-value change: 0.132908\n",
      "Episode 70000, max Q-value change: 0.096647\n",
      "Episode 80000, max Q-value change: 0.104347\n",
      "Episode 90000, max Q-value change: 0.074383\n",
      "Episode 100000, max Q-value change: 0.092804\n",
      "Episode 110000, max Q-value change: 0.061057\n",
      "Episode 120000, max Q-value change: 0.042384\n",
      "Episode 130000, max Q-value change: 0.041183\n",
      "Episode 140000, max Q-value change: 0.047078\n",
      "Episode 150000, max Q-value change: 0.048959\n",
      "Episode 160000, max Q-value change: 0.036943\n",
      "Episode 170000, max Q-value change: 0.031302\n",
      "Episode 180000, max Q-value change: 0.036392\n",
      "Episode 190000, max Q-value change: 0.028669\n",
      "Episode 200000, max Q-value change: 0.024174\n",
      "Episode 210000, max Q-value change: 0.019015\n",
      "Episode 220000, max Q-value change: 0.018808\n",
      "Episode 230000, max Q-value change: 0.025863\n",
      "Episode 240000, max Q-value change: 0.021810\n",
      "Episode 250000, max Q-value change: 0.019891\n",
      "Episode 260000, max Q-value change: 0.016899\n",
      "Episode 270000, max Q-value change: 0.016861\n",
      "Episode 280000, max Q-value change: 0.018726\n",
      "Episode 290000, max Q-value change: 0.018819\n",
      "Episode 300000, max Q-value change: 0.015043\n",
      "Episode 310000, max Q-value change: 0.017982\n",
      "Episode 320000, max Q-value change: 0.013084\n",
      "Episode 330000, max Q-value change: 0.010821\n",
      "Episode 340000, max Q-value change: 0.017677\n",
      "Episode 350000, max Q-value change: 0.012988\n",
      "Episode 360000, max Q-value change: 0.008868\n",
      "Episode 370000, max Q-value change: 0.011058\n",
      "Episode 380000, max Q-value change: 0.009375\n",
      "Episode 390000, max Q-value change: 0.008705\n",
      "Episode 400000, max Q-value change: 0.008269\n",
      "Episode 410000, max Q-value change: 0.008376\n",
      "Episode 420000, max Q-value change: 0.011163\n",
      "Episode 430000, max Q-value change: 0.008828\n",
      "Episode 440000, max Q-value change: 0.007594\n",
      "Episode 450000, max Q-value change: 0.009438\n",
      "Episode 460000, max Q-value change: 0.006896\n",
      "Episode 470000, max Q-value change: 0.007289\n",
      "Episode 480000, max Q-value change: 0.006734\n",
      "Episode 490000, max Q-value change: 0.007225\n",
      "Episode 500000, max Q-value change: 0.006850\n",
      "Episode 510000, max Q-value change: 0.009271\n",
      "Episode 520000, max Q-value change: 0.008219\n",
      "Episode 530000, max Q-value change: 0.006674\n",
      "Episode 540000, max Q-value change: 0.007029\n",
      "Episode 550000, max Q-value change: 0.005099\n",
      "Episode 560000, max Q-value change: 0.005053\n",
      "Episode 570000, max Q-value change: 0.006655\n",
      "Episode 580000, max Q-value change: 0.005939\n",
      "Episode 590000, max Q-value change: 0.005153\n",
      "Episode 600000, max Q-value change: 0.006986\n",
      "Episode 610000, max Q-value change: 0.004904\n",
      "Episode 620000, max Q-value change: 0.004183\n",
      "Episode 630000, max Q-value change: 0.006686\n",
      "Episode 640000, max Q-value change: 0.006172\n",
      "Episode 650000, max Q-value change: 0.004835\n",
      "Episode 660000, max Q-value change: 0.006054\n",
      "Episode 670000, max Q-value change: 0.004712\n",
      "Episode 680000, max Q-value change: 0.005457\n",
      "Episode 690000, max Q-value change: 0.004977\n",
      "Episode 700000, max Q-value change: 0.005758\n",
      "Episode 710000, max Q-value change: 0.003940\n",
      "Episode 720000, max Q-value change: 0.004360\n",
      "Episode 730000, max Q-value change: 0.006512\n",
      "Episode 740000, max Q-value change: 0.004691\n",
      "Episode 750000, max Q-value change: 0.005166\n",
      "Episode 760000, max Q-value change: 0.005623\n",
      "Episode 770000, max Q-value change: 0.006019\n",
      "Episode 780000, max Q-value change: 0.005185\n",
      "Episode 790000, max Q-value change: 0.004659\n",
      "Episode 800000, max Q-value change: 0.004637\n",
      "Episode 810000, max Q-value change: 0.002874\n",
      "Episode 820000, max Q-value change: 0.003867\n",
      "Episode 830000, max Q-value change: 0.003332\n",
      "Episode 840000, max Q-value change: 0.003072\n",
      "Episode 850000, max Q-value change: 0.005306\n",
      "Episode 860000, max Q-value change: 0.003986\n",
      "Episode 870000, max Q-value change: 0.004578\n",
      "Episode 880000, max Q-value change: 0.003375\n",
      "Episode 890000, max Q-value change: 0.004741\n",
      "Episode 900000, max Q-value change: 0.002629\n",
      "Episode 910000, max Q-value change: 0.005325\n",
      "Episode 920000, max Q-value change: 0.004080\n",
      "Episode 930000, max Q-value change: 0.003900\n",
      "Episode 940000, max Q-value change: 0.004267\n",
      "Episode 950000, max Q-value change: 0.003305\n",
      "Episode 960000, max Q-value change: 0.003100\n",
      "Episode 970000, max Q-value change: 0.002741\n",
      "Episode 980000, max Q-value change: 0.003510\n",
      "Episode 990000, max Q-value change: 0.003325\n",
      "Training complete after 1000000 episodes.\n",
      "Win rate: 0.4141\n",
      "Draw rate: 0.0632\n",
      "Loss rate: 0.5227\n"
     ]
    }
   ],
   "source": [
    "# Training loop with convergence check\n",
    "print(\"Starting improved training...\")\n",
    "wins = 0\n",
    "draws = 0\n",
    "losses = 0\n",
    "epsilon = initial_epsilon\n",
    "lr = initial_lr\n",
    "money_won = 0\n",
    "money_lost = 0\n",
    "\n",
    "# Parameters for convergence\n",
    "n_episodes = 1000000  # Number of episodes for training\n",
    "convergence_threshold = 0.001  # Lower threshold for better stability\n",
    "convergence_check_interval = 10000  # Check for convergence every N episodes\n",
    "convergence_required_count = 3  # Number of consecutive checks below threshold to confirm convergence\n",
    "max_episodes = n_episodes  # Maximum episodes as a fallback\n",
    "\n",
    "# Keep a copy of the previous Q-table for comparison\n",
    "previous_q = Q.clone()\n",
    "convergence_count = 0\n",
    "converged = False\n",
    "episode = 0\n",
    "#first training phase only for the Q-table with fixed betting strategy\n",
    "while episode < max_episodes and not converged:\n",
    "\n",
    "    env.reset()\n",
    "    bet_index = env.bet_space.sample()  # Sample bet index from the environment\n",
    "    bet_amount = env.bets[bet_index]  # Sample bet amount from the environment\n",
    "    # print(env.step(bet_index, action_type=\"bet\"))\n",
    "    state, reward, done = env.step(bet_index, action_type=\"bet\")  # Place bet\n",
    "    if done:\n",
    "        if reward > 0:\n",
    "            wins += 1\n",
    "            money_won += reward * bet_amount\n",
    "        elif reward == 0:\n",
    "            draws += 1\n",
    "        else:\n",
    "            losses += 1\n",
    "            money_lost += abs(reward) * bet_amount\n",
    "    # print(bet_amount)\n",
    "    state_features = get_state_features(state)\n",
    "\n",
    "    # Training episode\n",
    "    while not done:\n",
    "        \n",
    "        if state_features[0] < 12:\n",
    "        # Always hit this state as it's not relevant for our training\n",
    "            next_state, _, _ = env.step(1, action_type=\"move\")\n",
    "            next_state_features = get_state_features(next_state) if not done else None\n",
    "            state = next_state\n",
    "            state_features = next_state_features if next_state is not None else None\n",
    "            continue\n",
    "        \n",
    "        # Epsilon-greedy action selection\n",
    "        elif np.random.rand() < epsilon:\n",
    "            action = env.move_space.sample()  # Random action\n",
    "        else:\n",
    "            q_values = get_q_values(state_features)\n",
    "            action = np.argmax(q_values)  # Greedy action\n",
    "        \n",
    "        # Take action\n",
    "        next_state, reward, done = env.step(action, action_type=\"move\")\n",
    "        next_state_features = get_state_features(next_state) if not done else None\n",
    "\n",
    "        # Get adaptive learning rate for this state-action pair\n",
    "        adaptive_lr = get_adaptive_lr(state_features, action, lr)\n",
    "\n",
    "        # Randomly decide which Q-table to update (Double Q-learning)\n",
    "        # print(f\"State: {state_features}, Action: {action}, Done: {done}, Reward: {reward}, Next State: {next_state_features}\")\n",
    "        if np.random.rand() < 0.5:\n",
    "            # print(\"Updating Q-table 1\")\n",
    "            Q = update_q_value(state_features, action, reward*bet_amount, next_state_features, adaptive_lr, Q, Q2)\n",
    "        else:\n",
    "            # print(\"Updating Q-table 2\")\n",
    "            Q2 = update_q_value(state_features, action, reward*bet_amount, next_state_features, adaptive_lr, Q2, Q)\n",
    "            \n",
    "        # Track outcomes\n",
    "        if done:\n",
    "            if reward > 0:\n",
    "                wins += 1\n",
    "                money_won += reward * bet_amount\n",
    "            elif reward == 0:\n",
    "                draws += 1\n",
    "            else:\n",
    "                losses += 1\n",
    "                money_lost += abs(reward) * bet_amount\n",
    "        \n",
    "        state = next_state\n",
    "        state_features = next_state_features if next_state is not None else None\n",
    "        \n",
    "        if state_features is None:\n",
    "            # print(f\"Entered break condition with done being {done}\")\n",
    "            break\n",
    "    \n",
    "    # Decay epsilon and learning rate\n",
    "    epsilon = max(epsilon_min, epsilon * epsilon_decay)\n",
    "    lr = initial_lr / (1 + lr_decay_rate * episode)\n",
    "    \n",
    "    # Check for convergence periodically\n",
    "    if episode % convergence_check_interval == 0 and episode > 0:\n",
    "        # Calculate the maximum absolute difference between current and previous Q-values\n",
    "        diff_stand = (Q.select('Action 0 (Stand)').to_numpy() - \n",
    "                     previous_q.select('Action 0 (Stand)').to_numpy())\n",
    "        diff_hit = (Q.select('Action 1 (Hit)').to_numpy() - \n",
    "                   previous_q.select('Action 1 (Hit)').to_numpy())\n",
    "        \n",
    "        max_diff_stand = np.max(np.abs(diff_stand))\n",
    "        max_diff_hit = np.max(np.abs(diff_hit))\n",
    "        max_diff = max(max_diff_stand, max_diff_hit)\n",
    "        \n",
    "        if max_diff < convergence_threshold:\n",
    "            convergence_count += 1\n",
    "            print(f\"Episode {episode}, max Q-value change: {max_diff:.6f} (convergence count: {convergence_count}/{convergence_required_count})\")\n",
    "            if convergence_count >= convergence_required_count:\n",
    "                print(f\"Converged after {episode} episodes (max Q-value change: {max_diff:.6f})\")\n",
    "                converged = True\n",
    "        else:\n",
    "            convergence_count = 0\n",
    "            print(f\"Episode {episode}, max Q-value change: {max_diff:.6f}\")\n",
    "        \n",
    "        # Store current Q-values for next comparison\n",
    "        previous_q = Q.clone()\n",
    "    \n",
    "    episode += 1\n",
    "\n",
    "# Final statistics\n",
    "total_episodes = episode\n",
    "print(f\"Training complete after {total_episodes} episodes.\")\n",
    "print(f\"Win rate: {wins/total_episodes:.4f}\")\n",
    "print(f\"Draw rate: {draws/total_episodes:.4f}\")\n",
    "print(f\"Loss rate: {losses/total_episodes:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing Q-table win rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Final policy evaluation...\n",
      "Final evaluation complete.\n",
      "Win rate: 0.4375\n",
      "Draw rate: 0.0821\n",
      "Loss rate: 0.4804\n",
      "Money won: 4595.0\n",
      "Money lost: 4804\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Evaluate the final policy with more episodes\n",
    "print(\"\\nFinal policy evaluation...\")\n",
    "eval_wins = 0\n",
    "eval_draws = 0\n",
    "eval_loss = 0\n",
    "money_won = 0\n",
    "money_lost = 0\n",
    "eval_episodes = 10000\n",
    "\n",
    "for _ in range(eval_episodes):\n",
    "    env.reset()\n",
    "    bet_index = env.bet_space.sample()  # Sample bet index from the environment\n",
    "    bet_amount = env.bets[bet_index]  # Sample bet amount from the environment\n",
    "    # print(env.step(bet_index, action_type=\"bet\"))\n",
    "    state, reward, done = env.step(bet_index, action_type=\"bet\")  # Place bet\n",
    "    if done:\n",
    "        if reward > 0:\n",
    "            eval_wins += 1\n",
    "            money_won += reward * bet_amount\n",
    "        elif reward == 0:\n",
    "            eval_draws += 1\n",
    "        else:\n",
    "            eval_loss += 1\n",
    "            money_lost += abs(reward) * bet_amount\n",
    "    # print(bet_amount)\n",
    "    state_features = get_state_features(state)\n",
    "\n",
    "    # Training episode\n",
    "    while not done:\n",
    "        # Always choose the best action according to average of both Q-tables\n",
    "        q_values1 = get_q_values(state_features, Q)\n",
    "        q_values2 = get_q_values(state_features, Q2)\n",
    "        avg_q_values = (q_values1 + q_values2) / 2\n",
    "        action = np.argmax(avg_q_values)\n",
    "        \n",
    "        next_state, reward, done = env.step(action, action_type=\"move\")\n",
    "        \n",
    "        if done and reward > 0:\n",
    "            eval_wins += 1\n",
    "            money_won += reward * bet_amount\n",
    "        elif done and reward == 0:\n",
    "            eval_draws += 1\n",
    "        elif done and reward < 0:\n",
    "            eval_loss += 1\n",
    "            money_lost += abs(reward) * bet_amount\n",
    "        else:\n",
    "            pass\n",
    "        \n",
    "        state = next_state\n",
    "        state_features = get_state_features(state)\n",
    "\n",
    "        if done:\n",
    "            break\n",
    "\n",
    "print(f\"Final evaluation complete.\")\n",
    "print(f\"Win rate: {eval_wins/eval_episodes:.4f}\")\n",
    "print(f\"Draw rate: {eval_draws/eval_episodes:.4f}\")\n",
    "print(f\"Loss rate: {eval_loss/eval_episodes:.4f}\")\n",
    "print(f\"Money won: {money_won}\")\n",
    "print(f\"Money lost: {money_lost}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initialization for Bet table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "counts = list(range(-5, 6))\n",
    "bet_amounts = [1,2,5]\n",
    "bet_data = {\n",
    "    'True Count': counts,\n",
    "    'Bet 1' : np.zeros(len(counts)),\n",
    "    'Bet 2' : np.zeros(len(counts)),\n",
    "    'Bet 5' : np.zeros(len(counts))\n",
    "}\n",
    "\n",
    "for i, count in enumerate(counts):\n",
    "    for j, bet_amount in enumerate(bet_amounts):\n",
    "        if count <= -2:\n",
    "            # Conservative for negative counts\n",
    "            initial_value = 1.0 if bet_amount == 1 else 0.2\n",
    "        elif -1 <= count <= 1:\n",
    "            # Neutral for counts near zero\n",
    "            initial_value = 0.8 if bet_amount == 1 else (0.5 if bet_amount == 2 else 0.2)\n",
    "        else:\n",
    "            # Aggressive for positive counts\n",
    "            initial_value = 0.2 if bet_amount == 1 else (0.5 if bet_amount == 2 else 1.0)\n",
    "        bet_data[f'Bet {bet_amount}'][i] = initial_value\n",
    "\n",
    "bet_Q = pl.DataFrame(bet_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Helpers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_bet_Q(bet_Q, true_count, bet_ind, next_true_count, reward, alpha, gamma, bets):\n",
    "    # Get the current row and bet column\n",
    "    row = bet_Q.filter(pl.col('True Count') == true_count)\n",
    "    bet_col = f'Bet {bets[bet_ind]}'\n",
    "    \n",
    "    # Get the current Q value\n",
    "    current_q = row.select(bet_col).item(0, 0)\n",
    "    \n",
    "    # Get the next row\n",
    "    next_row = bet_Q.filter(pl.col('True Count') == next_true_count)\n",
    "    \n",
    "    # Get all bet columns\n",
    "    bet_cols = [f'Bet {bet}' for bet in bets]\n",
    "    \n",
    "    # Find the maximum Q value across all bet options for the next state\n",
    "    next_q_values = next_row.select(bet_cols).to_numpy()[0]\n",
    "    next_q = np.max(next_q_values)\n",
    "    \n",
    "    # print(f\"Current Q-value: {current_q}, Next Q-value: {next_q}\") if current_q != next_q else None\n",
    "    \n",
    "    # Calculate the new Q value\n",
    "    new_q = current_q + alpha * (reward + gamma * next_q - current_q)\n",
    "    \n",
    "    # Update the DataFrame with the new Q-value\n",
    "    mask = pl.col('True Count') == true_count\n",
    "    bet_Q = bet_Q.with_columns(\n",
    "        pl.when(mask)\n",
    "        .then(pl.lit(new_q))\n",
    "        .otherwise(pl.col(bet_col))\n",
    "        .alias(bet_col)\n",
    "    )\n",
    "    \n",
    "    return bet_Q"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training for Bet table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 0, Bet Q-values: [[-5.   1.   0.2  0.2]\n",
      " [-4.   1.   0.2  0.2]\n",
      " [-3.   1.   0.2  0.2]\n",
      " [-2.   1.   0.2  0.2]\n",
      " [-1.   0.8  0.5  0.2]\n",
      " [ 0.   0.7  0.5  0.2]\n",
      " [ 1.   0.8  0.5  0.2]\n",
      " [ 2.   0.2  0.5  1. ]\n",
      " [ 3.   0.2  0.5  1. ]\n",
      " [ 4.   0.2  0.5  1. ]\n",
      " [ 5.   0.2  0.5  1. ]]\n",
      "Episode 10000, Bet Q-values: [[-5.          1.          0.2         0.2       ]\n",
      " [-4.          1.          0.2         0.2       ]\n",
      " [-3.          0.9         0.2         0.2       ]\n",
      " [-2.          0.93468177  0.33057341  0.2       ]\n",
      " [-1.          0.65175916  0.86413177  1.63230018]\n",
      " [ 0.          2.11519182  1.98293817  2.35943286]\n",
      " [ 1.          1.79885741  2.24780836  1.66278287]\n",
      " [ 2.          0.89229428  0.63505757  1.81844587]\n",
      " [ 3.          0.14805132  0.89611576  1.3501385 ]\n",
      " [ 4.          0.2         0.5         0.85823662]\n",
      " [ 5.          0.2         0.5         0.91      ]]\n",
      "Episode 20000, Bet Q-values: [[-5.          1.          0.2         0.2       ]\n",
      " [-4.          1.          0.2         0.2       ]\n",
      " [-3.          1.          0.22784894  0.2       ]\n",
      " [-2.          0.9790516   0.33057341  0.28790516]\n",
      " [-1.          0.86739882  2.36875958  0.96057579]\n",
      " [ 0.          1.89405698  1.82541953  1.97599548]\n",
      " [ 1.          1.37932328  2.08578672  1.32418678]\n",
      " [ 2.          0.48653053  0.79464598  1.32817806]\n",
      " [ 3.          0.14805132  0.66937666  0.61545962]\n",
      " [ 4.          0.2         0.53948237  0.35823662]\n",
      " [ 5.          0.2         0.5         0.99482366]]\n",
      "Episode 30000, Bet Q-values: [[-5.          1.          0.2         0.2       ]\n",
      " [-4.          1.          0.2         0.2       ]\n",
      " [-3.          0.94996894  0.22784894  0.2       ]\n",
      " [-2.          1.22332809  0.61689917  0.40176682]\n",
      " [-1.          0.9427107   0.73404839  0.71353517]\n",
      " [ 0.          0.33435208  1.07683505  0.3312644 ]\n",
      " [ 1.          0.90351824  0.30360605  0.2415256 ]\n",
      " [ 2.          0.63072324  0.60519379  0.61069969]\n",
      " [ 3.          0.10275801  0.25112984  0.12301607]\n",
      " [ 4.          0.27394824  0.3171614   0.32189533]\n",
      " [ 5.          0.2         0.5         0.89482366]]\n",
      "Episode 40000, Bet Q-values: [[-5.          1.          0.2         0.2       ]\n",
      " [-4.          1.          0.2         0.2       ]\n",
      " [-3.          0.94996894  0.22784894  0.2       ]\n",
      " [-2.          1.02434608  0.77704527  0.40176682]\n",
      " [-1.          0.56127676  0.77388134  0.95576012]\n",
      " [ 0.          1.40313208  2.76183812  0.9832156 ]\n",
      " [ 1.          0.55454945  1.26720943  0.74714153]\n",
      " [ 2.          0.57854127  1.39097347  0.47177172]\n",
      " [ 3.          1.11981993  0.20313017  0.15740621]\n",
      " [ 4.          0.27394824  0.3171614   0.42868913]\n",
      " [ 5.          0.2         0.5         0.89482366]]\n",
      "Episode 50000, Bet Q-values: [[-5.          1.          0.2         0.2       ]\n",
      " [-4.          1.          0.2         0.2       ]\n",
      " [-3.          0.64996894  0.22784894  0.2       ]\n",
      " [-2.          0.47459723  0.67225099  0.40176682]\n",
      " [-1.          0.94740402  1.26073283  2.45911629]\n",
      " [ 0.          2.19273888  2.09059279  3.08388483]\n",
      " [ 1.          1.86307846  1.85051628  2.16022014]\n",
      " [ 2.          1.83376126  1.4103638   2.07429486]\n",
      " [ 3.          2.04945657  0.40951632  0.61539515]\n",
      " [ 4.          0.27394824  0.364558    0.61735137]\n",
      " [ 5.          0.2         0.5         0.79482366]]\n",
      "Episode 60000, Bet Q-values: [[-5.          1.          0.2         0.2       ]\n",
      " [-4.          0.9         0.2         0.2       ]\n",
      " [-3.          1.00901011  0.22784894  0.2       ]\n",
      " [-2.          0.47459723  2.01967409  0.40369409]\n",
      " [-1.          1.91101892  2.69490345  2.77550852]\n",
      " [ 0.          2.36317988  1.82849067  2.98924332]\n",
      " [ 1.          1.90986064  2.46167366  1.85953246]\n",
      " [ 2.          1.96389907  2.23570878  2.04683951]\n",
      " [ 3.          1.37306652  0.87043856  0.71378978]\n",
      " [ 4.          0.27394824  0.364558    0.67148488]\n",
      " [ 5.          0.2         0.5         0.79482366]]\n",
      "Episode 70000, Bet Q-values: [[-5.          1.          0.2         0.2       ]\n",
      " [-4.          0.9         0.2         0.2       ]\n",
      " [-3.          1.00901011  0.22784894  0.2       ]\n",
      " [-2.          0.84704949  1.8552619   0.40369409]\n",
      " [-1.          2.52878017  2.41942973  2.51081919]\n",
      " [ 0.          1.96744179  2.34897369  1.82751928]\n",
      " [ 1.          2.36508549  1.45872648  1.58205561]\n",
      " [ 2.          1.15133765  1.1599937   1.45341869]\n",
      " [ 3.          0.43100811  0.73565995  0.52826486]\n",
      " [ 4.          0.27394824  0.364558    0.80039115]\n",
      " [ 5.          0.2         0.42948237  0.79482366]]\n",
      "Episode 80000, Bet Q-values: [[-5.          1.          0.2         0.2       ]\n",
      " [-4.          0.9         0.2         0.2       ]\n",
      " [-3.          1.00901011  0.22784894  0.2       ]\n",
      " [-2.          0.90455087  2.2362801   0.40369409]\n",
      " [-1.          1.21964969  1.87730909  1.54661127]\n",
      " [ 0.          1.57555154  1.48739277  1.47314001]\n",
      " [ 1.          1.17160016  1.05082105  1.31062859]\n",
      " [ 2.          0.66192719  0.65531597  0.83741914]\n",
      " [ 3.          0.34973587  0.72358307  1.24080968]\n",
      " [ 4.          0.27394824  0.364558    0.40039115]\n",
      " [ 5.          0.2         0.42948237  0.79482366]]\n",
      "Episode 90000, Bet Q-values: [[-5.          1.          0.2         0.2       ]\n",
      " [-4.          0.9         0.2         0.2       ]\n",
      " [-3.          1.00901011  0.22784894  0.2       ]\n",
      " [-2.          0.9141482   1.83745754  0.4733771 ]\n",
      " [-1.          1.18270156  1.07328884  1.0502885 ]\n",
      " [ 0.          1.53303905  1.27638025  1.57795538]\n",
      " [ 1.          0.7489213   0.92637144  1.72959047]\n",
      " [ 2.          0.63875763  0.7563188   0.95847893]\n",
      " [ 3.          0.3212103   0.53594228  1.45314919]\n",
      " [ 4.          0.17394824  0.164558    0.36865075]\n",
      " [ 5.          0.2         0.42948237  0.79482366]]\n",
      "Episode 100000, Bet Q-values: [[-5.          1.          0.2         0.2       ]\n",
      " [-4.          0.9         0.2         0.2       ]\n",
      " [-3.          0.9881091   0.22784894  0.2       ]\n",
      " [-2.          1.14236173  1.60311519  0.7071001 ]\n",
      " [-1.          1.09379405  1.79477783  1.15351449]\n",
      " [ 0.          1.44556375  1.35242043  2.19757777]\n",
      " [ 1.          1.34935827  1.37528202  1.37705631]\n",
      " [ 2.          1.33594406  1.53261249  0.87968612]\n",
      " [ 3.          0.32460211  0.53594228  1.00116727]\n",
      " [ 4.          0.17394824  0.164558    0.50273904]\n",
      " [ 5.          0.2         0.42948237  0.79482366]]\n",
      "Episode 110000, Bet Q-values: [[-5.          1.          0.2         0.2       ]\n",
      " [-4.          0.9         0.2         0.2       ]\n",
      " [-3.          0.95991933  0.22784894  0.2       ]\n",
      " [-2.          1.10843707  1.85341551  0.7071001 ]\n",
      " [-1.          1.52170793  1.51048942  1.57949199]\n",
      " [ 0.          1.60987444  0.99281385  1.21365077]\n",
      " [ 1.          1.33944116  1.33328545  1.5990044 ]\n",
      " [ 2.          1.2648359   1.72938499  1.08842355]\n",
      " [ 3.          0.55314421  0.42260964  0.78455009]\n",
      " [ 4.          0.17394824  0.164558    0.46865302]\n",
      " [ 5.          0.2         0.42948237  0.79482366]]\n",
      "Episode 120000, Bet Q-values: [[-5.          1.          0.2         0.2       ]\n",
      " [-4.          0.9         0.2         0.2       ]\n",
      " [-3.          0.95991933  0.22784894  0.2       ]\n",
      " [-2.          1.46049841  1.09582685  0.91059422]\n",
      " [-1.          0.97780923  1.28169122  1.03266104]\n",
      " [ 0.          0.10182294  0.59607392  0.11675328]\n",
      " [ 1.          0.97018749  0.3889283   0.60700073]\n",
      " [ 2.          0.84897851  0.63698563  0.74515196]\n",
      " [ 3.          0.28899243  0.97528564  0.50620007]\n",
      " [ 4.          0.15281323  0.09713397  0.74576829]\n",
      " [ 5.          0.2         0.42948237  0.89482366]]\n",
      "Episode 130000, Bet Q-values: [[-5.          1.          0.2         0.2       ]\n",
      " [-4.          0.9         0.2         0.2       ]\n",
      " [-3.          0.85991933  0.22784894  0.2       ]\n",
      " [-2.          0.92305702  1.03386487  0.91059422]\n",
      " [-1.          0.74160934  0.76039966  1.75740614]\n",
      " [ 0.          1.58431853  1.29467835  1.25752195]\n",
      " [ 1.          1.34576811  1.34039676  1.60572918]\n",
      " [ 2.          0.39202714  1.77782805  0.95726525]\n",
      " [ 3.          0.43116808  0.47388965  0.37878377]\n",
      " [ 4.          0.15005719  0.09713397  0.94067383]\n",
      " [ 5.          0.2         0.42948237  0.79482366]]\n",
      "Episode 140000, Bet Q-values: [[-5.00000000e+00  1.00000000e+00  2.00000000e-01  2.00000000e-01]\n",
      " [-4.00000000e+00  9.00000000e-01  2.00000000e-01  2.00000000e-01]\n",
      " [-3.00000000e+00  8.59919329e-01  2.27848945e-01  2.00000000e-01]\n",
      " [-2.00000000e+00  1.06268774e+00  1.76062259e+00  9.10594216e-01]\n",
      " [-1.00000000e+00  1.09774595e+00  8.40396118e-01  8.80625742e-01]\n",
      " [ 0.00000000e+00  2.61383556e-01  3.44000001e-01  5.45999755e-03]\n",
      " [ 1.00000000e+00 -9.71566802e-02  1.50205020e-01 -6.60513082e-02]\n",
      " [ 2.00000000e+00 -2.25350198e-01 -2.01884167e-01 -2.76806292e-01]\n",
      " [ 3.00000000e+00  4.76565306e-02  2.05502673e-03 -4.08323009e-03]\n",
      " [ 4.00000000e+00  2.35991854e-01  1.29739666e-01  1.25865531e+00]\n",
      " [ 5.00000000e+00  2.00000000e-01  4.29482366e-01  8.94823662e-01]]\n",
      "Episode 150000, Bet Q-values: [[-5.          1.          0.2         0.2       ]\n",
      " [-4.          0.9         0.2         0.2       ]\n",
      " [-3.          0.85991933  0.22784894  0.2       ]\n",
      " [-2.          1.23621902  1.12792361  0.8431567 ]\n",
      " [-1.          0.47156743  0.43957335  1.01302274]\n",
      " [ 0.         -0.37533913 -0.3302248  -0.37020027]\n",
      " [ 1.          0.25133186  0.76766936  0.32155029]\n",
      " [ 2.          0.33768834  0.11269404  0.13769681]\n",
      " [ 3.         -0.12336715  0.26467547  0.78461324]\n",
      " [ 4.          0.23599185  0.12973967  1.07727215]\n",
      " [ 5.          0.2         0.42948237  0.89482366]]\n",
      "Episode 160000, Bet Q-values: [[-5.          1.          0.2         0.2       ]\n",
      " [-4.          0.9         0.2         0.2       ]\n",
      " [-3.          0.90991933  0.40105598  0.2       ]\n",
      " [-2.          1.11735897  1.47123516  0.80532607]\n",
      " [-1.          1.31096716  0.8450404   1.41327692]\n",
      " [ 0.          0.65803783  0.93496137  0.55924496]\n",
      " [ 1.          0.27074609  1.13471406  0.54967859]\n",
      " [ 2.          1.63220769  0.77762888  0.55377424]\n",
      " [ 3.         -0.01459104  0.16993773  1.20509361]\n",
      " [ 4.          0.23599185  0.12973967  0.67727215]\n",
      " [ 5.          0.2         0.42948237  0.89482366]]\n",
      "Episode 170000, Bet Q-values: [[-5.          1.          0.2         0.2       ]\n",
      " [-4.          0.9         0.2         0.2       ]\n",
      " [-3.          0.90991933  0.40105598  0.2       ]\n",
      " [-2.          1.03302119  1.78551629  1.02109933]\n",
      " [-1.          2.8459806   2.19421322  2.32792482]\n",
      " [ 0.          1.98028433  1.80552749  2.688168  ]\n",
      " [ 1.          2.29398863  2.35335694  2.57752883]\n",
      " [ 2.          2.3925986   1.73099243  1.62819485]\n",
      " [ 3.          0.81179105  1.10997589  2.4682739 ]\n",
      " [ 4.          0.23599185  0.12973967  1.25325391]\n",
      " [ 5.          0.2         0.42948237  0.89482366]]\n",
      "Episode 180000, Bet Q-values: [[-5.          1.          0.2         0.2       ]\n",
      " [-4.          0.9         0.2         0.2       ]\n",
      " [-3.          1.10991933  0.40105598  0.2       ]\n",
      " [-2.          1.03302119  2.37594772  1.02109933]\n",
      " [-1.          1.91968373  1.95265998  2.18794828]\n",
      " [ 0.          1.57015518  2.00797013  1.47408979]\n",
      " [ 1.          1.81624489  1.72412188  2.72944577]\n",
      " [ 2.          1.58086029  2.32542459  1.73583797]\n",
      " [ 3.          1.34168572  1.52163638  1.79878208]\n",
      " [ 4.          0.23599185  0.39370163  1.26935929]\n",
      " [ 5.          0.2         0.42948237  0.89482366]]\n",
      "Episode 190000, Bet Q-values: [[-5.          1.          0.2         0.2       ]\n",
      " [-4.          0.9         0.2         0.2       ]\n",
      " [-3.          1.10991933  0.40105598  0.2       ]\n",
      " [-2.          1.05901643  2.85503314  1.31709398]\n",
      " [-1.          2.60260976  1.96528333  1.66858961]\n",
      " [ 0.          1.36547582  0.93242999  2.55861098]\n",
      " [ 1.          2.5957763   1.43351691  1.3814037 ]\n",
      " [ 2.          0.77802482  0.83773875  2.86673877]\n",
      " [ 3.          1.24121679  1.42821013  1.89581291]\n",
      " [ 4.          0.23599185  0.39370163  1.14111479]\n",
      " [ 5.          0.2         0.42948237  0.89482366]]\n",
      "Episode 200000, Bet Q-values: [[-5.          1.          0.2         0.2       ]\n",
      " [-4.          0.9         0.2         0.2       ]\n",
      " [-3.          1.90918634  0.40105598  0.2       ]\n",
      " [-2.          1.41456994  2.34070028  1.79002172]\n",
      " [-1.          1.90561003  2.08109809  2.33953393]\n",
      " [ 0.          2.40758514  2.10387351  2.14016786]\n",
      " [ 1.          1.98829757  2.44977582  3.4175867 ]\n",
      " [ 2.          1.39137873  2.0761462   2.67805794]\n",
      " [ 3.          1.33325561  2.13707134  1.49726551]\n",
      " [ 4.          0.23599185  0.39370163  0.82831947]\n",
      " [ 5.          0.2         0.42948237  0.94482366]]\n",
      "Episode 210000, Bet Q-values: [[-5.          1.          0.2         0.2       ]\n",
      " [-4.          0.9         0.2         0.2       ]\n",
      " [-3.          2.21910777  0.40105598  0.2       ]\n",
      " [-2.          1.39718297  2.50198867  2.16058443]\n",
      " [-1.          2.16697261  3.18132417  2.12053946]\n",
      " [ 0.          2.88243233  2.71980273  3.93051223]\n",
      " [ 1.          3.07460685  2.20603514  2.32684008]\n",
      " [ 2.          1.59030753  2.61909025  1.52922725]\n",
      " [ 3.          1.60371531  1.95484841  1.36393694]\n",
      " [ 4.          0.23599185  0.39370163  1.21796567]\n",
      " [ 5.          0.2         0.42948237  0.94482366]]\n",
      "Episode 220000, Bet Q-values: [[-5.          1.          0.2         0.2       ]\n",
      " [-4.          0.9         0.2         0.2       ]\n",
      " [-3.          2.51739586  0.40105598  0.2       ]\n",
      " [-2.          1.39718297  2.61817699  2.31634368]\n",
      " [-1.          2.63807878  2.69500684  2.94382829]\n",
      " [ 0.          2.63228402  2.79327822  3.11832134]\n",
      " [ 1.          3.0972896   2.46553837  2.02644084]\n",
      " [ 2.          2.05705981  1.80507666  2.63542035]\n",
      " [ 3.          1.77401034  1.48379936  1.35412753]\n",
      " [ 4.          0.23599185  0.39370163  0.95103783]\n",
      " [ 5.          0.2         0.42948237  0.94482366]]\n",
      "Episode 230000, Bet Q-values: [[-5.          1.          0.2         0.2       ]\n",
      " [-4.          0.9         0.2         0.2       ]\n",
      " [-3.          2.51739586  0.40105598  0.2       ]\n",
      " [-2.          1.39541039  2.83418616  2.22265503]\n",
      " [-1.          2.14828377  2.16768045  2.27368438]\n",
      " [ 0.          1.48593066  2.03477713  2.30297205]\n",
      " [ 1.          1.85062608  1.80932374  1.77090122]\n",
      " [ 2.          1.38668185  1.85767091  1.46312223]\n",
      " [ 3.          1.28935869  1.22885179  2.45867539]\n",
      " [ 4.          0.23599185  0.39370163  1.20868154]\n",
      " [ 5.          0.2         0.42948237  0.94482366]]\n",
      "Episode 240000, Bet Q-values: [[-5.          1.          0.2         0.2       ]\n",
      " [-4.          0.9         0.2         0.2       ]\n",
      " [-3.          2.51739586  0.40105598  0.2       ]\n",
      " [-2.          1.39541039  2.96741641  2.28116021]\n",
      " [-1.          2.90330065  2.49179765  3.03051237]\n",
      " [ 0.          2.50752599  2.55960602  2.70879839]\n",
      " [ 1.          1.99447568  1.97768234  2.20403523]\n",
      " [ 2.          1.98930586  2.194112    2.58785865]\n",
      " [ 3.          1.32773438  1.60565612  2.04212563]\n",
      " [ 4.          0.23599185  0.39370163  1.3633818 ]\n",
      " [ 5.          0.2         0.42948237  1.14482366]]\n",
      "Episode 250000, Bet Q-values: [[-5.          1.          0.2         0.2       ]\n",
      " [-4.          0.9         0.2         0.2       ]\n",
      " [-3.          2.88855888  0.40105598  0.2       ]\n",
      " [-2.          1.65261099  3.26997933  2.28116021]\n",
      " [-1.          3.02997612  3.61931913  3.05956577]\n",
      " [ 0.          3.65978523  2.42394365  2.59549408]\n",
      " [ 1.          2.41884606  2.60334466  2.43548273]\n",
      " [ 2.          2.34102836  3.01512935  2.05190014]\n",
      " [ 3.          1.46232344  1.72033028  2.11368126]\n",
      " [ 4.          0.52050535  0.39370163  1.64446875]\n",
      " [ 5.          0.2         0.42948237  1.14482366]]\n",
      "Episode 260000, Bet Q-values: [[-5.          1.          0.2         0.2       ]\n",
      " [-4.          0.9         0.2         0.2       ]\n",
      " [-3.          2.88855888  0.40105598  0.2       ]\n",
      " [-2.          1.72228742  3.54937528  2.29851585]\n",
      " [-1.          2.36850138  2.87669516  3.6511104 ]\n",
      " [ 0.          2.89834623  2.18150003  2.13554595]\n",
      " [ 1.          2.73164566  3.42411211  2.85892251]\n",
      " [ 2.          3.0635458   2.40296803  2.8149876 ]\n",
      " [ 3.          1.84649769  2.30294015  1.67512135]\n",
      " [ 4.          0.52050535  0.39370163  1.83870877]\n",
      " [ 5.          0.2         0.42948237  1.39482366]]\n",
      "Episode 270000, Bet Q-values: [[-5.          1.          0.2         0.2       ]\n",
      " [-4.          0.9         0.2         0.2       ]\n",
      " [-3.          2.85685336  0.40105598  0.2       ]\n",
      " [-2.          1.87515493  3.35232223  2.29851585]\n",
      " [-1.          3.0464635   3.26836489  4.09932906]\n",
      " [ 0.          5.57174547  4.0973777   4.08414141]\n",
      " [ 1.          3.67241573  4.5257252   3.68703036]\n",
      " [ 2.          3.40178442  2.6877723   3.46170558]\n",
      " [ 3.          2.02547533  2.61625897  1.99001864]\n",
      " [ 4.          0.52050535  0.39370163  1.70909099]\n",
      " [ 5.          0.2         0.42948237  1.39482366]]\n",
      "Episode 280000, Bet Q-values: [[-5.          1.          0.2         0.2       ]\n",
      " [-4.          0.9         0.2         0.2       ]\n",
      " [-3.          2.85685336  0.40105598  0.2       ]\n",
      " [-2.          1.87515493  3.82797133  2.29851585]\n",
      " [-1.          3.48577693  3.44781335  3.67002292]\n",
      " [ 0.          2.98997701  2.89224588  2.8380157 ]\n",
      " [ 1.          2.34496256  2.93912941  2.40703303]\n",
      " [ 2.          3.73686338  2.50034143  2.4139793 ]\n",
      " [ 3.          2.50938523  2.62684511  2.14140709]\n",
      " [ 4.          0.52050535  0.64524056  1.90909099]\n",
      " [ 5.          0.2         0.42948237  1.39482366]]\n",
      "Episode 290000, Bet Q-values: [[-5.          1.          0.2         0.2       ]\n",
      " [-4.          0.9         0.2         0.2       ]\n",
      " [-3.          2.83647156  0.40105598  0.2       ]\n",
      " [-2.          1.87515493  4.27195269  2.29851585]\n",
      " [-1.          2.45374635  2.99417432  2.5824636 ]\n",
      " [ 0.          3.67274234  1.58781114  1.84232113]\n",
      " [ 1.          1.51600799  1.51665341  2.27430932]\n",
      " [ 2.          1.9634435   1.94050258  2.32563816]\n",
      " [ 3.          2.53073575  3.16245234  2.04254203]\n",
      " [ 4.          0.52050535  0.64524056  2.60909099]\n",
      " [ 5.          0.2         0.42948237  1.39482366]]\n",
      "Episode 300000, Bet Q-values: [[-5.          1.          0.2         0.2       ]\n",
      " [-4.          0.9         0.2         0.2       ]\n",
      " [-3.          2.83647156  0.40105598  0.2       ]\n",
      " [-2.          1.87515493  4.3575741   2.81408639]\n",
      " [-1.          3.45356346  3.72794173  3.15756264]\n",
      " [ 0.          2.84767298  3.06371672  2.57542446]\n",
      " [ 1.          3.84545712  3.04867588  3.09310719]\n",
      " [ 2.          3.74578574  2.72618193  2.66762825]\n",
      " [ 3.          2.73641097  2.22600855  2.20399285]\n",
      " [ 4.          0.84810238  0.64524056  2.89647561]\n",
      " [ 5.          0.2         0.42948237  1.39482366]]\n",
      "Episode 310000, Bet Q-values: [[-5.          1.          0.2         0.2       ]\n",
      " [-4.          0.9         0.2         0.2       ]\n",
      " [-3.          2.89729244  0.40105598  0.2       ]\n",
      " [-2.          1.98292864  4.37213561  3.32722486]\n",
      " [-1.          3.37472692  3.4168848   3.48338482]\n",
      " [ 0.          3.36348643  2.88931455  3.44509563]\n",
      " [ 1.          2.82050794  2.844397    2.79797415]\n",
      " [ 2.          3.16094473  2.81264637  2.64209341]\n",
      " [ 3.          2.47203077  2.17469084  2.66555354]\n",
      " [ 4.          0.84810238  0.64524056  2.95578243]\n",
      " [ 5.          0.2         0.42948237  1.39482366]]\n",
      "Episode 320000, Bet Q-values: [[-5.          1.          0.2         0.2       ]\n",
      " [-4.          0.9         0.2         0.2       ]\n",
      " [-3.          2.84822575  0.40105598  0.2       ]\n",
      " [-2.          1.98292864  3.20662557  3.21505678]\n",
      " [-1.          4.10192646  3.31012654  3.55642757]\n",
      " [ 0.          3.05264281  3.22363925  3.0233079 ]\n",
      " [ 1.          3.28498754  2.99101903  3.56863559]\n",
      " [ 2.          4.41896013  3.70263444  3.49654655]\n",
      " [ 3.          2.62632628  2.50308445  4.06661803]\n",
      " [ 4.          0.84810238  0.64524056  2.41611686]\n",
      " [ 5.          0.2         0.4260165   1.39482366]]\n",
      "Episode 330000, Bet Q-values: [[-5.          1.          0.2         0.2       ]\n",
      " [-4.          0.9         0.2         0.2       ]\n",
      " [-3.          2.73041212  0.40105598  0.2       ]\n",
      " [-2.          2.12153781  4.06111186  3.07614869]\n",
      " [-1.          4.22632762  3.85272991  3.77210494]\n",
      " [ 0.          3.06779994  4.20525495  3.53469984]\n",
      " [ 1.          3.26589472  3.22660748  3.24890746]\n",
      " [ 2.          3.32597703  3.17206736  3.69305615]\n",
      " [ 3.          2.83267566  2.53492906  3.1751583 ]\n",
      " [ 4.          0.93031261  0.64524056  2.73171468]\n",
      " [ 5.          0.2         0.4260165   1.39482366]]\n",
      "Episode 340000, Bet Q-values: [[-5.          1.          0.2         0.2       ]\n",
      " [-4.          0.9         0.2         0.2       ]\n",
      " [-3.          2.63041212  0.40105598  0.2       ]\n",
      " [-2.          2.28242524  3.50051244  3.20781893]\n",
      " [-1.          4.51435166  3.55239536  3.62581016]\n",
      " [ 0.          3.50754613  4.09591871  3.36436134]\n",
      " [ 1.          3.48316867  4.4960363   3.48545829]\n",
      " [ 2.          3.24089677  3.36021863  3.35165455]\n",
      " [ 3.          3.27818548  2.61740763  3.03678897]\n",
      " [ 4.          1.22344381  0.82019887  2.86162461]\n",
      " [ 5.          0.2         0.4260165   1.39482366]]\n",
      "Episode 350000, Bet Q-values: [[-5.          1.          0.2         0.2       ]\n",
      " [-4.          0.9         0.2         0.2       ]\n",
      " [-3.          2.85184697  0.40105598  0.2       ]\n",
      " [-2.          2.28242524  2.9270613   2.90781893]\n",
      " [-1.          3.04823376  3.60165651  3.07876188]\n",
      " [ 0.          3.51086085  3.32085953  4.73583374]\n",
      " [ 1.          2.73619799  2.78372049  3.08222689]\n",
      " [ 2.          3.279865    2.52675098  2.55613883]\n",
      " [ 3.          2.78936693  2.503887    2.59664252]\n",
      " [ 4.          1.27709388  0.82019887  2.65994451]\n",
      " [ 5.          0.2         0.4260165   1.39482366]]\n",
      "Episode 360000, Bet Q-values: [[-5.          1.          0.2         0.2       ]\n",
      " [-4.          0.9         0.2         0.2       ]\n",
      " [-3.          2.81477479  0.40105598  0.2       ]\n",
      " [-2.          2.28242524  3.68876994  2.90781893]\n",
      " [-1.          3.22276619  3.40413851  4.01297625]\n",
      " [ 0.          2.86833475  2.89229331  2.84006441]\n",
      " [ 1.          3.55119174  3.12465071  3.19673048]\n",
      " [ 2.          2.94906136  3.13099768  3.07246553]\n",
      " [ 3.          2.70565563  3.22144586  2.60852604]\n",
      " [ 4.          1.27709388  1.05688967  2.55994451]\n",
      " [ 5.          0.2         0.4260165   1.29482366]]\n",
      "Episode 370000, Bet Q-values: [[-5.          1.          0.2         0.2       ]\n",
      " [-4.          0.9         0.2         0.2       ]\n",
      " [-3.          3.32157517  0.40105598  0.2       ]\n",
      " [-2.          2.32295302  3.90474288  3.02123758]\n",
      " [-1.          3.83169623  3.64600866  4.40645461]\n",
      " [ 0.          4.26363894  4.67469446  5.58619939]\n",
      " [ 1.          3.27293768  5.13988341  3.08830261]\n",
      " [ 2.          3.32788723  3.01669108  2.76284846]\n",
      " [ 3.          2.49819575  2.49775836  2.49366789]\n",
      " [ 4.          1.27709388  1.05688967  2.45994451]\n",
      " [ 5.          0.2         0.4260165   1.29482366]]\n",
      "Episode 380000, Bet Q-values: [[-5.          1.          0.2         0.2       ]\n",
      " [-4.          0.9         0.2         0.2       ]\n",
      " [-3.          3.22157517  0.40105598  0.2       ]\n",
      " [-2.          2.52281523  4.03898905  3.2409411 ]\n",
      " [-1.          3.61384712  4.69807531  3.42173488]\n",
      " [ 0.          3.72238447  4.64772901  3.63730486]\n",
      " [ 1.          3.45326231  4.25434695  3.33456657]\n",
      " [ 2.          3.70096788  4.44491926  3.14919813]\n",
      " [ 3.          2.07300946  3.13992157  2.18419324]\n",
      " [ 4.          1.27709388  1.05688967  1.62743807]\n",
      " [ 5.          0.2         0.4260165   1.29482366]]\n",
      "Episode 390000, Bet Q-values: [[-5.          1.          0.2         0.2       ]\n",
      " [-4.          0.9         0.2         0.2       ]\n",
      " [-3.          3.22157517  0.40105598  0.2       ]\n",
      " [-2.          2.52281523  3.09483767  3.1409411 ]\n",
      " [-1.          2.93686985  3.26623742  2.77706077]\n",
      " [ 0.          2.47119943  2.43020983  2.44474975]\n",
      " [ 1.          3.03641269  2.94912468  3.11236951]\n",
      " [ 2.          2.68676525  3.34896874  2.69896027]\n",
      " [ 3.          2.51422588  2.91218636  1.88272613]\n",
      " [ 4.          1.27709388  1.05688967  1.92149923]\n",
      " [ 5.          0.2         0.4260165   1.29482366]]\n",
      "Episode 400000, Bet Q-values: [[-5.          1.          0.2         0.2       ]\n",
      " [-4.          0.9         0.2         0.2       ]\n",
      " [-3.          3.22157517  0.40105598  0.68501807]\n",
      " [-2.          2.52281523  2.93530451  4.3090604 ]\n",
      " [-1.          2.72256294  2.76080996  2.82632564]\n",
      " [ 0.          2.90132132  2.77595346  2.88026731]\n",
      " [ 1.          3.04233894  3.7301819   2.84834182]\n",
      " [ 2.          3.14935791  3.30972282  3.16149828]\n",
      " [ 3.          3.25943053  2.47671579  2.00173313]\n",
      " [ 4.          1.30391805  1.49381109  2.5453356 ]\n",
      " [ 5.          0.2         0.4260165   1.29482366]]\n",
      "Episode 410000, Bet Q-values: [[-5.          1.          0.2         0.2       ]\n",
      " [-4.          0.9         0.2         0.2       ]\n",
      " [-3.          3.22157517  0.40105598  0.68501807]\n",
      " [-2.          2.52281523  2.93530451  4.12259633]\n",
      " [-1.          2.87471106  2.88589688  4.01650798]\n",
      " [ 0.          5.55995509  3.87162957  3.58475191]\n",
      " [ 1.          3.23122454  3.56452735  3.24073765]\n",
      " [ 2.          3.51662174  3.16039036  3.47149449]\n",
      " [ 3.          2.90993964  2.44241134  1.97681343]\n",
      " [ 4.          1.30391805  1.49381109  2.65944772]\n",
      " [ 5.          0.2         0.4260165   1.29482366]]\n",
      "Episode 420000, Bet Q-values: [[-5.          1.          0.2         0.2       ]\n",
      " [-4.          0.9         0.2         0.2       ]\n",
      " [-3.          3.22157517  0.40105598  0.68501807]\n",
      " [-2.          2.52281523  3.19278581  4.05972191]\n",
      " [-1.          3.94207525  3.9839837   3.96154649]\n",
      " [ 0.          4.81046548  4.35320043  4.35638234]\n",
      " [ 1.          3.80766241  3.30641509  4.34561629]\n",
      " [ 2.          3.45986096  3.96780942  3.56125759]\n",
      " [ 3.          3.86987706  2.89120585  2.62538064]\n",
      " [ 4.          1.56297545  1.49381109  3.544492  ]\n",
      " [ 5.          0.2         0.4260165   1.19482366]]\n",
      "Episode 430000, Bet Q-values: [[-5.          1.          0.2         0.2       ]\n",
      " [-4.          0.9         0.2         0.2       ]\n",
      " [-3.          3.11186337  0.40105598  0.68501807]\n",
      " [-2.          2.52281523  3.19278581  3.76792588]\n",
      " [-1.          4.4405696   4.37714699  4.24732928]\n",
      " [ 0.          3.51612281  3.45776774  3.99445149]\n",
      " [ 1.          4.08750584  4.024203    4.11089181]\n",
      " [ 2.          3.47419058  4.12581648  3.77408052]\n",
      " [ 3.          3.91648936  3.09924049  2.60097818]\n",
      " [ 4.          1.8511271   1.57887918  3.59638544]\n",
      " [ 5.          0.2         0.4260165   1.19482366]]\n",
      "Episode 440000, Bet Q-values: [[-5.          1.          0.2         0.2       ]\n",
      " [-4.          0.9         0.2         0.2       ]\n",
      " [-3.          3.11186337  0.40105598  0.68501807]\n",
      " [-2.          2.61915634  3.67882587  3.17114712]\n",
      " [-1.          4.14765961  4.07983173  3.97907879]\n",
      " [ 0.          4.68345216  4.94609733  5.05043715]\n",
      " [ 1.          4.29185146  4.45978362  4.60817059]\n",
      " [ 2.          4.27748899  4.61344207  4.33581457]\n",
      " [ 3.          5.21310133  3.54371758  2.6744023 ]\n",
      " [ 4.          1.8511271   1.57887918  3.73951426]\n",
      " [ 5.          0.2         0.4260165   1.19482366]]\n",
      "Episode 450000, Bet Q-values: [[-5.          1.          0.2         0.2       ]\n",
      " [-4.          0.9         0.2         0.2       ]\n",
      " [-3.          2.94890289  0.40105598  0.68501807]\n",
      " [-2.          2.61915634  4.30892435  3.17114712]\n",
      " [-1.          5.37855461  5.00594483  5.26388207]\n",
      " [ 0.          6.30142768  5.92111167  5.95227298]\n",
      " [ 1.          5.88179325  5.84047246  5.89318714]\n",
      " [ 2.          5.57056394  6.05273103  5.19815091]\n",
      " [ 3.          5.11270916  4.19462282  3.16230308]\n",
      " [ 4.          1.8511271   1.57887918  4.0783626 ]\n",
      " [ 5.          0.2         0.4260165   1.19482366]]\n",
      "Episode 460000, Bet Q-values: [[-5.          1.          0.2         0.2       ]\n",
      " [-4.          0.9         0.2         0.2       ]\n",
      " [-3.          2.94890289  0.40105598  0.68501807]\n",
      " [-2.          3.05277978  5.26084734  3.35402978]\n",
      " [-1.          5.93521945  6.88186783  5.77526593]\n",
      " [ 0.          6.3343473   5.68359653  5.84894414]\n",
      " [ 1.          6.57349391  5.39838116  5.73924159]\n",
      " [ 2.          4.9312908   5.43287891  5.10510166]\n",
      " [ 3.          4.15468332  4.27939975  3.67258639]\n",
      " [ 4.          1.8511271   1.57887918  3.66491491]\n",
      " [ 5.          0.19948237  0.4260165   1.36434217]]\n",
      "Episode 470000, Bet Q-values: [[-5.          1.          0.2         0.2       ]\n",
      " [-4.          0.9         0.2         0.2       ]\n",
      " [-3.          2.94890289  0.40105598  0.68501807]\n",
      " [-2.          3.50926865  5.19453908  4.21175112]\n",
      " [-1.          5.18474156  5.10333488  5.15214888]\n",
      " [ 0.          5.50942509  4.55996225  4.16207307]\n",
      " [ 1.          4.3597564   4.70062518  4.3822967 ]\n",
      " [ 2.          4.18004715  4.12922595  4.19623727]\n",
      " [ 3.          4.1888488   3.76097796  3.79889956]\n",
      " [ 4.          1.8511271   1.90726708  3.92907032]\n",
      " [ 5.          0.19948237  0.4260165   1.36434217]]\n",
      "Episode 480000, Bet Q-values: [[-5.          1.          0.2         0.2       ]\n",
      " [-4.          0.9         0.2         0.2       ]\n",
      " [-3.          3.19346651  0.40105598  0.68501807]\n",
      " [-2.          3.50926865  4.94583907  4.4080968 ]\n",
      " [-1.          4.5348493   4.17237136  4.26294562]\n",
      " [ 0.          4.68692903  4.46844592  4.47005576]\n",
      " [ 1.          4.42013758  4.37747452  4.43443216]\n",
      " [ 2.          4.52505845  4.52384635  4.06426554]\n",
      " [ 3.          4.12053518  4.27314747  3.75930981]\n",
      " [ 4.          1.95892142  2.16089694  3.95683033]\n",
      " [ 5.          0.19948237  0.4260165   1.36434217]]\n",
      "Episode 490000, Bet Q-values: [[-5.          1.          0.2         0.2       ]\n",
      " [-4.          0.9         0.2         0.2       ]\n",
      " [-3.          3.26813325  0.40105598  0.68501807]\n",
      " [-2.          3.50926865  5.24706397  4.4080968 ]\n",
      " [-1.          5.04716356  4.53061411  4.81619197]\n",
      " [ 0.          4.37457808  4.51245474  5.77182025]\n",
      " [ 1.          3.94586273  5.50221622  3.96149969]\n",
      " [ 2.          4.92736324  4.33921929  4.12313559]\n",
      " [ 3.          4.6646089   4.14563527  4.02788338]\n",
      " [ 4.          1.95892142  2.16089694  4.35687787]\n",
      " [ 5.          0.19948237  0.4260165   1.36434217]]\n",
      "Episode 500000, Bet Q-values: [[-5.          1.          0.2         0.2       ]\n",
      " [-4.          0.9         0.2         0.2       ]\n",
      " [-3.          3.26813325  0.40105598  0.68501807]\n",
      " [-2.          3.69240175  5.78529284  4.47127743]\n",
      " [-1.          5.71747711  4.99841949  5.15588708]\n",
      " [ 0.          4.9568788   5.24916368  4.87129276]\n",
      " [ 1.          4.90958503  5.11319805  4.83843932]\n",
      " [ 2.          5.2097863   5.30064531  5.28936573]\n",
      " [ 3.          5.7835258   4.41625208  4.04385936]\n",
      " [ 4.          2.06871707  2.47049504  4.06021445]\n",
      " [ 5.          0.19948237  0.4260165   1.06434217]]\n",
      "Episode 510000, Bet Q-values: [[-5.          1.          0.2         0.2       ]\n",
      " [-4.          0.9         0.2         0.2       ]\n",
      " [-3.          3.16813325  0.40105598  0.68501807]\n",
      " [-2.          3.69240175  5.54943499  4.47127743]\n",
      " [-1.          5.36911566  5.58127986  6.46349853]\n",
      " [ 0.          6.1449834   6.42932523  6.85128424]\n",
      " [ 1.          5.69026687  5.99409803  6.68086954]\n",
      " [ 2.          5.5700024   6.2623608   5.21443346]\n",
      " [ 3.          5.99369347  4.62187449  4.58880737]\n",
      " [ 4.          2.06871707  2.47049504  4.06021445]\n",
      " [ 5.          0.19948237  0.4260165   1.4539294 ]]\n",
      "Episode 520000, Bet Q-values: [[-5.          1.          0.2         0.2       ]\n",
      " [-4.          0.9         0.2         0.2       ]\n",
      " [-3.          2.96813325  0.40105598  0.68501807]\n",
      " [-2.          3.69240175  5.32862311  4.47127743]\n",
      " [-1.          5.30832193  5.41643008  5.33135705]\n",
      " [ 0.          4.14072547  3.92727851  3.77451751]\n",
      " [ 1.          4.85283761  4.2227544   4.34067506]\n",
      " [ 2.          4.79903183  5.36602731  5.45437487]\n",
      " [ 3.          4.6411245   5.28015273  4.60264559]\n",
      " [ 4.          2.16786681  2.47049504  3.96021445]\n",
      " [ 5.          0.19948237  0.4260165   1.4539294 ]]\n",
      "Episode 530000, Bet Q-values: [[-5.          1.          0.2         0.2       ]\n",
      " [-4.          0.9         0.2         0.2       ]\n",
      " [-3.          3.11418223  0.40105598  0.68501807]\n",
      " [-2.          4.56843548  5.20760818  4.47127743]\n",
      " [-1.          5.16497901  4.96720047  6.27511501]\n",
      " [ 0.          6.29798777  6.30826155  6.27943797]\n",
      " [ 1.          7.01454275  5.93717303  5.80445046]\n",
      " [ 2.          4.82348547  5.31823666  6.77032164]\n",
      " [ 3.          5.44408512  4.56687008  4.43965369]\n",
      " [ 4.          2.16786681  2.47049504  3.90317057]\n",
      " [ 5.          0.19948237  0.4260165   1.3539294 ]]\n",
      "Episode 540000, Bet Q-values: [[-5.          1.          0.2         0.2       ]\n",
      " [-4.          0.9         0.2         0.2       ]\n",
      " [-3.          3.21418223  0.40105598  0.68501807]\n",
      " [-2.          4.56843548  5.66882294  4.56919298]\n",
      " [-1.          5.81596376  5.95651725  6.10064709]\n",
      " [ 0.          5.42826585  5.19488767  5.37842913]\n",
      " [ 1.          5.2423586   5.9256852   5.22073437]\n",
      " [ 2.          5.53331526  5.49085867  5.41161464]\n",
      " [ 3.          4.4230547   4.46687008  4.76646933]\n",
      " [ 4.          2.16786681  2.47049504  4.05947671]\n",
      " [ 5.          0.19948237  0.4260165   1.3539294 ]]\n",
      "Episode 550000, Bet Q-values: [[-5.          1.          0.2         0.2       ]\n",
      " [-4.          0.9         0.2         0.2       ]\n",
      " [-3.          3.21418223  0.40105598  0.68501807]\n",
      " [-2.          4.4866231   5.36463625  4.56919298]\n",
      " [-1.          4.64010459  4.57441689  4.90925967]\n",
      " [ 0.          3.82447465  4.51832892  3.93887275]\n",
      " [ 1.          4.48186927  4.62727084  4.48300697]\n",
      " [ 2.          4.85602579  4.88179867  4.83843152]\n",
      " [ 3.          4.35599516  4.40075118  4.57361364]\n",
      " [ 4.          2.16786681  2.47049504  4.28160692]\n",
      " [ 5.          0.19948237  0.4260165   1.3539294 ]]\n",
      "Episode 560000, Bet Q-values: [[-5.          1.          0.2         0.2       ]\n",
      " [-4.          0.9         0.2         0.2       ]\n",
      " [-3.          3.21418223  0.40105598  0.68501807]\n",
      " [-2.          4.60748312  4.86416303  4.54873731]\n",
      " [-1.          5.43234616  6.1727664   5.15534543]\n",
      " [ 0.          6.39099969  5.67094916  5.98380293]\n",
      " [ 1.          6.38014257  5.68905931  5.62378052]\n",
      " [ 2.          5.41207963  4.61358336  5.04467785]\n",
      " [ 3.          4.85205461  4.30075118  4.5345919 ]\n",
      " [ 4.          2.16786681  2.47049504  4.70865169]\n",
      " [ 5.          0.19948237  0.4260165   1.3539294 ]]\n",
      "Episode 570000, Bet Q-values: [[-5.          1.          0.2         0.2       ]\n",
      " [-4.          0.9         0.2         0.2       ]\n",
      " [-3.          3.21418223  0.40105598  0.68501807]\n",
      " [-2.          4.53652711  5.18558651  4.54873731]\n",
      " [-1.          5.46719592  6.68887439  5.58943359]\n",
      " [ 0.          6.01643689  6.33932138  6.02253576]\n",
      " [ 1.          6.55592321  6.42466893  5.95043952]\n",
      " [ 2.          5.76452487  5.67522711  6.15125517]\n",
      " [ 3.          5.25067714  4.50193271  4.5930909 ]\n",
      " [ 4.          2.16786681  2.24883847  3.58125446]\n",
      " [ 5.          0.19948237  0.4260165   1.2539294 ]]\n",
      "Episode 580000, Bet Q-values: [[-5.          1.          0.2         0.2       ]\n",
      " [-4.          0.9         0.2         0.2       ]\n",
      " [-3.          3.34413406  0.40105598  0.68501807]\n",
      " [-2.          4.53652711  5.61370049  4.54408032]\n",
      " [-1.          4.60183229  5.55259486  4.83841646]\n",
      " [ 0.          5.24198264  4.02789927  4.04055989]\n",
      " [ 1.          5.45491822  5.06411763  5.02061632]\n",
      " [ 2.          4.58280201  5.40851792  4.66649075]\n",
      " [ 3.          4.45962546  4.53633004  4.2907529 ]\n",
      " [ 4.          2.16786681  2.24883847  3.42852195]\n",
      " [ 5.          0.19948237  0.4260165   1.2539294 ]]\n",
      "Episode 590000, Bet Q-values: [[-5.          1.          0.2         0.2       ]\n",
      " [-4.          0.9         0.2         0.2       ]\n",
      " [-3.          3.44413406  0.79536379  0.68501807]\n",
      " [-2.          4.53652711  5.35668271  4.7740368 ]\n",
      " [-1.          4.26995916  4.30929393  4.53280425]\n",
      " [ 0.          3.98744558  3.4870678   3.43323008]\n",
      " [ 1.          3.72260797  3.65960466  3.76530965]\n",
      " [ 2.          3.99925279  4.41201016  4.11950218]\n",
      " [ 3.          4.37761321  4.51172855  4.38141859]\n",
      " [ 4.          2.16786681  2.24883847  3.19534936]\n",
      " [ 5.          0.19948237  0.4260165   1.3539294 ]]\n",
      "Episode 600000, Bet Q-values: [[-5.          1.          0.2         0.2       ]\n",
      " [-4.          0.9         0.2         0.2       ]\n",
      " [-3.          3.54600284  0.79536379  0.68501807]\n",
      " [-2.          4.53652711  5.37977623  4.7740368 ]\n",
      " [-1.          4.60731037  5.97088326  4.41917738]\n",
      " [ 0.          5.6063234   7.0013564   5.47375703]\n",
      " [ 1.          5.19475729  5.60459063  5.34217052]\n",
      " [ 2.          4.64753991  4.84671358  4.87097837]\n",
      " [ 3.          3.87332782  3.96555972  4.61234982]\n",
      " [ 4.          2.16786681  2.24883847  3.95024312]\n",
      " [ 5.          0.19948237  0.4260165   1.3539294 ]]\n",
      "Episode 610000, Bet Q-values: [[-5.          1.          0.2         0.2       ]\n",
      " [-4.          0.9         0.2         0.2       ]\n",
      " [-3.          3.54600284  0.79536379  0.68501807]\n",
      " [-2.          4.51745621  4.96708198  4.7740368 ]\n",
      " [-1.          4.20523099  4.34104517  5.59546801]\n",
      " [ 0.          4.10565452  4.40079231  4.35965604]\n",
      " [ 1.          5.04721541  4.62095753  4.41281088]\n",
      " [ 2.          5.181979    5.43803797  4.88644399]\n",
      " [ 3.          4.01625506  4.60709419  3.97883329]\n",
      " [ 4.          2.16786681  2.24883847  3.88716209]\n",
      " [ 5.          0.19948237  0.4260165   1.3539294 ]]\n",
      "Episode 620000, Bet Q-values: [[-5.          1.          0.2         0.2       ]\n",
      " [-4.          0.9         0.2         0.2       ]\n",
      " [-3.          3.54600284  0.79536379  0.68501807]\n",
      " [-2.          4.51745621  4.81490664  4.78812379]\n",
      " [-1.          4.97779557  5.48659447  5.03728982]\n",
      " [ 0.          5.58464754  4.8725438   5.00357669]\n",
      " [ 1.          4.63882863  4.67888348  5.55350834]\n",
      " [ 2.          4.99904758  4.52599177  4.61170716]\n",
      " [ 3.          4.13248326  4.12522983  4.11544878]\n",
      " [ 4.          2.16786681  2.28733851  3.71054393]\n",
      " [ 5.          0.19948237  0.4260165   1.3539294 ]]\n",
      "Episode 630000, Bet Q-values: [[-5.          1.          0.2         0.2       ]\n",
      " [-4.          0.9         0.2         0.2       ]\n",
      " [-3.          3.54600284  0.79536379  0.68501807]\n",
      " [-2.          4.51745621  4.87029477  4.7299211 ]\n",
      " [-1.          4.70966882  4.67790664  4.5242666 ]\n",
      " [ 0.          4.12752545  4.99241429  4.38451857]\n",
      " [ 1.          4.56473691  4.61106763  4.64451376]\n",
      " [ 2.          4.46888989  4.53177658  4.59462509]\n",
      " [ 3.          4.84044333  4.43920943  4.29581026]\n",
      " [ 4.          2.16786681  2.28733851  3.86181977]\n",
      " [ 5.          0.19948237  0.4260165   1.3539294 ]]\n",
      "Episode 640000, Bet Q-values: [[-5.          1.          0.2         0.2       ]\n",
      " [-4.          0.9         0.2         0.2       ]\n",
      " [-3.          3.72291879  0.79536379  0.68501807]\n",
      " [-2.          4.52575994  5.41516238  4.69869116]\n",
      " [-1.          6.40593273  5.2494338   4.86241322]\n",
      " [ 0.          5.08660462  5.36143643  5.25533697]\n",
      " [ 1.          5.17338774  5.14346626  5.33604513]\n",
      " [ 2.          4.90612813  5.07047414  5.30923913]\n",
      " [ 3.          4.1771681   4.69610037  4.29533087]\n",
      " [ 4.          2.16786681  2.28733851  3.86181977]\n",
      " [ 5.          0.19948237  0.4260165   1.3539294 ]]\n",
      "Episode 650000, Bet Q-values: [[-5.          1.          0.2         0.2       ]\n",
      " [-4.          0.9         0.2         0.2       ]\n",
      " [-3.          3.72291879  0.79536379  0.68501807]\n",
      " [-2.          4.52575994  5.55114578  4.69869116]\n",
      " [-1.          4.34194605  4.70681861  5.42765779]\n",
      " [ 0.          4.91024638  4.8770844   4.92613406]\n",
      " [ 1.          4.78902936  4.78965054  4.7529062 ]\n",
      " [ 2.          4.07349398  4.10106491  4.95250001]\n",
      " [ 3.          4.02633481  3.96362462  4.4475142 ]\n",
      " [ 4.          2.4522621   2.28733851  4.03603073]\n",
      " [ 5.          0.19948237  0.4260165   1.52213953]]\n",
      "Episode 660000, Bet Q-values: [[-5.          1.          0.2         0.2       ]\n",
      " [-4.          0.9         0.2         0.2       ]\n",
      " [-3.          3.72291879  0.79536379  0.68501807]\n",
      " [-2.          4.95126932  5.96836967  4.84879039]\n",
      " [-1.          4.55154297  6.11547364  4.77859676]\n",
      " [ 0.          4.08265798  3.6863025   3.7326428 ]\n",
      " [ 1.          3.84165541  4.02048273  4.55208525]\n",
      " [ 2.          3.92040565  3.77994963  4.08406528]\n",
      " [ 3.          3.64001546  3.65330917  3.83224513]\n",
      " [ 4.          2.4522621   2.28733851  3.40174428]\n",
      " [ 5.          0.19948237  0.4260165   1.62213953]]\n",
      "Episode 670000, Bet Q-values: [[-5.          1.          0.2         0.2       ]\n",
      " [-4.          0.9         0.2         0.2       ]\n",
      " [-3.          3.72291879  0.79536379  0.68501807]\n",
      " [-2.          4.68451358  5.15789653  4.74139776]\n",
      " [-1.          3.6544628   4.26665882  3.58883142]\n",
      " [ 0.          4.49898335  4.37069594  5.56604373]\n",
      " [ 1.          5.09418919  2.87243516  2.99099389]\n",
      " [ 2.          3.47331921  4.32603855  3.46020111]\n",
      " [ 3.          3.30506959  4.04827463  3.43095363]\n",
      " [ 4.          2.46924985  2.28733851  2.98174591]\n",
      " [ 5.          0.19948237  0.4260165   1.62213953]]\n",
      "Episode 680000, Bet Q-values: [[-5.          1.          0.2         0.2       ]\n",
      " [-4.          0.9         0.2         0.2       ]\n",
      " [-3.          3.72291879  0.79536379  0.68501807]\n",
      " [-2.          4.46723401  4.37206977  4.56304764]\n",
      " [-1.          3.21630187  3.84895122  3.21877558]\n",
      " [ 0.          3.1371838   3.20291005  3.13745965]\n",
      " [ 1.          3.11430603  3.18314169  3.78592646]\n",
      " [ 2.          3.42440457  3.62264541  3.24056809]\n",
      " [ 3.          3.21632803  3.25718506  3.34686945]\n",
      " [ 4.          2.41049945  2.28733851  2.88839183]\n",
      " [ 5.          0.19948237  0.4260165   1.62213953]]\n",
      "Episode 690000, Bet Q-values: [[-5.          1.          0.2         0.2       ]\n",
      " [-4.          0.9         0.2         0.2       ]\n",
      " [-3.          3.72291879  0.79536379  0.68501807]\n",
      " [-2.          4.33736228  4.29768466  4.37715729]\n",
      " [-1.          3.69951143  5.48983789  3.73146827]\n",
      " [ 0.          5.64620083  5.60070099  6.04999634]\n",
      " [ 1.          4.84410763  3.96091744  3.89178223]\n",
      " [ 2.          3.70136408  4.41821833  3.75256022]\n",
      " [ 3.          3.28298412  3.67208263  3.12898075]\n",
      " [ 4.          2.41049945  2.28733851  2.7805249 ]\n",
      " [ 5.          0.19948237  0.4260165   1.62213953]]\n",
      "Episode 700000, Bet Q-values: [[-5.          1.          0.2         0.2       ]\n",
      " [-4.          0.9         0.2         0.2       ]\n",
      " [-3.          3.78834264  0.79536379  0.68501807]\n",
      " [-2.          4.03958293  4.44821769  4.17715729]\n",
      " [-1.          3.27832134  3.51076402  3.76407484]\n",
      " [ 0.          3.83914677  3.52770394  3.64124524]\n",
      " [ 1.          3.72779942  3.39302538  3.46346227]\n",
      " [ 2.          3.20276932  3.37631976  3.7202764 ]\n",
      " [ 3.          3.25139353  4.01482877  3.27333788]\n",
      " [ 4.          2.41049945  2.44013185  2.7805249 ]\n",
      " [ 5.          0.19948237  0.4260165   1.62213953]]\n",
      "Episode 710000, Bet Q-values: [[-5.          1.          0.2         0.2       ]\n",
      " [-4.          0.9         0.2         0.2       ]\n",
      " [-3.          3.68834264  0.79536379  0.68501807]\n",
      " [-2.          3.99984765  4.61522791  4.17715729]\n",
      " [-1.          4.43258402  4.31602138  5.74545479]\n",
      " [ 0.          4.69569719  5.00822628  4.61115617]\n",
      " [ 1.          4.08205466  4.13408544  5.08017546]\n",
      " [ 2.          4.28257739  3.82010711  3.7757187 ]\n",
      " [ 3.          3.19294764  3.22646795  3.30098037]\n",
      " [ 4.          2.41049945  2.51433417  2.37043168]\n",
      " [ 5.          0.19948237  0.4260165   1.62213953]]\n",
      "Episode 720000, Bet Q-values: [[-5.          1.          0.2         0.2       ]\n",
      " [-4.          0.9         0.2         0.2       ]\n",
      " [-3.          3.68834264  0.79536379  0.68501807]\n",
      " [-2.          4.14965639  4.44723762  4.33296144]\n",
      " [-1.          3.28025808  4.69910023  3.61624456]\n",
      " [ 0.          3.66079934  4.26896634  3.37352495]\n",
      " [ 1.          2.74496401  2.85044767  3.04522974]\n",
      " [ 2.          2.41740071  2.48736409  2.48489518]\n",
      " [ 3.          2.8390273   2.80912809  2.73029085]\n",
      " [ 4.          2.43166346  2.39592455  2.37043168]\n",
      " [ 5.          0.19948237  0.4260165   1.62213953]]\n",
      "Episode 730000, Bet Q-values: [[-5.          1.          0.2         0.2       ]\n",
      " [-4.          0.9         0.2         0.2       ]\n",
      " [-3.          3.68834264  0.79536379  0.68501807]\n",
      " [-2.          3.82841006  3.97412215  4.30021916]\n",
      " [-1.          3.39995672  4.25235031  3.36025894]\n",
      " [ 0.          3.16638469  3.22074059  3.5185081 ]\n",
      " [ 1.          3.64449052  2.95007881  3.14757567]\n",
      " [ 2.          2.30221097  3.28068344  2.63776213]\n",
      " [ 3.          2.21586914  2.44643234  2.11355364]\n",
      " [ 4.          2.16228979  2.2128178   2.31631355]\n",
      " [ 5.          0.19948237  0.4260165   1.62213953]]\n",
      "Episode 740000, Bet Q-values: [[-5.          1.          0.2         0.2       ]\n",
      " [-4.          0.9         0.2         0.2       ]\n",
      " [-3.          3.94740238  0.79536379  0.68501807]\n",
      " [-2.          3.71091828  3.83546656  4.08587926]\n",
      " [-1.          3.28882092  3.26491835  3.01696632]\n",
      " [ 0.          2.6412432   2.63698426  2.48866389]\n",
      " [ 1.          2.47738293  2.70016973  2.85037838]\n",
      " [ 2.          2.22307421  3.70380659  2.28273287]\n",
      " [ 3.          2.38329955  2.02108669  1.98606879]\n",
      " [ 4.          2.16228979  2.3128178   2.11631355]\n",
      " [ 5.          0.19948237  0.4260165   1.52213953]]\n",
      "Episode 750000, Bet Q-values: [[-5.          1.          0.2         0.2       ]\n",
      " [-4.          0.9         0.2         0.2       ]\n",
      " [-3.          3.84152011  0.79536379  0.68501807]\n",
      " [-2.          3.64841438  4.70075981  3.72143036]\n",
      " [-1.          2.95784573  4.11540587  3.22661445]\n",
      " [ 0.          4.18772914  3.60629325  3.59684017]\n",
      " [ 1.          3.49971287  3.62457516  3.52238183]\n",
      " [ 2.          2.60403709  2.53392745  2.94045972]\n",
      " [ 3.          2.37242036  2.0055156   1.93944472]\n",
      " [ 4.          2.06228979  2.09191006  2.11631355]\n",
      " [ 5.          0.19948237  0.4260165   1.52213953]]\n",
      "Episode 760000, Bet Q-values: [[-5.          1.          0.2         0.2       ]\n",
      " [-4.          0.9         0.2         0.2       ]\n",
      " [-3.          3.84152011  0.79536379  0.68501807]\n",
      " [-2.          3.64841438  4.62705866  3.72143036]\n",
      " [-1.          3.8663407   3.82163892  4.01140162]\n",
      " [ 0.          3.28364915  3.15907508  3.85647238]\n",
      " [ 1.          3.57836606  3.38893218  4.10330302]\n",
      " [ 2.          4.08487066  3.07524765  3.20459361]\n",
      " [ 3.          2.29477603  2.23631882  2.81109522]\n",
      " [ 4.          2.06228979  2.09191006  2.31631355]\n",
      " [ 5.          0.19948237  0.4260165   1.52213953]]\n",
      "Episode 770000, Bet Q-values: [[-5.          1.          0.2         0.2       ]\n",
      " [-4.          0.9         0.2         0.2       ]\n",
      " [-3.          3.87288514  0.79536379  0.68501807]\n",
      " [-2.          3.61173953  4.39078783  3.87940048]\n",
      " [-1.          4.33010964  4.29568081  4.34661334]\n",
      " [ 0.          4.62948428  3.36252218  3.438209  ]\n",
      " [ 1.          4.23949745  3.25073488  3.19862679]\n",
      " [ 2.          3.59501582  3.28970691  3.88280842]\n",
      " [ 3.          2.54312538  3.19057662  2.5019278 ]\n",
      " [ 4.          2.06228979  2.09191006  2.34513087]\n",
      " [ 5.          0.19948237  0.4260165   1.52213953]]\n",
      "Episode 780000, Bet Q-values: [[-5.          1.          0.2         0.2       ]\n",
      " [-4.          0.9         0.2         0.2       ]\n",
      " [-3.          4.30689862  0.79536379  0.68501807]\n",
      " [-2.          3.80810118  4.64004995  4.01436019]\n",
      " [-1.          4.72132468  5.19968827  4.81277881]\n",
      " [ 0.          3.8512804   4.14278668  4.64053601]\n",
      " [ 1.          3.60401127  3.97557688  3.87793676]\n",
      " [ 2.          3.79347086  3.78989125  3.400363  ]\n",
      " [ 3.          2.68586215  3.90351024  2.87985243]\n",
      " [ 4.          2.06228979  2.09191006  2.55501344]\n",
      " [ 5.          0.19948237  0.4260165   1.52213953]]\n",
      "Episode 790000, Bet Q-values: [[-5.          1.          0.2         0.2       ]\n",
      " [-4.          0.9         0.2         0.2       ]\n",
      " [-3.          4.20689862  1.07750089  0.68501807]\n",
      " [-2.          4.03422163  4.6637228   4.01436019]\n",
      " [-1.          3.4011023   3.36372329  3.79056034]\n",
      " [ 0.          3.68133617  3.87319341  4.08750536]\n",
      " [ 1.          3.83837899  2.55556223  3.23636535]\n",
      " [ 2.          2.40933916  2.17342243  2.83267877]\n",
      " [ 3.          2.49337247  2.46427792  2.56737803]\n",
      " [ 4.          2.06228979  2.09191006  2.77548626]\n",
      " [ 5.          0.19948237  0.4260165   1.52213953]]\n",
      "Episode 800000, Bet Q-values: [[-5.          1.          0.2         0.2       ]\n",
      " [-4.          0.9         0.2         0.2       ]\n",
      " [-3.          4.27299163  1.07750089  0.68501807]\n",
      " [-2.          4.03422163  4.523358    3.93506493]\n",
      " [-1.          3.47872717  3.50367285  3.43994377]\n",
      " [ 0.          3.07580128  3.64589573  2.7921456 ]\n",
      " [ 1.          3.39942941  2.58193959  2.70476167]\n",
      " [ 2.          2.44958207  2.4283047   2.32315481]\n",
      " [ 3.          2.05051684  2.01490905  2.02820354]\n",
      " [ 4.          2.06228979  2.09191006  2.35015159]\n",
      " [ 5.          0.19948237  0.4260165   1.52213953]]\n",
      "Episode 810000, Bet Q-values: [[-5.          1.          0.2         0.2       ]\n",
      " [-4.          0.9         0.2         0.2       ]\n",
      " [-3.          4.27299163  1.07750089  0.68501807]\n",
      " [-2.          3.7105761   3.81227065  3.93767394]\n",
      " [-1.          3.03639213  3.02582008  2.90888892]\n",
      " [ 0.          3.72772643  3.0158272   3.24164424]\n",
      " [ 1.          3.09482391  3.22811217  3.81365596]\n",
      " [ 2.          2.58435899  3.08050318  3.07227304]\n",
      " [ 3.          3.44475035  2.4241789   2.30238231]\n",
      " [ 4.          2.45729376  2.09191006  2.20235038]\n",
      " [ 5.          0.19948237  0.4260165   1.42213953]]\n",
      "Episode 820000, Bet Q-values: [[-5.          1.          0.2         0.2       ]\n",
      " [-4.          0.9         0.2         0.2       ]\n",
      " [-3.          4.27299163  1.07750089  0.68501807]\n",
      " [-2.          3.67821763  3.65385048  4.02719863]\n",
      " [-1.          3.28713391  3.3558      3.46424429]\n",
      " [ 0.          3.37072674  3.31686557  3.44331256]\n",
      " [ 1.          3.24188514  3.30678827  3.89948967]\n",
      " [ 2.          3.42362439  3.21494088  3.82157157]\n",
      " [ 3.          3.45249922  2.64472964  2.32739912]\n",
      " [ 4.          3.09512988  1.82522159  2.20235038]\n",
      " [ 5.          0.19948237  0.4260165   1.73565495]]\n",
      "Episode 830000, Bet Q-values: [[-5.          1.          0.2         0.2       ]\n",
      " [-4.          0.9         0.2         0.2       ]\n",
      " [-3.          4.27299163  1.07750089  0.68501807]\n",
      " [-2.          3.67821763  3.68072691  4.3232076 ]\n",
      " [-1.          5.03396466  3.57693776  3.61880231]\n",
      " [ 0.          3.44222738  3.42597334  3.46233281]\n",
      " [ 1.          3.5055683   2.921126    3.78117594]\n",
      " [ 2.          3.19657526  2.69998746  3.15862059]\n",
      " [ 3.          2.56614119  2.66220595  2.30010878]\n",
      " [ 4.          3.11390278  1.82522159  2.20235038]\n",
      " [ 5.          0.19948237  0.4260165   1.73565495]]\n",
      "Episode 840000, Bet Q-values: [[-5.          1.          0.2         0.2       ]\n",
      " [-4.          0.9         0.2         0.2       ]\n",
      " [-3.          4.27299163  1.07750089  0.68501807]\n",
      " [-2.          3.65012318  3.84238153  3.70633939]\n",
      " [-1.          3.8991601   4.3452815   3.87345689]\n",
      " [ 0.          4.32279409  3.87444851  4.01205915]\n",
      " [ 1.          3.56056214  4.11749413  3.38564298]\n",
      " [ 2.          3.67773179  4.27233297  3.28182361]\n",
      " [ 3.          4.06546483  2.78403938  2.70973477]\n",
      " [ 4.          2.8902976   1.82522159  2.37114511]\n",
      " [ 5.          0.19948237  0.4260165   1.73565495]]\n",
      "Episode 850000, Bet Q-values: [[-5.          1.          0.2         0.2       ]\n",
      " [-4.          0.9         0.2         0.2       ]\n",
      " [-3.          4.17299163  1.07750089  0.68501807]\n",
      " [-2.          3.65012318  4.00843608  3.70633939]\n",
      " [-1.          3.91337017  3.75985637  3.59214168]\n",
      " [ 0.          3.62788579  3.65880046  4.33786611]\n",
      " [ 1.          3.90571857  3.85951427  4.12221769]\n",
      " [ 2.          3.64499513  3.6964297   3.50434929]\n",
      " [ 3.          3.90147525  3.36039301  2.95496601]\n",
      " [ 4.          3.25965017  1.82522159  2.37114511]\n",
      " [ 5.          0.19948237  0.4260165   1.73565495]]\n",
      "Episode 860000, Bet Q-values: [[-5.          1.          0.2         0.2       ]\n",
      " [-4.          0.9         0.2         0.2       ]\n",
      " [-3.          4.12387956  1.07750089  0.68501807]\n",
      " [-2.          4.02173745  4.11451589  3.84589125]\n",
      " [-1.          4.5657081   4.25818804  4.11591943]\n",
      " [ 0.          4.32791413  3.5264399   3.74278296]\n",
      " [ 1.          3.87872876  3.54137054  4.15263578]\n",
      " [ 2.          3.66595161  4.45883857  3.65671832]\n",
      " [ 3.          4.19664114  3.67590822  3.56872196]\n",
      " [ 4.          3.15965017  1.82522159  2.37114511]\n",
      " [ 5.          0.19948237  0.4260165   1.73565495]]\n",
      "Episode 870000, Bet Q-values: [[-5.          1.          0.2         0.2       ]\n",
      " [-4.          0.9         0.2         0.2       ]\n",
      " [-3.          4.12387956  1.07750089  0.68501807]\n",
      " [-2.          4.02173745  4.29092999  3.97270142]\n",
      " [-1.          4.73819645  4.69947892  5.69207132]\n",
      " [ 0.          4.60404815  4.40782529  4.44688053]\n",
      " [ 1.          4.91624521  4.77911403  5.2721186 ]\n",
      " [ 2.          4.57490589  4.32771884  3.94573795]\n",
      " [ 3.          3.42804339  3.58531311  3.50393668]\n",
      " [ 4.          3.02086919  1.82522159  2.37114511]\n",
      " [ 5.          0.19948237  0.4260165   1.73565495]]\n",
      "Episode 880000, Bet Q-values: [[-5.          1.          0.2         0.2       ]\n",
      " [-4.          0.9         0.2         0.2       ]\n",
      " [-3.          4.12387956  1.07750089  0.68501807]\n",
      " [-2.          4.02173745  4.70085515  4.29980875]\n",
      " [-1.          3.91252555  4.31430423  4.01596998]\n",
      " [ 0.          3.50252062  3.66828338  2.96695425]\n",
      " [ 1.          3.35594427  3.69099469  3.32386091]\n",
      " [ 2.          3.35578356  3.51349563  3.93402968]\n",
      " [ 3.          3.13566664  3.99169804  3.31518614]\n",
      " [ 4.          3.17461946  1.82522159  2.37114511]\n",
      " [ 5.          0.19948237  0.4260165   1.73565495]]\n",
      "Episode 890000, Bet Q-values: [[-5.          1.          0.2         0.2       ]\n",
      " [-4.          0.9         0.2         0.2       ]\n",
      " [-3.          3.85157712  1.07750089  0.68501807]\n",
      " [-2.          4.08408483  4.18271011  4.16777683]\n",
      " [-1.          3.55162197  4.87871868  3.71328257]\n",
      " [ 0.          4.51411749  4.4757524   5.4116729 ]\n",
      " [ 1.          4.1804898   4.01415791  3.9970845 ]\n",
      " [ 2.          3.49010543  3.93337482  3.49502188]\n",
      " [ 3.          3.62908503  3.13080477  3.01873449]\n",
      " [ 4.          2.91339742  1.82522159  2.37114511]\n",
      " [ 5.          0.19948237  0.4260165   1.73565495]]\n",
      "Episode 900000, Bet Q-values: [[-5.          1.          0.2         0.2       ]\n",
      " [-4.          0.9         0.2         0.2       ]\n",
      " [-3.          3.85157712  1.07750089  0.68501807]\n",
      " [-2.          3.63060607  4.0516089   3.74548455]\n",
      " [-1.          3.02700343  3.04851316  3.67427323]\n",
      " [ 0.          3.5829403   2.90514971  3.02945803]\n",
      " [ 1.          3.70682678  2.69897684  2.78048873]\n",
      " [ 2.          3.62861822  2.64767409  2.64948514]\n",
      " [ 3.          2.95633608  2.95484113  3.58802334]\n",
      " [ 4.          3.27421577  1.82522159  2.37114511]\n",
      " [ 5.          0.19948237  0.4260165   1.73565495]]\n",
      "Episode 910000, Bet Q-values: [[-5.          1.          0.2         0.2       ]\n",
      " [-4.          0.9         0.2         0.2       ]\n",
      " [-3.          3.59257437  1.07750089  0.68501807]\n",
      " [-2.          3.56373176  3.67341027  3.8362898 ]\n",
      " [-1.          3.43985806  3.02454645  3.01289433]\n",
      " [ 0.          4.07593236  3.41633117  3.45819084]\n",
      " [ 1.          3.2364258   3.30229383  3.43979074]\n",
      " [ 2.          4.33922516  3.04751058  3.54229519]\n",
      " [ 3.          2.86126079  3.34656167  3.44996038]\n",
      " [ 4.          3.23674529  2.10953048  2.57172853]\n",
      " [ 5.          0.19948237  0.4260165   2.09951103]]\n",
      "Episode 920000, Bet Q-values: [[-5.          1.          0.2         0.2       ]\n",
      " [-4.          0.9         0.2         0.2       ]\n",
      " [-3.          3.59257437  1.07750089  0.68501807]\n",
      " [-2.          3.76375613  3.67341027  4.85527389]\n",
      " [-1.          5.13976332  3.01755945  4.16042905]\n",
      " [ 0.          4.07160803  4.27333527  4.06505489]\n",
      " [ 1.          4.33355686  4.58516925  4.39215461]\n",
      " [ 2.          3.92087487  4.24871755  3.93977848]\n",
      " [ 3.          3.30348584  3.15641434  4.11206949]\n",
      " [ 4.          3.37563219  2.10953048  2.57172853]\n",
      " [ 5.          0.19948237  0.4260165   2.09951103]]\n",
      "Episode 930000, Bet Q-values: [[-5.          1.          0.2         0.2       ]\n",
      " [-4.          0.9         0.2         0.2       ]\n",
      " [-3.          3.6375119   1.07750089  0.68501807]\n",
      " [-2.          3.76375613  3.7114351   4.58590901]\n",
      " [-1.          4.68400893  4.71683932  4.89442431]\n",
      " [ 0.          4.05523697  4.03582866  4.05758539]\n",
      " [ 1.          3.84315954  3.87621911  4.53973683]\n",
      " [ 2.          4.00105169  3.90115147  3.48222974]\n",
      " [ 3.          2.99200947  3.71081358  2.94480691]\n",
      " [ 4.          3.17802008  2.10953048  2.62450678]\n",
      " [ 5.          0.19948237  0.4260165   2.19951103]]\n",
      "Episode 940000, Bet Q-values: [[-5.          1.          0.2         0.2       ]\n",
      " [-4.          0.9         0.2         0.2       ]\n",
      " [-3.          3.7955146   1.07750089  0.68501807]\n",
      " [-2.          3.76375613  3.85110713  3.87470443]\n",
      " [-1.          3.27700488  3.56856833  3.52935049]\n",
      " [ 0.          2.03506285  2.2099143   2.35184228]\n",
      " [ 1.          2.55540408  2.62602518  2.97155459]\n",
      " [ 2.          3.33354818  3.11245786  3.03235211]\n",
      " [ 3.          2.95674985  3.73594258  2.84480691]\n",
      " [ 4.          3.59975964  2.35637944  2.62450678]\n",
      " [ 5.          0.19948237  0.4260165   2.29951103]]\n",
      "Episode 950000, Bet Q-values: [[-5.          1.          0.2         0.2       ]\n",
      " [-4.          0.9         0.2         0.2       ]\n",
      " [-3.          4.2955146   1.07750089  0.68501807]\n",
      " [-2.          4.30965908  3.65001976  3.56022101]\n",
      " [-1.          3.81096082  2.87158735  3.00332797]\n",
      " [ 0.          5.4967038   4.47282655  4.57206847]\n",
      " [ 1.          3.62845112  4.8960284   3.60085281]\n",
      " [ 2.          4.40511034  2.8680513   3.19988932]\n",
      " [ 3.          2.82362713  2.87463928  2.92623672]\n",
      " [ 4.          3.25973478  2.35637944  2.62450678]\n",
      " [ 5.          0.19948237  0.4260165   2.29951103]]\n",
      "Episode 960000, Bet Q-values: [[-5.          1.          0.2         0.2       ]\n",
      " [-4.          0.9         0.2         0.2       ]\n",
      " [-3.          4.2955146   1.07750089  0.68501807]\n",
      " [-2.          4.39862411  3.65001976  3.56022101]\n",
      " [-1.          4.60721548  4.20107784  4.00264764]\n",
      " [ 0.          4.99740943  4.34996639  4.43745267]\n",
      " [ 1.          4.25055858  3.76377082  3.75800268]\n",
      " [ 2.          3.37421441  3.38461541  3.9135851 ]\n",
      " [ 3.          2.82362713  2.87463928  3.8700969 ]\n",
      " [ 4.          3.0737124   2.35637944  2.77802958]\n",
      " [ 5.          0.19948237  0.4260165   2.29951103]]\n",
      "Episode 970000, Bet Q-values: [[-5.          1.          0.2         0.2       ]\n",
      " [-4.          0.9         0.2         0.2       ]\n",
      " [-3.          4.2955146   1.07750089  0.68501807]\n",
      " [-2.          4.53965362  3.61646202  3.56816427]\n",
      " [-1.          3.99484621  4.25647254  4.09634423]\n",
      " [ 0.          3.88707089  3.26080544  2.97652585]\n",
      " [ 1.          3.64580457  3.83905178  3.44083321]\n",
      " [ 2.          4.1792156   3.72609034  3.91069432]\n",
      " [ 3.          3.5082229   2.63970323  3.02090111]\n",
      " [ 4.          2.92374359  2.35637944  2.77802958]\n",
      " [ 5.          0.19948237  0.4260165   2.29951103]]\n",
      "Episode 980000, Bet Q-values: [[-5.          1.          0.2         0.2       ]\n",
      " [-4.          0.9         0.2         0.2       ]\n",
      " [-3.          4.43287251  1.07750089  0.68501807]\n",
      " [-2.          4.37063802  3.77530406  3.78825721]\n",
      " [-1.          3.90346596  4.40537905  4.21004246]\n",
      " [ 0.          4.1698792   5.39201101  4.15991017]\n",
      " [ 1.          4.16713826  4.01023391  4.72853843]\n",
      " [ 2.          4.55029258  4.32863895  4.08159211]\n",
      " [ 3.          3.08283442  2.99051676  3.77622729]\n",
      " [ 4.          2.93565541  2.35637944  2.77802958]\n",
      " [ 5.          0.19948237  0.4260165   2.29951103]]\n",
      "Episode 990000, Bet Q-values: [[-5.          1.          0.2         0.2       ]\n",
      " [-4.          0.9         0.2         0.2       ]\n",
      " [-3.          4.56050916  1.07750089  0.68501807]\n",
      " [-2.          4.46022348  3.77530406  4.00271874]\n",
      " [-1.          3.71708066  4.00787257  3.70493205]\n",
      " [ 0.          3.16283008  3.85983331  3.37748235]\n",
      " [ 1.          4.14967752  3.30405067  3.37281437]\n",
      " [ 2.          3.01944087  4.07587523  2.96361658]\n",
      " [ 3.          3.08834751  3.17359192  3.16225368]\n",
      " [ 4.          2.73565541  2.35637944  3.17802958]\n",
      " [ 5.          0.19948237  0.4260165   2.35236289]]\n",
      "Final evaluation complete.\n",
      "Win rate: 0.4336\n",
      "Draw rate: 0.0835\n",
      "Loss rate: 0.4829\n",
      "Money won: 1217819.0\n",
      "Money lost: 1289558\n",
      "Net profit: -71739.0\n"
     ]
    }
   ],
   "source": [
    "# Q-learning parameters\n",
    "n_episodes = 1000000\n",
    "epsilon = 0.1\n",
    "alpha = 0.1\n",
    "gamma = 1.0\n",
    "bet_sizes = [1, 2, 5]  # low and high bets\n",
    "\n",
    "config = {\n",
    "    \"num_decks\": 6,\n",
    "    \"red_card_position\": 0.2,\n",
    "    \"bet_size\": bet_sizes,\n",
    "    \"actions\": [\"stand\", \"hit\"],\n",
    "    \"num_players\": 1\n",
    "}\n",
    "env = BlackjackEnv(config)\n",
    "episode = 0\n",
    "wins = 0\n",
    "draws = 0\n",
    "losses = 0\n",
    "money_won = 0\n",
    "money_lost = 0\n",
    "\n",
    "while episode < n_episodes:\n",
    "    obs = env.reset()\n",
    "    true_count = obs[3]\n",
    "    #discretize the true count to the range of the bet table\n",
    "    true_count = int(np.clip(true_count, -5, 5))\n",
    "    if np.random.rand() < epsilon:\n",
    "        bet_ind = rnd.choice(range(env.bet_space.n))\n",
    "    else:\n",
    "        # Get the current row for the true count\n",
    "        row_data = bet_Q.filter(pl.col('True Count') == true_count)\n",
    "        # Get all bet columns\n",
    "        bet_cols = [f'Bet {bet}' for bet in env.bets]\n",
    "        # Get Q values for all bets at this count\n",
    "        q_values = row_data.select(bet_cols).to_numpy()[0]\n",
    "        # Choose the bet with the highest Q value\n",
    "        bet_ind = np.argmax(q_values)\n",
    "    bet = env.bets[bet_ind]\n",
    "    state, reward, done = env.step(bet_ind, action_type=\"bet\")\n",
    "    next_true_count = state[3]\n",
    "    #discretize the true count to the range of the bet table\n",
    "    next_true_count = int(np.clip(next_true_count, -5, 5))\n",
    "    state_features = get_state_features(state)\n",
    "    if done:\n",
    "        bet_Q = update_bet_Q(bet_Q, true_count, bet_ind, next_true_count, reward, alpha, gamma, env.bets)\n",
    "        if reward > 0:\n",
    "            wins += 1\n",
    "            money_won += reward * bet\n",
    "        elif reward == 0:\n",
    "            draws += 1\n",
    "        else:\n",
    "            losses += 1\n",
    "            money_lost += abs(reward) * bet\n",
    "    while not done:\n",
    "        if state_features[0] < 12:\n",
    "            next_state, _, _ = env.step(1, action_type=\"move\")\n",
    "            next_state_features = get_state_features(next_state) if not done else None\n",
    "            state = next_state\n",
    "            state_features = next_state_features if next_state is not None else None\n",
    "            continue\n",
    "        \n",
    "        q_values1 = get_q_values(state_features, Q)\n",
    "        q_values2 = get_q_values(state_features, Q2)\n",
    "        avg_q_values = (q_values1 + q_values2) / 2\n",
    "        action = np.argmax(avg_q_values)\n",
    "        next_state, reward, done = env.step(action, action_type=\"move\")\n",
    "        next_state_features = get_state_features(next_state) if not done else None\n",
    "        if done:\n",
    "            next_true_count = next_state[3]\n",
    "            #discretize the true count to the range of the bet table\n",
    "            next_true_count = int(np.clip(next_true_count, -5, 5))\n",
    "            bet_Q = update_bet_Q(bet_Q, true_count, bet_ind, next_true_count, reward, alpha, gamma, env.bets)\n",
    "            if reward > 0:\n",
    "                wins += 1\n",
    "                money_won += reward * bet\n",
    "            elif reward == 0:\n",
    "                draws += 1\n",
    "            else:\n",
    "                losses += 1\n",
    "                money_lost += abs(reward) * bet\n",
    "                \n",
    "        state = next_state\n",
    "        state_features = next_state_features if next_state is not None else None\n",
    "    \n",
    "    #make some prints to  see the progress of the training\n",
    "    if episode % 10000 == 0:\n",
    "        # print something about how the bet table is doing\n",
    "        print(f\"Episode {episode}, Bet Q-values: {bet_Q.to_numpy()}\")\n",
    "    \n",
    "    episode += 1\n",
    "\n",
    "\n",
    "print(f\"Final evaluation complete.\")\n",
    "print(f\"Win rate: {wins/n_episodes:.4f}\")\n",
    "print(f\"Draw rate: {draws/n_episodes:.4f}\")\n",
    "print(f\"Loss rate: {losses/n_episodes:.4f}\")\n",
    "print(f\"Money won: {money_won}\")\n",
    "print(f\"Money lost: {money_lost}\")\n",
    "print(f\"Net profit: {money_won - money_lost}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing Q-table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Final policy evaluation with bet table...\n",
      "Final evaluation complete.\n",
      "Win rate: 0.4400\n",
      "Draw rate: 0.0822\n",
      "Loss rate: 0.4778\n",
      "Money won: 22318.0\n",
      "Money lost: 23122\n",
      "Net profit: -804.0\n",
      "Benchmark Net profit: -160.5\n"
     ]
    }
   ],
   "source": [
    "# Test the final policy with the bet table\n",
    "print(\"\\nFinal policy evaluation with bet table...\")\n",
    "eval_wins = 0\n",
    "eval_draws = 0\n",
    "eval_loss = 0\n",
    "money_won = 0\n",
    "money_lost = 0\n",
    "benchmark_money_won = 0\n",
    "benchmark_money_lost = 0\n",
    "eval_episodes = 10000\n",
    "bet_sizes = [1, 2, 5]  # low and high bets\n",
    "config = {\n",
    "    \"num_decks\": 6,\n",
    "    \"red_card_position\": 0.2,\n",
    "    \"bet_size\": bet_sizes,\n",
    "    \"actions\": [\"stand\", \"hit\"],\n",
    "    \"num_players\": 1\n",
    "}\n",
    "env = BlackjackEnv(config)\n",
    "episode = 0\n",
    "while episode < eval_episodes:\n",
    "    obs = env.reset()\n",
    "    true_count = obs[3]\n",
    "    #discretize the true count to the range of the bet table\n",
    "    true_count = int(np.clip(true_count, -5, 5))\n",
    "    bet_ind = np.argmax(bet_Q.filter(pl.col('True Count') == true_count).select([f'Bet {bet}' for bet in env.bets]).to_numpy()[0])\n",
    "    bet = env.bets[bet_ind]\n",
    "    state, reward, done = env.step(bet_ind, action_type=\"bet\")\n",
    "    next_true_count = state[3]\n",
    "    #discretize the true count to the range of the bet table\n",
    "    next_true_count = int(np.clip(next_true_count, -5, 5))\n",
    "    state_features = get_state_features(state)\n",
    "    if done:\n",
    "        if reward > 0:\n",
    "            eval_wins += 1\n",
    "            money_won += reward * bet\n",
    "            benchmark_money_won += reward * 1\n",
    "        elif reward == 0:\n",
    "            eval_draws += 1\n",
    "        else:\n",
    "            eval_loss += 1\n",
    "            money_lost += abs(reward) * bet\n",
    "            benchmark_money_lost += abs(reward) * 1\n",
    "    while not done:\n",
    "        q_values1 = get_q_values(state_features, Q)\n",
    "        q_values2 = get_q_values(state_features, Q2)\n",
    "        avg_q_values = (q_values1 + q_values2) / 2\n",
    "        action = np.argmax(avg_q_values)\n",
    "        next_state, reward, done = env.step(action, action_type=\"move\")\n",
    "        next_state_features = get_state_features(next_state) if not done else None\n",
    "        if done:\n",
    "            next_true_count = next_state[3]\n",
    "            #discretize the true count to the range of the bet table\n",
    "            next_true_count = int(np.clip(next_true_count, -5, 5))\n",
    "            if reward > 0:\n",
    "                eval_wins += 1\n",
    "                money_won += reward * bet\n",
    "                benchmark_money_won += reward * 1\n",
    "            elif reward == 0:\n",
    "                eval_draws += 1\n",
    "            else:\n",
    "                eval_loss += 1\n",
    "                money_lost += abs(reward) * bet\n",
    "                benchmark_money_lost += abs(reward) * 1\n",
    "        \n",
    "        state = next_state\n",
    "        state_features = next_state_features if next_state is not None else None\n",
    "    \n",
    "    episode += 1\n",
    "\n",
    "\n",
    "print(f\"Final evaluation complete.\")\n",
    "print(f\"Win rate: {eval_wins/eval_episodes:.4f}\")\n",
    "print(f\"Draw rate: {eval_draws/eval_episodes:.4f}\")\n",
    "print(f\"Loss rate: {eval_loss/eval_episodes:.4f}\")\n",
    "print(f\"Money won: {money_won}\")\n",
    "print(f\"Money lost: {money_lost}\")\n",
    "print(f\"Net profit: {money_won - money_lost}\")\n",
    "# print(f\"Benchmark Money won: {benchmark_money_won}\")\n",
    "# print(f\"Benchmark Money lost: {benchmark_money_lost}\")\n",
    "print(f\"Benchmark Net profit: {benchmark_money_won - benchmark_money_lost}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "benchmark_bet = {\n",
    "    -5: {1 : 1.0, 2 : 0.2, 5 : 0.2},\n",
    "    -4: {1 : 1.0, 2 : 0.2, 5 : 0.2},\n",
    "    -3: {1 : 1.0, 2 : 0.2, 5 : 0.2},\n",
    "    -2: {1 : 1.0, 2 : 0.5, 5 : 0.2},\n",
    "    -1: {1 : 0.8, 2 : 0.5, 5 : 0.2},\n",
    "     0: {1 : 0.8, 2 : 0.5, 5 : 0.2},\n",
    "     1: {1 : 0.8, 2 : 0.5, 5 : 0.2},\n",
    "     2: {1 : 0.5, 2 : 0.8, 5 : 0.2},\n",
    "     3: {1 : 0.5, 2 : 0.8, 5 : 0.2},\n",
    "     4: {1 : 0.2, 2 : 0.5, 5 : 1.0},\n",
    "     5: {1 : 0.2, 2 : 0.8, 5 : 1.0}\n",
    "}"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
